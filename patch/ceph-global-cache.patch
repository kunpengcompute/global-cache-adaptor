diff --git a/src/CMakeLists.txt b/src/CMakeLists.txt
index 28ec9835..bc11ec5f 100644
--- a/src/CMakeLists.txt
+++ b/src/CMakeLists.txt
@@ -103,6 +103,11 @@ if(HAVE_INTEL)
     HAVE_BETTER_YASM_ELF64)
 endif()
 
+if(WITH_GLOBAL_CACHE)
+set(third_part_dir /usr/local/gcache_adaptor)
+message(STATUS "third part directory --> " ${third_part_dir})
+link_directories(${third_part_dir}/lib)
+endif()
 
 # require c++17
 if(CMAKE_VERSION VERSION_LESS "3.8")
@@ -393,6 +398,10 @@ if(WITH_DPDK)
   list(APPEND ceph_common_deps common_async_dpdk)
 endif()
 
+if(WITH_GLOBAL_CACHE)
+  list(APPEND ceph_common_deps ceph_client_adaptor_plugin)
+endif()
+
 add_library(common STATIC ${ceph_common_objs})
 target_link_libraries(common ${ceph_common_deps})
 
@@ -560,6 +569,12 @@ add_subdirectory(dmclock)
 
 add_subdirectory(compressor)
 
+# Client adaptor
+if(WITH_GLOBAL_CACHE)
+message(STATUS "Client adaptor cmake executing...")
+add_subdirectory(client_adaptor)
+endif()
+
 add_subdirectory(tools)
 
 if(WITH_TESTS)
diff --git a/src/client_adaptor/CMakeLists.txt b/src/client_adaptor/CMakeLists.txt
new file mode 100644
index 00000000..75e0a7a3
--- /dev/null
+++ b/src/client_adaptor/CMakeLists.txt
@@ -0,0 +1,16 @@
+set(client_adaptor_srcs
+  ClientAdaptorMsg.cc
+  ClientAdaptorMgr.cc
+  ClientAdaptorPerf.cc
+  ClientAdaptorPlugin.cc
+)
+
+add_library(ceph_client_adaptor_plugin SHARED ${client_adaptor_srcs})
+message(STATUS "In cliend adaptor third part directory --> " ${third_part_dir})
+target_link_libraries(ceph_client_adaptor_plugin osdc agent_client_lib das)
+
+
+set(client_adaptor_dir ${CEPH_INSTALL_PKGLIBDIR})
+install(TARGETS ceph_client_adaptor_plugin DESTINATION ${client_adaptor_dir})
+
+message(STATUS "Global Cache  client-adaptor cmake executing...")
diff --git a/src/client_adaptor/ClientAdaptorMgr.cc b/src/client_adaptor/ClientAdaptorMgr.cc
new file mode 100644
index 00000000..9a4ed2ce
--- /dev/null
+++ b/src/client_adaptor/ClientAdaptorMgr.cc
@@ -0,0 +1,256 @@
+/* License:LGPL-2.1
+*
+* Copyright (c) 2021 Huawei Technologies Co., Ltd All rights reserved.
+*
+  */
+
+#include <iostream>
+#include "ClientAdaptorMgr.h"
+
+void ClientAdaptorMgr::set_init_flag(bool flag){
+  init_flag = flag;
+  return;
+}
+
+const bool ClientAdaptorMgr::is_init_succeed(){
+  if (init_flag){
+    return true;
+  } else {
+    return false;
+  }
+}
+
+int32_t CcmPtChangeNotify(PTViewPtEntry *entry, uint32_t entryNum, void *ctx)
+{
+  if (entryNum == 0) {
+      return RET_OK;
+  }
+  std::vector<uint32_t> normal_pt;
+  for (uint32_t i = 0; i < entryNum; i++) {
+      if (entry[i].state == CCM_PT_STATE_OK) {
+          normal_pt.push_back(entry[i].ptId);
+      }
+  }
+  if (normal_pt.size() == 0) {
+    return RET_OK;
+  }
+  Objecter *obj = static_cast<Objecter*>(ctx);
+  obj->retry_op_submit(normal_pt);
+  return RET_OK;
+}
+
+int32_t CcmNodeChangeNotify(int32_t clusterId, NodeInfo *nodeList, uint32_t nodeNum, void *ctx) {
+    if (nodeNum == 0) {
+        return RET_OK;
+    }
+    std::set<uint32_t> available_nodes;
+    for (uint32_t i = 0; i < nodeNum; i++) {
+        if (nodeList[i].state == NODE_STATE_UP) {
+            available_nodes.insert(nodeList[i].nodeId);
+        }
+    }
+    if (nodeNum - available_nodes.size() == 0) {
+        return RET_OK;
+    }
+    Objecter *obj = static_cast<Objecter *>(ctx);
+    obj->nodeview_change_retry_op_submit(clusterId, available_nodes);
+    return RET_OK;
+}
+
+void ClientAdaptorCcm::ccm_deregister(Objecter *obj)
+{
+    if (register_objs.count(obj) > 0) {
+        OpenDeregisterViewChangeNotifyChain(register_objs[obj]);
+        OpenDeregisterNodeViewChangeNotifyChain(register_node_change_objs[obj]);
+        delete register_objs[obj];
+        delete register_node_change_objs[obj];
+        register_objs.erase(obj);
+        register_node_change_objs.erase(obj);
+    }
+    if (register_objs.empty() && is_init_succeed()) {
+        set_init_flag(false);
+    }
+}
+
+bool ClientAdaptorCcm::ccm_callback_register(Objecter *obj)
+{
+    PTViewChangeOpHandle *ccmCallback = new PTViewChangeOpHandle();
+    NodeViewChangeOpHandle *ccmNodeChangeCallback = new NodeViewChangeOpHandle();
+    register_objs[obj] = ccmCallback;
+    register_node_change_objs[obj] = ccmNodeChangeCallback;
+    ccmCallback->notifyPtChange = CcmPtChangeNotify;
+    ccmNodeChangeCallback->notifyNodeChange = CcmNodeChangeNotify;
+    ccmCallback->ctx = (void *)obj;
+    ccmNodeChangeCallback->ctx = (void *)obj;
+    if (OpenRegisterViewChangeNotifyChain(ccmCallback) || OpenRegisterNodeViewChangeNotifyChain(ccmNodeChangeCallback)) {
+        std::cout << __func__ << " Client Adaptor: CCM agent register failed" << std::endl;
+        return false;
+    }
+    return true;
+}
+
+/*
+ * Init manager , failed to return !0
+ */
+int32_t ClientAdaptorCcm::init_mgr(Objecter *obj){
+  int32_t ret = 0;
+  // Already init
+  if (is_init_succeed()){
+    if (!ccm_callback_register(obj)) {
+        return RET_CCM_REGISTER_ERROR;
+    }
+    return RET_OK;
+  }
+
+  ret = OpenBcmInit();
+  if (ret != 0) {
+    std::cout << __func__ << "ccm agint init failed, ret=" << ret << std::endl;
+    return RET_CCM_AGENT_INIT_ERROR;
+  }
+
+  if (!ccm_callback_register(obj)) {
+      return RET_CCM_REGISTER_ERROR;
+  }
+  return RET_OK;
+}
+
+int32_t ClientAdaptorCcm::get_pt_num(int32_t clusterId, uint32_t& num){
+  num = OpenGetTotalPtNum(clusterId);
+  return RET_OK;
+}
+
+int32_t ClientAdaptorCcm::get_pt_entry(int32_t clusterId, uint32_t pt_index, PTViewPtEntry* entry){
+  if (OpenGetPtEntry(clusterId, pt_index, entry)){
+    std::cout << __func__ << " Client Adaptor: Get PT entry failed" << std::endl;
+    return RET_CCM_PT_ENTRY_ERROR;
+  }
+  return RET_OK;
+}
+
+int32_t ClientAdaptorCcm::get_node_info(int32_t clusterId, uint32_t node_id, NodeInfo* node_info){
+  using namespace std::chrono;
+  int32_t ret = 0;
+  seconds timeout {50 * 60};        // 50 minutes
+
+  steady_clock::time_point begin = steady_clock::now();
+  while (true) {
+      ret = OpenAgentGetNodeInfo(clusterId, node_id, node_info);
+      if (ret == 0) {
+          break;
+      }
+
+      steady_clock::time_point end = steady_clock::now();
+      seconds time_span = duration_cast<seconds>(end - begin);
+
+      if (time_span > timeout) {
+          std::cout << __func__ << " Client Adaptor: get node info failed because of timeout"
+                                << ", timeout=" << timeout << std::endl;
+          break;
+      }
+      sleep(1);
+  }
+  if (ret){
+    std::cout << __func__ << " Client Adaptor: Get node infomation failed" << std::endl;
+    return RET_CCM_NODE_INFO_ERROR;
+  }
+
+  return RET_OK;
+}
+
+bool ClientAdaptorCcm::get_pt_status(int32_t clusterId, uint32_t pt_id){
+  bool ret = true;
+  PTViewPtEntry pt_entry = { 0 };
+  if (get_pt_entry(clusterId, pt_id, &pt_entry)){
+    std::cout << __func__ << " Client Adaptor: Get PT entry failed" << std::endl;
+    return false;
+  }
+
+  if (pt_entry.state != CCM_PT_STATE_OK) {
+       return false;
+  }
+  return ret;
+}
+
+int32_t ClientAdaptorCcm::add_snap_to_gc(int64_t md_pool_id,
+                                         int64_t data_pool_id,
+                                         const std::string &image_id,
+                                         uint64_t snap_id) {
+    int32_t ret = OpenCreateSnapshot(md_pool_id, data_pool_id, image_id.c_str(), snap_id);
+    if (ret < 0) {
+        std::cout << __func__ << " Client Adaptor: Add to gc failed, snap_id=" << snap_id
+                 << " ret="<< ret << std::endl;
+        return ret;
+    }
+    return 0;
+}
+
+int32_t ClientAdaptorCcm::remove_snap_from_gc(int64_t data_pool_id,
+                                              const std::string &name_space,
+                                              const std::string &image_id,
+                                              uint64_t snap_id) {
+    int32_t ret = OpenDeleteSnapshot(data_pool_id, name_space.c_str(), image_id.c_str(), snap_id);
+    if (ret < 0) {
+        std::cout << __func__ << " Client Adaptor: Remove from gc failed, snap_name=" << data_pool_id << "/" << image_id
+                 << "@" << snap_id << " ret="<< ret << std::endl;
+        return ret;
+    }
+    return 0;
+}
+
+int32_t ClientAdaptorCcm::remove_gc_image_resource(int64_t data_pool_id, const std::string image_id) {
+    int32_t ret = OpenReleaseImageResource(data_pool_id, image_id.c_str());
+    if (ret < 0) {
+        std::cout << __func__ << " Client Adaptor: Remove image resource failed, image_id=" << image_id
+                              << " ret="<< ret << std::endl;
+        return ret;
+    }
+    return 0;
+}
+
+int32_t ClientAdaptorCcm::get_node_from_ma(const int64_t pool_id, int32_t *nodeId) {
+    return OpenAgentInit(pool_id, nodeId);
+}
+
+int32_t ClientAdaptorCcm::rollback_gc_snap(int64_t md_pool_id, int64_t data_pool_id,
+                                         const std::string image_id, uint64_t num_objs,
+                                         uint64_t snap_seq, uint64_t rb_snap_id,
+                                         uint64_t tp_snap_id1, uint64_t tp_snap_id2) {
+    RollbackInfo info;
+    info.mdPoolId = md_pool_id;
+    info.dataPoolId = data_pool_id;
+    info.imageId = image_id.c_str();
+    info.numObjs = num_objs;
+    info.snapId = rb_snap_id;
+    info.oldHeadSnapId = tp_snap_id1;
+    info.rollbackSnapId = tp_snap_id2;
+    info.snapSeq = snap_seq;
+    int ret = OpenRollbackSnapshot(&info);
+    if (ret < 0) {
+        std::cout << __func__ << " Client Adaptor: register rollback list failed, snap="
+                            << md_pool_id << "-" << data_pool_id << "/" << image_id
+                            << "@" << rb_snap_id << " ret="<< ret << std::endl;
+        return ret;
+    }
+    return 0;
+}
+
+int32_t ClientAdaptorCcm::gc_is_rollbacking(int64_t md_pool_id, int64_t data_pool_id, const std::string image_id)
+{
+    int ret = OpenImageBusy(data_pool_id, image_id.c_str());
+    if (ret < 0) {
+        std::cout << __func__ << " Client Adaptor: query gc rollbacking failed, image=" << md_pool_id
+                            << "(" << data_pool_id << ")/" << image_id << std::endl;
+    }
+    return ret;
+}
+
+int32_t ClientAdaptorCcm::gc_snap_is_rollbacking(int64_t data_pool_id, const std::string image_id,
+                                                int64_t snap_id)
+{
+    int ret = OpenSnapshotBusy(data_pool_id, image_id.c_str(), snap_id);
+    if (ret < 0) {
+        std::cout << __func__ << " Client Adaptor: query gc snap rollbacking failed, image=" << data_pool_id
+                            << "/" << image_id << "@" << snap_id << ", ret=" << ret << std::endl;
+    }
+    return ret;
+}
diff --git a/src/client_adaptor/ClientAdaptorMgr.h b/src/client_adaptor/ClientAdaptorMgr.h
new file mode 100644
index 00000000..6903a293
--- /dev/null
+++ b/src/client_adaptor/ClientAdaptorMgr.h
@@ -0,0 +1,189 @@
+/* License:LGPL-2.1
+*
+* Copyright (c) 2021 Huawei Technologies Co., Ltd All rights reserved.
+*
+  */
+
+#ifndef CLIENT_ADAPTOR_MGR_H
+#define CLIENT_ADAPTOR_MGR_H
+
+#include <string>
+#include <set>
+#include <osdc/Objecter.h>
+extern "C"
+{
+#include "open_ccm.h"
+}
+
+enum {
+   RET_OK = 0,
+   RET_PARAM_ERROR,
+   RET_CCM_PT_NUM_ERROR,
+   RET_CCM_PT_ENTRY_ERROR,
+   RET_CCM_NODE_INFO_ERROR,
+   RET_CCM_AGENT_INIT_ERROR,
+   RET_CONF_PARSER_ERROR,
+   RET_CCM_PORT_NUM_ERROR,
+   RET_CCM_IP_ERROR,
+   RET_CCM_REGISTER_ERROR,
+   RET_CCM_GET_NODE_ERROR,
+   RET_CCM_PARAM_ERROR
+};
+
+class ClientAdaptorMgr {
+public:
+  ClientAdaptorMgr(){}
+  virtual ~ClientAdaptorMgr(){}
+
+  virtual int32_t init_mgr(Objecter *obj) = 0;
+  
+  virtual int32_t get_pt_num(int32_t clusterId, uint32_t& num) = 0;
+
+  virtual int32_t get_pt_entry(int32_t clusterId, uint32_t pt_index, PTViewPtEntry* entry) = 0;
+
+  virtual int32_t get_node_info(int32_t clusterId, uint32_t node_id, NodeInfo* node_info) = 0;
+
+  virtual int32_t add_snap_to_gc(int64_t md_pool_id, int64_t data_pool_id, const std::string &image_id,
+                                uint64_t snap_id) = 0;
+
+  virtual int32_t remove_snap_from_gc(int64_t data_pool_id, const std::string &name_space,
+                                    const std::string &image_id, uint64_t snap_id) = 0;
+
+  virtual int32_t remove_gc_image_resource(const int64_t pool_id, const std::string image_id) = 0;
+
+  virtual int32_t get_node_from_ma(const int64_t pool_id, int32_t *nodeId) = 0;
+
+  virtual int32_t rollback_gc_snap(int64_t pool_id,  int64_t data_pool_id, const std::string image_id,
+                                    uint64_t num_objs, uint64_t snap_seq,
+                                    uint64_t rb_snap_id, uint64_t tp_snap_id1, uint64_t tp_snap_id2) = 0;
+
+  virtual int32_t gc_is_rollbacking(int64_t md_pool_id, 
+                                    int64_t data_pool_id, const std::string image_id) = 0;
+
+  virtual int32_t gc_snap_is_rollbacking(int64_t data_pool_id, const std::string image_id, int64_t snap_id) = 0;
+
+  virtual const std::string name(){
+    return "ClientAdaptorMgr";
+  }
+
+  const bool is_init_succeed();
+  
+  void set_init_flag(bool flag);
+
+  virtual bool get_pt_status(int32_t clusterid, uint32_t pt_id) = 0;
+  virtual void ccm_deregister(Objecter *obj) = 0;
+private:
+  bool init_flag = false;
+};
+
+class ClientAdaptorCcm : public ClientAdaptorMgr {
+public:
+  ClientAdaptorCcm(){}
+  ~ClientAdaptorCcm() override {}
+
+  int32_t init_mgr(Objecter *obj);
+
+  int32_t get_pt_num(int32_t clusterId, uint32_t& num);
+
+  int32_t get_pt_entry(int32_t clusterId, uint32_t pt_index, PTViewPtEntry* entry);
+
+  int32_t get_node_info(int32_t clusterId, uint32_t node_id, NodeInfo* node_info);
+
+  int32_t add_snap_to_gc(int64_t md_pool_id, int64_t data_pool_id, const std::string &image_id, uint64_t snap_id);
+
+  int32_t remove_snap_from_gc(int64_t data_pool_id, const std::string &name_space, 
+                            const std::string &image_id, uint64_t snap_id);
+
+  int32_t remove_gc_image_resource(const int64_t pool_id, const std::string image_id);
+
+  int32_t get_node_from_ma(const int64_t pool_id, int32_t *nodeId);
+
+  int32_t rollback_gc_snap(int64_t pool_id,  int64_t data_pool_id,
+                            const std::string image_id, uint64_t num_objs, uint64_t snap_seq,
+                            uint64_t rb_snap_id, uint64_t tp_snap_id1, uint64_t tp_snap_id2);
+
+  int32_t gc_is_rollbacking(int64_t md_pool_id, int64_t data_pool_id, const std::string image_id);
+
+  int32_t gc_snap_is_rollbacking(int64_t data_pool_id, const std::string image_id, int64_t snap_id);
+
+  const std::string name() override {
+    return "ClientAdaptorCcm";
+  }
+
+  bool get_pt_status(int32_t clusterid, uint32_t pt_id);
+  void ccm_deregister(Objecter *obj);
+
+private:
+  std::map<Objecter*,PTViewChangeOpHandle* > register_objs;
+  std::map<Objecter*,NodeViewChangeOpHandle* > register_node_change_objs;
+  bool ccm_callback_register(Objecter *obj);
+};
+
+class ClientAdaptorLocal : public ClientAdaptorMgr {
+public:
+  ClientAdaptorLocal(){}
+  ~ClientAdaptorLocal() override {}
+
+  int32_t init_mgr(Objecter *obj){
+    return 0;
+  }
+
+  int32_t get_pt_num(int32_t clusterId, uint32_t& num){
+    num = 10;
+    return 0;
+  }
+
+  int32_t get_pt_entry(int32_t clusterId, uint32_t pt_index, PTViewPtEntry* entry){
+    entry->curNodeInfo.nodeId = pt_index % 3;  // Assume 3 nodes in one cluster
+    return 0;
+  }
+
+  int32_t get_node_info(int32_t clusterId, uint32_t node_id, NodeInfo* node_info){
+    strcpy(node_info->publicAddrStr, "localhost");
+    node_info->ports[0] = 1234;
+    node_info->portNum = 1;
+    return 0;
+  }
+
+  int32_t add_snap_to_gc(int64_t md_pool_id, int64_t data_pool_id, const std::string &image_id, uint64_t snap_id) {
+    return 0;
+  }
+
+  int32_t remove_snap_from_gc(int64_t data_pool_id, const std::string &name_space,
+                            const std::string &image_id, uint64_t snap_id) {
+    return 0;
+  }
+
+  int32_t remove_gc_image_resource(const int64_t pool_id, const std::string image_id) {
+      return 0;
+  }
+  int32_t get_node_from_ma(const int64_t pool_id, int32_t *nodeId) { 
+    return 0;
+  }
+  int32_t rollback_gc_snap(int64_t pool_id, int64_t data_pool_id,
+                            const std::string image_id, uint64_t num_objs, uint64_t snap_seq,
+                            uint64_t rb_snap_id, uint64_t tp_snap_id1, uint64_t tp_snap_id2) {
+      return 0;
+  }
+
+  int32_t gc_is_rollbacking(int64_t md_pool_id, int64_t data_pool_id, const std::string image_id) {
+      return 0;
+  }
+
+  int32_t gc_snap_is_rollbacking(int64_t data_pool_id, const std::string image_id, int64_t snap_id) {
+      return 0;
+  }
+
+  const std::string name() override {
+    return "ClientAdaptorLocal";
+  }
+  bool get_pt_status(int32_t clusterid, uint32_t pt_id) {
+    return true;
+  }
+  void ccm_deregister(Objecter *obj) {}
+
+private:
+};
+
+
+#endif
diff --git a/src/client_adaptor/ClientAdaptorMsg.cc b/src/client_adaptor/ClientAdaptorMsg.cc
new file mode 100644
index 00000000..b431167f
--- /dev/null
+++ b/src/client_adaptor/ClientAdaptorMsg.cc
@@ -0,0 +1,363 @@
+/* License:LGPL-2.1
+*
+* Copyright (c) 2021 Huawei Technologies Co., Ltd All rights reserved.
+*
+  */
+
+#include <iostream>
+#include <regex>
+#include <bits/stdc++.h>
+#include "ClientAdaptorMsg.h"
+#include "ClientAdaptorMgr.h"
+
+namespace {
+const int RBD_DATA_OBJECT_NAME_FILTER_LEN = 8;  // rbd_data(8 bits)
+const int RBD_DATA_OBJECT_NAME_LEN = 27;   // rbd_data(8 bits).image_id(n bits).object_index(16 bits)
+const string RBD_DATA_OBJECT_NAME = "rbd_data";
+const int RGW_BUCKET_ID_LEN = 36;   // bucket_id(36 bits)
+const int RGW_OBJECT_NAME_LEN = 38;     // bucket_id(36 bits)_Object_Name(n bits)
+const uint64_t SEGMENT_SIZE = 4194304;
+const uint64_t SEGMENT_MASK = 0x3FFFFF;
+const int OBJECT_ID_LEN = 16;
+const int GC_PORT_MIN = 7880;
+const int GC_PORT_MAX = 7889;
+const string GC_SNAP_PREFIX = "gc_";
+}
+
+ClientAdaptorMsg::ClientAdaptorMsg(ClientAdaptorMgr* mgr) : mgr_ref(mgr){
+}
+
+void ClientAdaptorMsg::push_strategy(Objecter *objecter, uint64_t pool_id, int32_t node_id, std::string oid_name, bufferlist &indata)
+{
+    if (objecter == NULL){
+        std::cout << __func__ << " objecter null " << std::endl;
+        return;
+    }
+    if (oid_name.size() == 0){
+        std::cout << __func__ << " oid_name size 0 " << std::endl;
+        return;
+    }
+    if ( node_id < 0){
+        std::cout << __func__ << " node id < 0 " << std::endl;
+        return;
+    }
+    const char *cls = "rpc";
+    const char *method = "das_prefetch";
+    vector<OSDOp> nops(1);
+    OSDOp &op = nops[0];
+    op.op.op = CEPH_OSD_OP_CALL;
+    op.op.cls.class_len = strlen(cls);
+    op.op.cls.method_len = strlen(method);
+    op.op.cls.indata_len = indata.length();
+    op.indata.append(cls, op.op.cls.class_len);
+    op.indata.append(method, op.op.cls.method_len);
+    op.indata.append(indata);
+    Objecter::Op *objecter_op =
+        new Objecter::Op(object_t(oid_name), object_locator_t(), nops, CEPH_OSD_FLAG_EXEC, NULL, NULL, NULL, nullptr);
+    objecter_op->target.osd = node_id;
+    objecter_op->target.base_oloc.pool = pool_id;
+    objecter_op->target.base_oid.name = oid_name;
+    objecter_op->target.flags = CEPH_OSD_FLAG_READ | CEPH_OSD_FLAG_WRITE;
+
+    objecter->op_submit(objecter_op);
+}
+
+/**
+ * Maximum string length of the RBD block object name prefix (not including
+ * null termination).
+ *
+ * v1 format: rb.<max 8-byte high id>.<max 8-byte low id>.<max 8-byte extra>
+ * v2 format: rbd_data.[<max 19-byte pool id>.]<max 14-byte image id>
+ *
+ * Note: new features might require increasing this maximum prefix length.
+ */
+bool ClientAdaptorMsg::filter_msg(Objecter::op_target_t *t){
+  string obj_name = t->base_oid.name;
+  if (obj_name.size() < RBD_DATA_OBJECT_NAME_LEN) {
+    return false;
+  }
+
+  if (obj_name.compare(0, RBD_DATA_OBJECT_NAME_FILTER_LEN, RBD_DATA_OBJECT_NAME) == 0){
+    return true;
+  }
+  
+  return false;
+}
+
+bool ClientAdaptorMsg::filter_msg_by_op(Objecter::Op *op){
+  return filter_msg(&op->target);
+}
+
+
+bool ClientAdaptorMsg::is_node(uint32_t index){
+  if (index >> FLAG_OFFSET_BIT){
+    return true;
+  }
+  return false;
+}
+
+/*
+ * Hash to get node id. Failed to return !0
+ */
+int32_t ClientAdaptorMsg::get_node_id(int32_t clusterId, string obj_name, int64_t pool_id, uint32_t& pt_id){
+  if (obj_name.length() == 0 ){
+    std::cout << __func__ << " Client Adaptor: input parameter invalid!" << std::endl; 
+    return -RET_CCM_PARAM_ERROR;
+  }
+
+  // Hash obj_name+pool_name to hashed id
+  string obj_id = to_string(pool_id);
+  obj_id += '_';
+  obj_id += obj_name;
+  hash<string> hash_str;
+  uint32_t obj_hashed_id = hash_str(obj_id);
+
+  // Calculate node id
+  uint32_t pt_num = 0;
+  NodeInfo info = {0};
+
+  if (mgr_ref->get_pt_num(clusterId, pt_num)){
+    std::cout << __func__ << " Client Adaptor: Get PT number failed" << std::endl;
+    return -RET_CCM_PT_NUM_ERROR;
+  }
+
+  if (pt_num == 0) {
+    std::cout << __func__ << " Client Adaptor: Get PT number zero" << std::endl;
+    return -RET_CCM_PT_NUM_ERROR;
+  }
+
+  pt_id = obj_hashed_id % pt_num;
+
+  PTViewPtEntry pt_entry = {0};
+  if (mgr_ref->get_pt_entry(clusterId, pt_id, &pt_entry)){
+    std::cout << __func__ << " Client Adaptor: Get PT entry failed" << std::endl;
+    return -RET_CCM_PT_ENTRY_ERROR;
+  }
+  uint32_t node_id = pt_entry.curNodeInfo.nodeId << NODE_ID_OFFSET_BIT;
+  node_id += 0x1 << FLAG_OFFSET_BIT;
+  node_id += clusterId << CLUSTER_ID_OFFSET;
+
+  if (mgr_ref->get_node_info(clusterId, pt_entry.curNodeInfo.nodeId, &info)){
+    std::cout << __func__ << " Client Adaptor: Get node info failed. node id " << pt_entry.curNodeInfo.nodeId << std::endl;
+    return -RET_CCM_NODE_INFO_ERROR;
+  }
+  if (info.portNum > PORT_SUPPORT_MAX || info.portNum == 0) {
+    std::cout << __func__ << " Client Adaptor: Port number invalid. Port Number: " << info.portNum << std::endl;
+    return -RET_CCM_PORT_NUM_ERROR;
+  }
+  uint32_t pt_index = pt_entry.indexInNode;
+
+  // port index encode in OSD
+  node_id += pt_index % info.portNum;
+
+  return node_id;
+}
+
+bool ClientAdaptorMsg::valid_ip(string ip_addr)
+{
+  string regStr = "^((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]\\d|[1-9])"\
+
+                  "(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]\\d|\\d)){3})|(0.0.0.0)$";
+  regex regIp(regStr);
+  bool matchValue = regex_match(ip_addr, regIp);
+  return matchValue;
+}
+
+string ClientAdaptorMsg::gc_snap_prefix()
+{
+    return GC_SNAP_PREFIX;
+}
+
+bool ClientAdaptorMsg::is_gc_snap(string snap_name)
+{
+    int n = snap_name.find(GC_SNAP_PREFIX);
+    if (n == 0) {
+        return true;
+    }
+    return false;
+}
+
+void ClientAdaptorMsg::gen_random_gc_snap(uint64_t snap_id, int num, string &rd_snap_name)
+{
+    std::chrono::system_clock::time_point now = std::chrono::system_clock::now();
+    std::chrono::microseconds ms = std::chrono::duration_cast<std::chrono::microseconds>(now.time_since_epoch());
+    long timepoint = ms.count();
+    std::mt19937 generator{std::random_device{}()};
+    std::uniform_int_distribution<uint32_t> distribution{0, 0xFFFF};
+    uint32_t extra = distribution(generator);
+    rd_snap_name.clear();
+    rd_snap_name.append(GC_SNAP_PREFIX);
+    rd_snap_name.append(to_string(extra));
+    rd_snap_name.append("_");
+    rd_snap_name.append(to_string(snap_id));
+    rd_snap_name.append("_");
+    rd_snap_name.append(to_string(num));
+    rd_snap_name.append("_");
+    rd_snap_name.append(to_string(timepoint));
+}
+
+/*
+ * Get node ip from MA. Failed to return !0
+ */
+int32_t ClientAdaptorMsg::get_node_ip(int32_t clusterId, uint32_t node_index, string& node_ip){
+  uint32_t node_id = (node_index & NODE_ID_MASK) >> NODE_ID_OFFSET_BIT;
+  uint32_t port_index = node_index & PORT_INDEX_MASK;
+  NodeInfo info = {0};
+  if (mgr_ref->get_node_info(clusterId, node_id, &info)){
+    std::cout << __func__ << " Client Adaptor: Get node info failed." << std::endl;
+    return RET_CCM_NODE_INFO_ERROR;
+  }
+  uint32_t port = info.ports[port_index];
+  if (port < GC_PORT_MIN || port > GC_PORT_MAX) {
+     return RET_CCM_PORT_NUM_ERROR;
+  }
+
+  string server_ip = info.publicAddrStr;
+
+  if (!valid_ip(server_ip)) {
+    return RET_CCM_IP_ERROR;
+  }
+
+  string addr_str = "tcp://";
+  addr_str += server_ip;
+  addr_str += ":";
+  addr_str += to_string(port);
+  node_ip = addr_str;
+  return RET_OK;
+}
+
+int32_t ClientAdaptorMsg::get_node_raw_ip(int32_t clusterId, uint32_t node_index, string& node_ip) {
+    uint32_t node_id = (node_index & NODE_ID_MASK) >> NODE_ID_OFFSET_BIT;
+    uint32_t port_index = node_index & PORT_INDEX_MASK;
+    NodeInfo info = {0};
+    if (mgr_ref->get_node_info(clusterId, node_id, &info)){
+        std::cout << __func__ << " Client Adaptor: Get node info failed." << std::endl;
+        return RET_CCM_NODE_INFO_ERROR;
+    }
+    uint32_t port = info.ports[port_index];
+    if (port < GC_PORT_MIN || port > GC_PORT_MAX) {
+        return RET_CCM_PORT_NUM_ERROR;
+    }
+
+    node_ip = info.publicAddrStr;
+
+    if (!valid_ip(node_ip)) {
+        return RET_CCM_IP_ERROR;
+    }
+
+    return RET_OK;
+}
+
+void ClientAdaptorMsg::set_mgr(ClientAdaptorMgr* mgr){
+  mgr_ref = mgr;
+  return;
+}
+
+ClientAdaptorMgr* ClientAdaptorMsg::get_mgr(){
+  return mgr_ref;
+}
+
+void das_req_prefetch(DasKvParam *params)
+{
+    if (params == NULL) {
+        return;
+    }
+    ClientAdaptorMsg *msg_ref = static_cast<ClientAdaptorMsg *>(params->handle);
+    Objecter *obj = static_cast<Objecter *>(params->ctx);
+    if (msg_ref->is_valid_object(obj) == false) {
+        return;
+    }
+    uint64_t offset = params->offset & SEGMENT_MASK;
+    int id = params->objId;
+    uint64_t left = params->len;
+    while (left) {
+        uint64_t max = std::min<uint64_t>(SEGMENT_SIZE - offset, left);
+
+        char buff[params->imageIdLen+OBJECT_ID_LEN + 1];
+        snprintf(buff, params->imageIdLen + 1, "%s", params->imageIdBuf);
+        snprintf(buff+params->imageIdLen, OBJECT_ID_LEN+1, "%016x", id);
+        std::string oid_name(buff);
+        uint32_t pt_id;
+        int64_t pool_id = params->cephPoolId;
+        int32_t node_id = msg_ref->get_node_id(params->clusterId, oid_name, pool_id, pt_id);
+        if (node_id < 0) {
+            ceph_abort();
+        }
+        bufferlist indata;
+        encode(offset, indata);
+        encode(max, indata);
+        msg_ref->push_strategy(obj, params->cephPoolId, node_id, oid_name, indata);
+
+        left -= max;
+        offset = 0;
+        id++;
+    };
+}
+
+int32_t ClientAdaptorMsg::das_init(Objecter *obj)
+{
+    int32_t rc;
+    das_objs.insert(obj);
+    if (initialized)
+      return 0;
+    DasModuleParam *dasInstanceParam = new DasModuleParam();
+    DasOPS *regOps = new DasOPS();
+    regOps->SubmitDasPrefetch = das_req_prefetch;
+    dasInstanceParam->ops = regOps;
+
+    rc = OpenRcacheCeateDasModule(this, dasInstanceParam);
+    if (rc) {
+        return -1;
+    }
+    initialized = true;
+    return 0;
+}
+
+int32_t ClientAdaptorMsg::das_update_info(int32_t clusterId, Objecter *obj, Objecter::Op *op)
+{
+    if (!initialized)
+      return 0;
+    DasKvParam *params[op->ops.size()];
+
+    if ((op->target.flags & CEPH_OSD_FLAG_WRITE) == CEPH_OSD_FLAG_WRITE)
+        return 0;
+    string obj_name = op->target.base_oid.name;
+    if (obj_name.compare(0, RBD_DATA_OBJECT_NAME_FILTER_LEN, RBD_DATA_OBJECT_NAME))
+      return 0;
+    std::size_t found = obj_name.find_last_of('.');
+    if (found == std::string::npos)
+      return -EINVAL;
+    uint64_t objId = std::stol(obj_name.substr(found+1, OBJECT_ID_LEN), nullptr, 16);
+    uint64_t ns = ceph_clock_now().to_nsec();
+    int i = 0;
+    for (vector<OSDOp>::iterator p = op->ops.begin(); p != op->ops.end(); ++p) {
+        if (p->op.op == CEPH_OSD_OP_READ || p->op.op == CEPH_OSD_OP_SPARSE_READ || p->op.op == CEPH_OSD_OP_SYNC_READ) {
+            params[i] = reinterpret_cast<DasKvParam*>(new char[sizeof(DasKvParam) + found + 1]);
+            params[i]->offset = p->op.extent.offset;
+            params[i]->len = p->op.extent.length;
+            params[i]->opcode = 0;
+            params[i]->timeStamp = ns;
+            params[i]->cephPoolId = op->target.base_oloc.pool;
+            params[i]->algType = DAS_ALG_SEQ;
+            params[i]->objId = objId;
+            params[i]->imageIdLen = found + 1;
+            params[i]->clusterId = clusterId;
+            memcpy(params[i]->imageIdBuf, obj_name.c_str(), params[i]->imageIdLen);
+            params[i]->handle = this;
+            params[i]->ctx = obj;
+            i++;
+        }
+    }
+
+    if (i) {
+      int rc = OpenRcachePutDasInfo(params, i);
+      if (rc)
+        return -1;
+    }
+    return 0;
+}
+
+int32_t ClientAdaptorMsg::get_node_pool(const int64_t pool_id, int32_t *nodeId)
+{
+    return mgr_ref->get_node_from_ma(pool_id, nodeId);
+}
diff --git a/src/client_adaptor/ClientAdaptorMsg.h b/src/client_adaptor/ClientAdaptorMsg.h
new file mode 100644
index 00000000..f367dd2a
--- /dev/null
+++ b/src/client_adaptor/ClientAdaptorMsg.h
@@ -0,0 +1,87 @@
+/* License:LGPL-2.1
+*
+* Copyright (c) 2021 Huawei Technologies Co., Ltd All rights reserved.
+*
+  */
+
+#ifndef CLIENT_ADAPTOR_MSG_H
+#define CLIENT_ADAPTOR_MSG_H
+
+#include <string>
+#include <map>
+#include <stdint.h>
+#include "open_das.h"
+
+#include "osdc/Objecter.h"
+#include "ClientAdaptorMgr.h"
+
+class ClientAdaptorMsg {
+public:
+  ClientAdaptorMsg(ClientAdaptorMgr* mgr);
+  ~ClientAdaptorMsg() {};
+
+  void push_strategy(Objecter *objecter, uint64_t pool_id, int32_t node_id, std::string oid_name, bufferlist &indata);
+
+  int32_t das_init(Objecter *obj);
+
+  void das_remove(Objecter *obj) {
+    das_objs.erase(obj);
+    if (das_objs.empty() && initialized) {
+      initialized = false;
+      OpenRcacheExitDasModule(this);
+    }
+  }
+
+  bool filter_msg(Objecter::op_target_t *t);
+
+  bool filter_msg_by_op(Objecter::Op *op);
+  
+  const string name() {return "ClientAdaptorMsg";}
+
+  bool is_node(uint32_t index);
+
+  int32_t get_node_id(int32_t clusterId, string obj_name, int64_t pool_id, uint32_t& pt_index);
+
+  int32_t get_node_ip(int32_t clusterId, uint32_t node_index, string& node_ip);
+
+  int32_t get_node_raw_ip(int32_t clusterId, uint32_t node_index, string& node_ip);
+
+  void set_mgr(ClientAdaptorMgr* mgr);
+
+  ClientAdaptorMgr* get_mgr(void);
+
+  bool is_valid_object(Objecter *obj) {
+    auto it = das_objs.find(obj);
+    if (it != das_objs.end())
+        return true;
+    return false;
+  }
+
+  int32_t das_update_info(int32_t clusterId, Objecter *obj, Objecter::Op *op);
+
+  int32_t get_node_pool(const int64_t pool_id, int32_t *nodeId);
+
+  string gc_snap_prefix();
+  bool is_gc_snap(string snap_name);
+  void gen_random_gc_snap(uint64_t snap_id, int num, string &rd_snap_name);
+
+protected:
+  ClientAdaptorMgr* mgr_ref;
+  // FLAG:20 (true means global cache node) Node ID:4~15  PORT INDEX ID:0~3
+  const int FLAG_OFFSET_BIT = 20;
+  const int CLUSTER_ID_OFFSET = 16;
+  const int PORT_INDEX_MASK = 0xf;
+  const int NODE_ID_OFFSET_BIT = 4;
+  const int NODE_ID_MASK = 0xfff0;
+  const int PORT_SUPPORT_MAX = 16;
+private:
+  bool initialized = false;
+  std::set<Objecter *> das_objs;
+  bool valid_ip(string ip_addr);
+public:
+  std::unordered_set<void *> connections;
+  mutable std::shared_mutex connlock;
+};
+
+
+#endif
diff --git a/src/client_adaptor/ClientAdaptorPerf.cc b/src/client_adaptor/ClientAdaptorPerf.cc
new file mode 100644
index 00000000..90f5e1e6
--- /dev/null
+++ b/src/client_adaptor/ClientAdaptorPerf.cc
@@ -0,0 +1,85 @@
+/* License:LGPL-2.1
+*
+* Copyright (c) 2021 Huawei Technologies Co., Ltd All rights reserved.
+*
+  */
+
+#include "ClientAdaptorPerf.h"
+#include "ClientAdaptorPlugin.h"
+using namespace std;
+
+#include <sys/syscall.h>
+#define gettid() syscall(__NR_gettid)
+
+void ClientAdaptorPerf::start_tick(Objecter::Op *op) {
+  gettimeofday(&(op->perf_tick.start), NULL);
+  return;
+}
+
+void ClientAdaptorPerf::end_tick(Objecter::Op *op) {
+  gettimeofday(&(op->perf_tick.end), NULL);
+  return;
+}
+
+void ClientAdaptorPerf::record_op(Objecter::Op *op) {
+  for (vector<OSDOp>::iterator p = op->ops.begin(); p != op->ops.end(); ++p) {
+      if (p->op.op == CEPH_OSD_OP_READ || p->op.op == CEPH_OSD_OP_SPARSE_READ || p->op.op == CEPH_OSD_OP_SYNC_READ) {
+        read.op_count++;
+        read.time_cost += (op->perf_tick.end.tv_sec - op->perf_tick.start.tv_sec) * 1000 * 1000 + \
+               (op->perf_tick.end.tv_usec - op->perf_tick.start.tv_usec);
+      } else if (p->op.op == CEPH_OSD_OP_WRITE || p->op.op == CEPH_OSD_OP_WRITEFULL) {
+        write.op_count++;
+        write.time_cost += (op->perf_tick.end.tv_sec - op->perf_tick.start.tv_sec) * 1000 * 1000 + \
+               (op->perf_tick.end.tv_usec - op->perf_tick.start.tv_usec);
+      }
+  }
+  return;
+}
+
+std::function<void ()> ClientAdaptorPerf::create_thread(const ClientAdaptorPlugin* in) {
+  const ClientAdaptorPlugin* plugin = in;
+  return [this, plugin](){
+    char thread_name[16];
+    sprintf(thread_name, "ca-perf-tick");
+    pthread_setname_np(pthread_self(), thread_name);
+    uint64_t read_cnt = 0;
+    uint64_t read_cost = 0;
+    uint64_t write_cnt = 0;
+    uint64_t write_cost = 0;
+    uint64_t read_lat = 0xff;
+    uint64_t write_lat = 0xff;
+    float avg_flight = 0;
+
+    while (!tick_done) {
+      sleep(3);
+      read_cnt = plugin->perf_ref->read.op_count;
+      read_cost = plugin->perf_ref->read.time_cost;
+      write_cnt = plugin->perf_ref->write.op_count;
+      write_cost = plugin->perf_ref->write.time_cost;
+      if (read_cnt != 0) {
+        read_lat = read_cost/read_cnt;
+      }
+      if (write_cnt != 0) {
+        write_lat = write_cost/write_cnt;
+      }
+      if ((read_cnt + write_cnt) != 0) {
+        avg_flight = (float)total_in_flight / (float)(read_cnt + write_cnt);
+      }
+      outfile << "*************************************************************************" << std::endl;
+      outfile << "PID: " << getpid() << "    TID: " << gettid() << std::endl;
+      outfile << "          total_count     avg_latency(us)" << std::endl;
+      outfile << "read " << setw(16) << read_cnt << "    " << setw(16) << read_lat << std::endl;
+      outfile << "write" << setw(16) << write_cnt << "    " << setw(16) << write_lat << std::endl;
+      outfile << "          total_count             average" << std::endl;
+      outfile << "in-flight" << setw(12) << total_in_flight
+           << "    " << setw(16) << fixed << setprecision(1) << avg_flight << std::endl;
+    }
+  };
+}
+
+void ClientAdaptorPerf::start_record(ClientAdaptorPlugin* plugin) {
+  std::function<void ()> perf_thread = create_thread(plugin);
+  threads.push_back(std::thread(perf_thread));
+  outfile.open("/var/log/ceph/perf_tick.log", ios::out | ios::app);
+  return;
+}
diff --git a/src/client_adaptor/ClientAdaptorPerf.h b/src/client_adaptor/ClientAdaptorPerf.h
new file mode 100644
index 00000000..f57b2074
--- /dev/null
+++ b/src/client_adaptor/ClientAdaptorPerf.h
@@ -0,0 +1,55 @@
+/* License:LGPL-2.1
+*
+* Copyright (c) 2021 Huawei Technologies Co., Ltd All rights reserved.
+*
+  */
+
+#ifndef CLIENT_ADAPTOR_PERF_H
+#define CLIENT_ADAPTOR_PERF_H
+
+#include <stdint.h>
+#include <sys/time.h>
+#include <thread>
+#include <iomanip>
+#include <sched.h>
+#include <vector>
+#include <iostream>
+#include <fstream>
+
+#include "osdc/Objecter.h"
+
+class ClientAdaptorPlugin;
+
+class ClientAdaptorPerf {
+public:
+  ClientAdaptorPerf(){}
+  ~ClientAdaptorPerf(){}
+  // friend class ClientAdaptorPlugin;
+  
+  struct op_perf_t {
+    std::atomic<uint64_t> op_count{0};
+    std::atomic<uint64_t> time_cost{0};
+  };
+
+  void start_tick(Objecter::Op *op);
+
+  void end_tick(Objecter::Op *op);
+
+  void record_op(Objecter::Op *op);
+
+  void start_record(ClientAdaptorPlugin* plugin);
+
+  std::function<void ()> create_thread(const ClientAdaptorPlugin* plugin);
+
+  const string name() {return "ClientAdaptorPerf";}
+  vector<std::thread> threads;
+  bool tick_done{false};
+  std::ofstream outfile;
+  std::atomic<uint64_t> total_in_flight{0};
+private:
+  struct op_perf_t read;
+  struct op_perf_t write;
+
+};
+
+#endif
diff --git a/src/client_adaptor/ClientAdaptorPlugin.cc b/src/client_adaptor/ClientAdaptorPlugin.cc
new file mode 100644
index 00000000..88365c25
--- /dev/null
+++ b/src/client_adaptor/ClientAdaptorPlugin.cc
@@ -0,0 +1,45 @@
+/* License:LGPL-2.1
+*
+* Copyright (c) 2021 Huawei Technologies Co., Ltd All rights reserved.
+*
+  */
+
+#include <iostream>
+#include "ClientAdaptorPlugin.h"
+#include "ceph_ver.h"
+#include "ClientAdaptorMsg.h"
+#include "ClientAdaptorMgr.h"
+#include "ClientAdaptorPerf.h"
+
+
+
+
+ClientAdaptorPlugin::~ClientAdaptorPlugin() {
+    delete mgr_ref;
+    delete msg_ref;
+    delete perf_ref;
+}
+
+const char *__ceph_plugin_version()
+{
+  return CEPH_GIT_NICE_VER;
+}
+
+// plugin load时调用的初始化函数
+int __ceph_plugin_init(CephContext *cct,
+                       const std::string& type,
+                       const std::string& name)
+{
+  PluginRegistry *instance = cct->get_plugin_registry();
+  if (cct->_conf.get_val<bool>("global_cache_debug_mode")){
+    ClientAdaptorLocal* ccm = new ClientAdaptorLocal();
+    ClientAdaptorMsg* msg = new ClientAdaptorMsg(ccm);
+    ClientAdaptorPerf* perf = new ClientAdaptorPerf();
+    return instance->add(type, name, new ClientAdaptorPlugin(cct, msg, ccm, perf));
+  } else {
+    ClientAdaptorCcm* ccm = new ClientAdaptorCcm();
+    ClientAdaptorMsg* msg = new ClientAdaptorMsg(ccm);
+    ClientAdaptorPerf* perf = new ClientAdaptorPerf();
+    return instance->add(type, name, new ClientAdaptorPlugin(cct, msg, ccm, perf));
+  }
+}
diff --git a/src/client_adaptor/ClientAdaptorPlugin.h b/src/client_adaptor/ClientAdaptorPlugin.h
new file mode 100644
index 00000000..3509005f
--- /dev/null
+++ b/src/client_adaptor/ClientAdaptorPlugin.h
@@ -0,0 +1,39 @@
+/* License:LGPL-2.1
+*
+* Copyright (c) 2021 Huawei Technologies Co., Ltd All rights reserved.
+*
+  */
+
+#ifndef CLIENT_ADAPTOR_PLUGIN_H
+#define CLIENT_ADAPTOR_PLUGIN_H
+#include <unistd.h>
+
+//#include "ceph_ver.h"
+#include "common/PluginRegistry.h"
+#include "common/ceph_context.h"
+//#include "acconfig.h"
+
+
+class ClientAdaptorMsg;
+class ClientAdaptorMgr;
+class ClientAdaptorPerf;
+
+class ClientAdaptorPlugin : public Plugin {
+public:
+  ClientAdaptorPlugin(CephContext* cct, ClientAdaptorMsg* msg, ClientAdaptorMgr* mgr, 
+      ClientAdaptorPerf* perf) : Plugin(cct), msg_ref(msg), mgr_ref(mgr), perf_ref(perf)
+  {
+  }
+
+  ~ClientAdaptorPlugin();
+
+  ClientAdaptorMsg* msg_ref;
+  ClientAdaptorMgr* mgr_ref;
+  ClientAdaptorPerf* perf_ref; 
+
+  const string name(){
+    return "ClientAdaptorPlugin";
+  }
+};
+
+#endif
diff --git a/src/client_adaptor/open_ccm.h b/src/client_adaptor/open_ccm.h
new file mode 100644
index 00000000..db87f7d1
--- /dev/null
+++ b/src/client_adaptor/open_ccm.h
@@ -0,0 +1,248 @@
+/*
+Copyright (c) 2021 Huawei Technologies Co., Ltd All rights reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+*/
+#ifndef __CCM_INTERFACE_H__
+#define __CCM_INTERFACE_H__
+
+#include <stdint.h>
+#include <stdbool.h>
+#include <time.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#define PT_VIEW_NODE_MAX_DOMAIN     32
+#define PT_VIEW_MAX_POOL            256
+#define MAX_CCM_CTRL_NODE_NUM       128             /* 管理节点数量 */
+
+#define MAX_PT_ENTRY        1024                    /* PT最大数量 */
+
+#define MAX_SERVER_NUM      MAX_CCM_CTRL_NODE_NUM   /* 节点最大数量 */
+
+#define CCM_MAX_DISK_NUM    1024                    /* 最大磁盘数量 */
+#define CCM_VNODE_NUM_PER_NODE 8                    /* 每个节点上最大的VNODE数量 */
+#define MAX_DISK_NUM_PER_NODE 16                    /* 每个节点上最大的磁盘数量 */
+#define IP_ADDR_LEN         (16)                    /* IP地址长度 */
+#define DISK_NAME_LEN       (64)                    /* 磁盘名长度 */
+#define DISK_SN_LEN         (64)                    /* 磁盘SN长度 */
+
+#define MAX_POOL_NAME_LEN   (256)                   /* POOLName的最大长度 */
+#define CCM_MAX_POOL_NUM    (4096)                  /* POOL的数量限制 */
+#define MAX_PORT_NUM        (8)                     /* 每个节点支持的对外监听接口数 */
+
+#define ZK_IP_ADDR_LEN      (16)
+#define ZK_DISK_NAME_LEN    (64)
+#define ZK_DISK_SN_LEN      (64)
+#define MAX_CLUSTER_NETWROK_NUM 4
+
+// Upgrade embedding
+#define CCM_VERSION_0 0
+#define CCM_VERSION_1 1
+#define CCM_CURRENT_VERSION CCM_VERSION_0
+#define CCM_Upgrade_Embedding_LEN 64
+
+/* Ndoe & Disk Info */
+typedef enum {
+    NODE_STATE_INVALID  = 0,
+    NODE_STATE_UP       = 1,
+    NODE_STATE_STARTING = 2,
+    NODE_STATE_RUNNING  = 3,
+    NODE_STATE_UNWORK   = 4,
+    NODE_STATE_DOWN     = 5,
+    NODE_STATE_BUTT
+} NodeState;
+
+typedef enum {
+    VDISK_STATE_DOWN = 0,
+    VDISK_STATE_UP   = 1,
+    VIDSK_STATE_BUTT
+} VdiskState;
+
+typedef struct {
+    uint32_t NodeId;
+    uint32_t ptNum;
+    uint32_t (*ptMap)[2];
+} NodePtInfo;
+
+typedef struct {
+    uint32_t nodeId;
+    uint32_t diskId;
+    uint32_t localDiskId;
+    char diskName[DISK_NAME_LEN];
+    char sn[DISK_SN_LEN];
+    uint32_t capacity;
+    uint32_t usedCap;
+    VdiskState state;
+    VdiskState inOutState;      /* 磁盘的IN OUT状态 */
+    bool isFirstFormat;
+} VdiskInfo;
+
+typedef struct {
+    uint32_t rackId;
+    uint32_t nodeId;
+    NodeState state;
+    uint32_t ipv4addr;
+    char ipv4AddrStr[IP_ADDR_LEN];      /* 用于管理的IP地址,与zookeeper通信使用的IP地址 */
+    char publicAddrStr[IP_ADDR_LEN];    /* 前端IO使用的IP地址，即Client与ServerAdaptor一起使用的地址 */
+    char clusterAddrStr[MAX_CLUSTER_NETWROK_NUM][IP_ADDR_LEN]; /* 后端集群通信IP地址，即Plog 3副本之间使用的IP地址 */
+    uint32_t clusterIpNum;              /* 后端集群的个数 */
+    int32_t  portNum;                   /* 有效的端口数量 */
+    uint32_t ports[MAX_PORT_NUM];       /* port */
+    uint32_t diskNum;                   /* 磁盘数量 */
+    VdiskInfo diskList[MAX_DISK_NUM_PER_NODE];  /* 磁盘列表 */
+    uint64_t version;                           /* 版本号 */
+    NodeState inOutState;               /* 节点的IN OUT状态 */
+    NodeState runningState;             /* 节点的开工状态 */
+} NodeInfo;
+
+typedef enum {
+    CCM_PT_STATE_INIT = 0,
+    CCM_PT_STATE_OK,                // OK状态
+    CCM_PT_STATE_TRIM,              // 迁出状态
+    CCM_PT_STATE_REPLAY,            // 迁入状态
+    CCM_PT_STATE_FAULT,             // 失败状态
+} PtState;
+
+typedef struct {
+    uint32_t nodeId;
+    uint32_t diskId;
+    uint32_t vnodeId;
+} PtNodeInfo;
+
+typedef struct {
+    uint32_t version;
+    bool ptChange;
+    uint32_t birthVersion;
+    uint32_t ptId;                  // PTID
+    uint32_t indexInNode;           // pt在Node内部编号
+    PtState  state;                 // pt状态
+    PtNodeInfo curNodeInfo;         // 当前所在节点信息
+    PtNodeInfo srcNodeInfo;         // 初始节点信息
+    char reserved[CCM_Upgrade_Embedding_LEN];
+} PtInfo;
+
+typedef struct _PtView {
+    uint32_t version;
+    uint32_t globalVersion;
+    uint32_t ptNum;
+    char reserved[CCM_Upgrade_Embedding_LEN];
+    PtInfo  ptInfo[0];
+} PtView;
+
+typedef PtInfo PTViewPtEntry;
+
+/* NodeView变更通知回调函数 */
+typedef struct {
+    void *ctx;
+    int32_t (*notifyNodeChange)(int32_t clusterId, NodeInfo *nodeList, uint32_t nodeNum, void *ctx);
+} NodeViewChangeOpHandle;
+
+/* PTView变更通知回调函数 */
+typedef struct {
+    void *ctx;
+    int32_t (*notifyPtChange)(PTViewPtEntry *entry, uint32_t entryNum, void *ctx);
+} PTViewChangeOpHandle;
+
+typedef enum {
+    CCM_MODULE_INFRAS = 0,
+    CCM_MODULE_PLOG,
+    CCM_MODULE_INDEX,
+    CCM_MODULE_CACHE,
+    CCM_MODULE_CLIENT,
+    CCM_MODULE_CEPH,
+    CCM_MODULE_BUTT,
+} ModuleType;
+
+typedef struct {
+    int64_t mdPoolId;
+    int64_t dataPoolId;
+    const char *imageId;
+    uint64_t numObjs;
+    uint64_t snapId;
+    uint64_t oldHeadSnapId;
+    uint64_t rollbackSnapId;
+    uint64_t snapSeq;
+} RollbackInfo;
+
+int32_t OpenAgentInit(int64_t poolId, int32_t *nodeId);
+
+int32_t OpenBcmInit(void);
+
+int32_t OpenGetPtEntry(int32_t clusterId, uint32_t ptId, PTViewPtEntry *entry);
+
+/* 
+ * 功能描述：获取总的PT的数量
+ * 参数说明：无参数
+ * 返回值：返回总的PT的数量
+ */
+uint32_t OpenGetTotalPtNum(int32_t clusterId);
+
+/*
+ * 功能描述：Agent模块获取某个指定的节点的NodeInfo信息
+ * 参数说明：nodeId: {in}, 节点编号
+ *          nodeInfo: {out}, NodeInfo结构体指针
+ * 返回值：0表示成功，非0表示失败
+ */
+int32_t OpenAgentGetNodeInfo(int32_t clusterId, uint32_t nodeId, NodeInfo *nodeInfo);
+
+/*
+ * 功能描述：注册PTview更新通知与回调函数
+ * 参数说明：handle: {in}, PTView更新回调函数，在PTView更之后，则会调用该回调函数
+ * 返回值：0表示成功，非0表示失败
+ */
+int32_t OpenRegisterViewChangeNotifyChain(PTViewChangeOpHandle *handle);
+
+/*
+ * 功能描述：注册NodeView更新通知与回调函数
+ * 参数说明：handle: {in}, NodeView更新回调函数，在NodeView变更之后，则会调用该回调函数
+ * 返回值：0表示成功，非0表示失败
+ */
+int32_t OpenRegisterNodeViewChangeNotifyChain(NodeViewChangeOpHandle *handle);
+
+void OpenDeregisterViewChangeNotifyChain(PTViewChangeOpHandle *handle);
+
+void OpenDeregisterNodeViewChangeNotifyChain(NodeViewChangeOpHandle *handle);
+
+/*
+ * 功能描述：创建快照视图
+ * 参数说明：poolId: {in}, pool的id
+             imageId: {in}, image的id
+             SnapId: {in}, snapshot的id
+ * 返回值：0表示成功，非0表示失败
+ */
+int32_t OpenCreateSnapshot(int64_t mdPoolId, int64_t dataPoolId, const char *imageId, uint64_t snapId);
+/*
+ * 功能描述：删除快照视图
+ * 参数说明：poolId: {in}, pool的id
+             imageId: {in}, image的id
+             SnapId: {in}, snapshot的id
+ * 返回值：0表示成功，非0表示失败
+ */
+int32_t OpenDeleteSnapshot(int64_t dataPoolId, const char *nameSpace, const char *imageId, uint64_t snapId);
+
+int32_t OpenReleaseImageResource(int64_t poolId, const char *imageId);
+
+int32_t OpenRollbackSnapshot(RollbackInfo *info);
+
+int32_t OpenImageBusy(int64_t dataPoolId, const char *imageId);
+
+int32_t OpenSnapshotBusy(int64_t dataPoolId, const char *imageId, int64_t snapId);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif
diff --git a/src/client_adaptor/open_das.h b/src/client_adaptor/open_das.h
new file mode 100755
index 00000000..77e42672
--- /dev/null
+++ b/src/client_adaptor/open_das.h
@@ -0,0 +1,70 @@
+/*
+Copyright (c) 2021 Huawei Technologies Co., Ltd All rights reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+*/
+#ifndef OPEN_DAS_H
+#define OPEN_DAS_H
+
+#include <cstdio>
+#include <cstdint>
+#include <cstdlib>
+#include <string>
+
+typedef enum EnumDasResult {
+    RETURN_DAS_FULL = -2,
+    RETURN_DAS_ERROR = -1,
+    RETURN_DAS_OK = 0,
+    RETURN_DAS_EMPTY = 1,
+    RETURN_DAS_DELETING = 2,
+}DAS_RESULT;
+
+typedef enum TagDasAlgType {
+    DAS_ALG_SEQ = 0,
+    DAS_ALG_REVERSE_SEQ,
+    DAS_ALG_STRIDE,
+    DAS_ALG_BUTT,
+} DasAlgType;
+
+typedef struct TagDasKvParam {
+    uint64_t offset;     /* offset by byte  */
+    uint64_t len;        /* io length by byte  */
+    uint8_t opcode;      /* kv opcode  0:read/1:write/ */
+    uint64_t timeStamp;  /* timestamp for test. NS */
+    int64_t cephPoolId; /* ceph pool id */
+    DasAlgType algType;  /* 入参时填0 */
+    uint64_t objId;
+    uint32_t imageIdLen;
+    int32_t clusterId;
+    void* ctx;           /* client adaptor 上下文 */
+    void* handle;
+    char imageIdBuf[0];
+} DasKvParam;
+
+
+typedef struct TagDasOPS {
+    void (*SubmitDasPrefetch)(DasKvParam* params); // 同步接口
+} DasOPS;
+
+/* Param to create DAS */
+typedef struct TagDasModuleParam {
+    DasOPS *ops; // client adaptor注册
+} DasModuleParam;
+
+
+int32_t OpenRcacheCeateDasModule(void* handle, DasModuleParam *createInstanceParam);
+
+int32_t OpenRcachePutDasInfo(DasKvParam *params[], uint32_t keyNum);
+
+void OpenRcacheExitDasModule(void* handle);
+#endif
diff --git a/src/common/PluginRegistry.cc b/src/common/PluginRegistry.cc
index 2cb7fcee..59707481 100644
--- a/src/common/PluginRegistry.cc
+++ b/src/common/PluginRegistry.cc
@@ -70,8 +70,11 @@ int PluginRegistry::remove(const std::string& type, const std::string& name)
   std::map<std::string,Plugin*>::iterator j = i->second.find(name);
   if (j == i->second.end())
     return -ENOENT;
-
+#ifdef WITH_GLOBAL_CACHE
+  ldout(cct, 5) << __func__ << " " << type << " " << name << dendl;
+#else
   ldout(cct, 1) << __func__ << " " << type << " " << name << dendl;
+#endif
   void *library = j->second->library;
   delete j->second;
   dlclose(library);
@@ -91,8 +94,13 @@ int PluginRegistry::add(const std::string& type,
       plugins[type].count(name)) {
     return -EEXIST;
   }
+#ifdef WITH_GLOBAL_CACHE
+  ldout(cct, 5) << __func__ << " " << type << " " << name
+        << " " << plugin << dendl;
+#else
   ldout(cct, 1) << __func__ << " " << type << " " << name
 		<< " " << plugin << dendl;
+#endif
   plugins[type][name] = plugin;
   return 0;
 }
@@ -127,8 +135,13 @@ Plugin *PluginRegistry::get(const std::string& type,
   ret = j->second;
 
  out:
+#ifdef WITH_GLOBAL_CACHE
+  ldout(cct, 5) << __func__ << " " << type << " " << name
+        << " = " << ret << dendl;
+#else
   ldout(cct, 1) << __func__ << " " << type << " " << name
 		<< " = " << ret << dendl;
+#endif
   return ret;
 }
 
@@ -136,7 +149,11 @@ int PluginRegistry::load(const std::string &type,
 			 const std::string &name)
 {
   ceph_assert(ceph_mutex_is_locked(lock));
+#ifdef WITH_GLOBAL_CACHE
+  ldout(cct, 5) << __func__ << " " << type << " " << name << dendl;
+#else
   ldout(cct, 1) << __func__ << " " << type << " " << name << dendl;
+#endif
 
   // std::string fname = cct->_conf->plugin_dir + "/" + type + "/" PLUGIN_PREFIX
   //  + name + PLUGIN_SUFFIX;
@@ -206,9 +223,15 @@ int PluginRegistry::load(const std::string &type,
   }
 
   plugin->library = library;
-
+#ifdef WITH_GLOBAL_CACHE
+  ldout(cct, 5) << __func__ << ": " << type << " " << name
+        << " loaded and registered" << dendl;
+#else
   ldout(cct, 1) << __func__ << ": " << type << " " << name
 		<< " loaded and registered" << dendl;
+#endif
+
+
   return 0;
 }
 
diff --git a/src/common/options.cc b/src/common/options.cc
index 8135ea8f..9d3bb781 100644
--- a/src/common/options.cc
+++ b/src/common/options.cc
@@ -1015,7 +1015,7 @@ std::vector<Option> get_global_options() {
     .set_description("Induce a crash/exit on various bugs (for testing purposes)"),
 
     Option("ms_dispatch_throttle_bytes", Option::TYPE_SIZE, Option::LEVEL_ADVANCED)
-    .set_default(100_M)
+    .set_default(2048_M)
     .set_description("Limit messages that are read off the network but still being processed"),
 
     Option("ms_bind_ipv4", Option::TYPE_BOOL, Option::LEVEL_ADVANCED)
@@ -2308,6 +2308,15 @@ std::vector<Option> get_global_options() {
     .set_default(10.0)
     .set_description("Seconds before in-flight op is considered 'laggy' and we query mon for the latest OSDMap"),
 
+#ifdef WITH_GLOBAL_CACHE
+    Option("objecter_inflight_op_bytes", Option::TYPE_SIZE, Option::LEVEL_ADVANCED)
+    .set_default(0)
+    .set_description("Max in-flight data in bytes (both directions)"),
+
+    Option("objecter_inflight_ops", Option::TYPE_UINT, Option::LEVEL_ADVANCED)
+    .set_default(0)
+    .set_description("Max in-flight operations"),
+#else
     Option("objecter_inflight_op_bytes", Option::TYPE_SIZE, Option::LEVEL_ADVANCED)
     .set_default(100_M)
     .set_description("Max in-flight data in bytes (both directions)"),
@@ -2315,6 +2324,7 @@ std::vector<Option> get_global_options() {
     Option("objecter_inflight_ops", Option::TYPE_UINT, Option::LEVEL_ADVANCED)
     .set_default(1024)
     .set_description("Max in-flight operations"),
+#endif
 
     Option("objecter_completion_locks_per_session", Option::TYPE_UINT, Option::LEVEL_DEV)
     .set_default(32)
@@ -5587,6 +5597,14 @@ std::vector<Option> get_global_options() {
     Option("debug_heartbeat_testing_span", Option::TYPE_INT, Option::LEVEL_DEV)
     .set_default(0)
     .set_description("Override 60 second periods for testing only"),
+#ifdef WITH_GLOBAL_CACHE
+    Option("global_cache_debug_mode", Option::TYPE_BOOL, Option::LEVEL_DEV)
+    .set_default(false)
+    .set_description("Global Cache client adaptor local debug mode switch"),
+    Option("global_cache_tick", Option::TYPE_BOOL, Option::LEVEL_DEV)
+    .set_default(false)
+    .set_description("Global Cache client adaptor performance tick switch"),
+#endif
   });
 }
 
@@ -7222,11 +7240,15 @@ static std::vector<Option> get_rbd_options() {
     Option("rbd_non_blocking_aio", Option::TYPE_BOOL, Option::LEVEL_ADVANCED)
     .set_default(true)
     .set_description("process AIO ops from a dispatch thread to prevent blocking"),
-
+#ifdef WITH_GLOBAL_CACHE
+    Option("rbd_cache", Option::TYPE_BOOL, Option::LEVEL_ADVANCED)
+    .set_default(false)
+    .set_description("whether to enable caching (writeback unless rbd_cache_max_dirty is 0)"),
+#else
     Option("rbd_cache", Option::TYPE_BOOL, Option::LEVEL_ADVANCED)
     .set_default(true)
     .set_description("whether to enable caching (writeback unless rbd_cache_max_dirty is 0)"),
-
+#endif
     Option("rbd_cache_writethrough_until_flush", Option::TYPE_BOOL, Option::LEVEL_ADVANCED)
     .set_default(true)
     .set_description("whether to make writeback caching writethrough until "
@@ -7537,6 +7559,15 @@ static std::vector<Option> get_rbd_options() {
     .set_default(60)
     .set_min(0)
     .set_description("RBD Image access timestamp refresh interval. Set to 0 to disable access timestamp update."),
+#ifdef WITH_GLOBAL_CACHE
+    Option("global_cache", Option::TYPE_BOOL, Option::LEVEL_ADVANCED)
+    .set_default(true)
+    .set_description("whether to enable global cache"),
+
+    Option("gc_perf", Option::TYPE_BOOL, Option::LEVEL_ADVANCED)
+    .set_default(true)
+    .set_description("whether to enable global cache perf"),
+#endif
   });
 }
 
diff --git a/src/crush/CrushWrapper.h b/src/crush/CrushWrapper.h
index 9dffe69c..136ad538 100644
--- a/src/crush/CrushWrapper.h
+++ b/src/crush/CrushWrapper.h
@@ -1321,6 +1321,7 @@ public:
       crush->max_devices = name_map.rbegin()->first + 1;
     }
     have_uniform_rules = !has_legacy_rule_ids();
+    build_rmaps();
   }
   int bucket_set_alg(int id, int alg);
 
diff --git a/src/include/config-h.in.cmake b/src/include/config-h.in.cmake
index d83a59b2..12dfdf5e 100644
--- a/src/include/config-h.in.cmake
+++ b/src/include/config-h.in.cmake
@@ -187,6 +187,9 @@
 /* Define if you want to use Babeltrace */
 #cmakedefine WITH_BABELTRACE
 
+/* Define if you want to use Global Cache */
+#cmakedefine WITH_GLOBAL_CACHE
+
 /* Define to 1 if you have the <babeltrace/babeltrace.h> header file. */
 #cmakedefine HAVE_BABELTRACE_BABELTRACE_H 1
 
diff --git a/src/include/rados/librados.hpp b/src/include/rados/librados.hpp
index 0c047c43..2b0ce9f2 100644
--- a/src/include/rados/librados.hpp
+++ b/src/include/rados/librados.hpp
@@ -1247,6 +1247,9 @@ inline namespace v14_2_0 {
     std::string get_namespace() const;
 
     int64_t get_id();
+#ifdef WITH_GLOBAL_CACHE
+    uint64_t get_snap_seq();
+#endif
 
     // deprecated versions
     uint32_t get_object_hash_position(const std::string& oid)
@@ -1276,6 +1279,11 @@ inline namespace v14_2_0 {
                                     const std::string &key);
     int application_metadata_list(const std::string& app_name,
                                   std::map<std::string, std::string> *values);
+#ifdef WITH_GLOBAL_CACHE
+    bool check_acc();
+    int32_t get_cluster_id();
+
+#endif
 
   private:
     /* You can only get IoCtx instances from Rados */
diff --git a/src/include/rbd/librbd.h b/src/include/rbd/librbd.h
index 83b5735c..88742861 100644
--- a/src/include/rbd/librbd.h
+++ b/src/include/rbd/librbd.h
@@ -934,6 +934,16 @@ CEPH_RBD_API int64_t rbd_read_iterate(rbd_image_t image, uint64_t ofs, size_t le
 CEPH_RBD_API int rbd_read_iterate2(rbd_image_t image, uint64_t ofs, uint64_t len,
 		                   int (*cb)(uint64_t, size_t, const char *, void *),
                                    void *arg);
+#ifdef WITH_GLOBAL_CACHE
+CEPH_RBD_API void rbd_get_date_dts_addr(rbd_image_t image, uint64_t offset, uint64_t *objOffset,
+                    char *objAddr, uint32_t *objId);
+
+CEPH_RBD_API int rbd_client_image_read(rbd_image_t image, uint32_t objId, uint32_t objOffset,
+                    char* buf, size_t len);
+
+CEPH_RBD_API int rbd_client_image_aio_read(rbd_image_t image, uint32_t objId, uint32_t objOffset,
+                char *buf, size_t len, rbd_completion_t c);
+#endif
 /**
  * get difference between two versions of an image
  *
diff --git a/src/include/rbd/librbd.hpp b/src/include/rbd/librbd.hpp
index 15eb9f56..10e82f41 100644
--- a/src/include/rbd/librbd.hpp
+++ b/src/include/rbd/librbd.hpp
@@ -542,6 +542,14 @@ public:
 		       int (*cb)(uint64_t, size_t, const char *, void *), void *arg);
   int read_iterate2(uint64_t ofs, uint64_t len,
 		    int (*cb)(uint64_t, size_t, const char *, void *), void *arg);
+
+  int get_data_dst_addr(uint64_t off, uint64_t *obj_offset,
+                        char *obj_addr, uint32_t *obj_id);
+
+  ssize_t client_image_read(uint32_t objId, uint32_t objOffset,
+                            char* buf, size_t len);
+  ssize_t client_image_aio_read(uint32_t objId, uint32_t objOffset,
+                            char* buf, size_t len, RBD::AioCompletion *c);
   /**
    * get difference between two versions of an image
    *
@@ -621,7 +629,6 @@ public:
    * @returns 0 on success, negative error code on failure
    */
   int aio_flush(RBD::AioCompletion *c);
-
   /**
    * Drop any cached data for this image
    *
diff --git a/src/librados/RadosClient.cc b/src/librados/RadosClient.cc
index 902c2c66..aeb15fa1 100644
--- a/src/librados/RadosClient.cc
+++ b/src/librados/RadosClient.cc
@@ -52,6 +52,11 @@
 #include "include/ceph_assert.h"
 #include "common/EventTrace.h"
 
+#ifdef WITH_GLOBAL_CACHE
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMsg.h"
+#endif
+
 #define dout_subsys ceph_subsys_rados
 #undef dout_prefix
 #define dout_prefix *_dout << "librados: "
@@ -495,7 +500,23 @@ int librados::RadosClient::create_ioctx(const char *name, IoCtxImpl **io)
   if (poolid < 0) {
     return (int)poolid;
   }
-
+#ifdef WITH_GLOBAL_CACHE
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ceph_assert(plugin);
+  int32_t node_pool =  -1;
+  int32_t ret = plugin->msg_ref->get_node_pool(poolid, &node_pool);
+  if (ret != 0) {
+    lderr(cct) << __func__ << " get node pool from ma failed" << dendl;
+    return -EHOSTUNREACH;
+  }
+  if (node_pool <= 4 && node_pool >= 1) {
+    ldout(cct, 10) << __func__ << " poolid " << poolid << " belong to node " << node_pool << " is acc pool" << dendl;
+    objecter->set_acc_pool_set(poolid, node_pool);
+  } else {
+    ldout(cct, 10) << __func__ << " poolid " << poolid << " is nor pool" << dendl;
+  }
+#endif
   *io = new librados::IoCtxImpl(this, objecter, poolid, CEPH_NOSNAP);
   return 0;
 }
@@ -506,6 +527,24 @@ int librados::RadosClient::create_ioctx(int64_t pool_id, IoCtxImpl **io)
   int r = pool_get_name(pool_id, &pool_name, true);
   if (r < 0)
     return r;
+
+#ifdef WITH_GLOBAL_CACHE
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ceph_assert(plugin);
+  int32_t node_pool =  -1;
+  int32_t ret  = plugin->msg_ref->get_node_pool(pool_id, &node_pool);
+  if (ret != 0) {
+    lderr(cct) << __func__ << " get node pool from ma failed" << dendl;
+    return -EHOSTUNREACH;
+  }
+  if (node_pool <= 4 && node_pool >=1) {
+    ldout(cct, 10) << __func__ << " poolid " << pool_id << " belong to node " << node_pool << " is acc pool" << dendl;
+    objecter->set_acc_pool_set(pool_id, node_pool);
+  } else {
+    ldout(cct, 10) << __func__ << " poolid " << pool_id <<  " is nor pool" << dendl;
+  }
+#endif
   *io = new librados::IoCtxImpl(this, objecter, pool_id, CEPH_NOSNAP);
   return 0;
 }
diff --git a/src/librados/librados_cxx.cc b/src/librados/librados_cxx.cc
index bc3f65f2..69f02520 100644
--- a/src/librados/librados_cxx.cc
+++ b/src/librados/librados_cxx.cc
@@ -2976,3 +2976,18 @@ int librados::IoCtx::application_metadata_list(const std::string& app_name,
 {
   return io_ctx_impl->application_metadata_list(app_name, values);
 }
+
+#ifdef WITH_GLOBAL_CACHE
+bool librados::IoCtx::check_acc()
+{
+  int64_t poolid = io_ctx_impl->get_id();
+  return io_ctx_impl->objecter->get_acc_pool_set(poolid);
+}
+
+int32_t librados::IoCtx::get_cluster_id()
+{
+  int64_t poolid = io_ctx_impl->get_id();
+  return io_ctx_impl->objecter->get_cluster_id(poolid);
+}
+
+#endif
diff --git a/src/librbd/DeepCopyRequest.cc b/src/librbd/DeepCopyRequest.cc
index 1d56b255..e1454372 100644
--- a/src/librbd/DeepCopyRequest.cc
+++ b/src/librbd/DeepCopyRequest.cc
@@ -296,7 +296,7 @@ void DeepCopyRequest<I>::handle_refresh_object_map(int r) {
     RWLock::WLocker object_map_locker(m_dst_image_ctx->object_map_lock);
     std::swap(m_dst_image_ctx->object_map, m_object_map);
   }
-  delete m_object_map;
+  m_object_map->put();
 
   send_copy_metadata();
 }
diff --git a/src/librbd/ExclusiveLock.cc b/src/librbd/ExclusiveLock.cc
index 4db3f29a..48db3e23 100644
--- a/src/librbd/ExclusiveLock.cc
+++ b/src/librbd/ExclusiveLock.cc
@@ -21,13 +21,15 @@
 namespace librbd {
 
 using namespace exclusive_lock;
+using librbd::util::create_context_callback;
 
 template <typename I>
 using ML = ManagedLock<I>;
 
 template <typename I>
 ExclusiveLock<I>::ExclusiveLock(I &image_ctx)
-  : ML<I>(image_ctx.md_ctx, image_ctx.op_work_queue, image_ctx.header_oid,
+  : RefCountedObject(image_ctx.cct),
+    ML<I>(image_ctx.md_ctx, image_ctx.op_work_queue, image_ctx.header_oid,
           image_ctx.image_watcher, managed_lock::EXCLUSIVE,
           image_ctx.config.template get_val<bool>("rbd_blacklist_on_break_lock"),
           image_ctx.config.template get_val<uint64_t>("rbd_blacklist_expire_seconds")),
@@ -105,6 +107,9 @@ int ExclusiveLock<I>::get_unlocked_op_error() const {
 template <typename I>
 void ExclusiveLock<I>::init(uint64_t features, Context *on_init) {
   ceph_assert(m_image_ctx.owner_lock.is_locked());
+
+  on_init = create_context_callback<Context>(on_init, this);
+
   ldout(m_image_ctx.cct, 10) << dendl;
 
   {
@@ -120,6 +125,8 @@ template <typename I>
 void ExclusiveLock<I>::shut_down(Context *on_shut_down) {
   ldout(m_image_ctx.cct, 10) << dendl;
 
+  on_shut_down = create_context_callback<Context>(on_shut_down, this);
+
   ML<I>::shut_down(on_shut_down);
 
   // if stalled in request state machine -- abort
diff --git a/src/librbd/ExclusiveLock.h b/src/librbd/ExclusiveLock.h
index 824cb00d..23c4518b 100644
--- a/src/librbd/ExclusiveLock.h
+++ b/src/librbd/ExclusiveLock.h
@@ -7,11 +7,13 @@
 #include "common/AsyncOpTracker.h"
 #include "librbd/ManagedLock.h"
 #include "librbd/exclusive_lock/Policy.h"
+#include "common/RefCountedObj.h"
 
 namespace librbd {
 
 template <typename ImageCtxT = ImageCtx>
-class ExclusiveLock : public ManagedLock<ImageCtxT> {
+class ExclusiveLock : public RefCountedObject,
+                      public ManagedLock<ImageCtxT> {
 public:
   static ExclusiveLock *create(ImageCtxT &image_ctx) {
     return new ExclusiveLock<ImageCtxT>(image_ctx);
diff --git a/src/librbd/ImageCtx.cc b/src/librbd/ImageCtx.cc
index 8375d1a6..02b20a9a 100644
--- a/src/librbd/ImageCtx.cc
+++ b/src/librbd/ImageCtx.cc
@@ -60,7 +60,7 @@ public:
   ContextWQ *op_work_queue;
 
   explicit ThreadPoolSingleton(CephContext *cct)
-    : ThreadPool(cct, "librbd::thread_pool", "tp_librbd", 1,
+    : ThreadPool(cct, "librbd::thread_pool", "tp_librbd", cct->_conf.get_val<uint64_t>("rbd_op_threads"),
                  "rbd_op_threads"),
       op_work_queue(new ContextWQ("librbd::op_work_queue",
                                   cct->_conf.get_val<uint64_t>("rbd_op_thread_timeout"),
@@ -270,6 +270,18 @@ public:
                         "wb", perf_prio, unit_t(UNIT_BYTES));
     plb.add_time_avg(l_librbd_wr_latency, "wr_latency", "Write latency",
                      "wl", perf_prio);
+#ifdef WITH_GLOBAL_CACHE
+    plb.add_time_avg(l_librbd_rd_before_queue_op_lat, "rd_before_queue_latency", "before queue latency",
+                     "rbql", perf_prio);
+    plb.add_time_avg(l_librbd_wr_before_queue_op_lat, "wr_before_queue_latency", "before queue latency",
+                     "wbql", perf_prio);
+    plb.add_time_avg(l_librbd_after_dequeue_op_lat, "after_dequeue_latency", "after dequeue latency",
+                     "adl", perf_prio);
+    plb.add_time_avg(l_librbd_send_lat, "send_latency", "send latency",
+                     "send", perf_prio);
+    plb.add_u64(l_librbd_rd_queue, "rqueue", "q", "q", PerfCountersBuilder::PRIO_USEFUL);
+    plb.add_u64(l_librbd_wr_queue, "wqueue", "q", "q", PerfCountersBuilder::PRIO_USEFUL);
+#endif
     plb.add_u64_counter(l_librbd_discard, "discard", "Discards");
     plb.add_u64_counter(l_librbd_discard_bytes, "discard_bytes", "Discarded data", NULL, 0, unit_t(UNIT_BYTES));
     plb.add_time_avg(l_librbd_discard_latency, "discard_latency", "Discard latency");
@@ -778,9 +790,7 @@ public:
 
     bool skip_partial_discard = true;
     ASSIGN_OPTION(non_blocking_aio, bool);
-    ASSIGN_OPTION(cache, bool);
     ASSIGN_OPTION(cache_writethrough_until_flush, bool);
-    ASSIGN_OPTION(cache_max_dirty, Option::size_t);
     ASSIGN_OPTION(sparse_read_threshold_bytes, Option::size_t);
     ASSIGN_OPTION(readahead_max_bytes, Option::size_t);
     ASSIGN_OPTION(readahead_disable_after_bytes, Option::size_t);
diff --git a/src/librbd/ImageCtx.h b/src/librbd/ImageCtx.h
index df5271e8..2e8d7f0c 100644
--- a/src/librbd/ImageCtx.h
+++ b/src/librbd/ImageCtx.h
@@ -174,9 +174,9 @@ namespace librbd {
 
     /// Cached latency-sensitive configuration settings
     bool non_blocking_aio;
-    bool cache;
+    bool cache = false; // bypass rbd cache feature
     bool cache_writethrough_until_flush;
-    uint64_t cache_max_dirty;
+    uint64_t cache_max_dirty = 0;
     uint64_t sparse_read_threshold_bytes;
     uint64_t readahead_max_bytes;
     uint64_t readahead_disable_after_bytes;
diff --git a/src/librbd/Journal.cc b/src/librbd/Journal.cc
index 1be60cbf..115a167d 100644
--- a/src/librbd/Journal.cc
+++ b/src/librbd/Journal.cc
@@ -3,6 +3,7 @@
 
 #include "librbd/Journal.h"
 #include "include/rados/librados.hpp"
+#include "common/AsyncOpTracker.h"
 #include "common/errno.h"
 #include "common/Timer.h"
 #include "common/WorkQueue.h"
@@ -12,7 +13,6 @@
 #include "journal/ReplayEntry.h"
 #include "journal/Settings.h"
 #include "journal/Utils.h"
-#include "librbd/ExclusiveLock.h"
 #include "librbd/ImageCtx.h"
 #include "librbd/io/ImageRequestWQ.h"
 #include "librbd/io/ObjectDispatchSpec.h"
@@ -326,7 +326,8 @@ std::ostream &operator<<(std::ostream &os,
 
 template <typename I>
 Journal<I>::Journal(I &image_ctx)
-  : m_image_ctx(image_ctx), m_journaler(NULL),
+  : RefCountedObject(image_ctx.cct),
+    m_image_ctx(image_ctx), m_journaler(NULL),
     m_lock("Journal<I>::m_lock"), m_state(STATE_UNINITIALIZED),
     m_error_result(0), m_replay_handler(this), m_close_pending(false),
     m_event_lock("Journal<I>::m_event_lock"), m_event_tid(0),
@@ -352,6 +353,7 @@ Journal<I>::~Journal() {
     delete m_work_queue;
   }
 
+  std::lock_guard locker{m_lock};
   ceph_assert(m_state == STATE_UNINITIALIZED || m_state == STATE_CLOSED);
   ceph_assert(m_journaler == NULL);
   ceph_assert(m_journal_replay == NULL);
@@ -564,6 +566,8 @@ void Journal<I>::open(Context *on_finish) {
   CephContext *cct = m_image_ctx.cct;
   ldout(cct, 20) << this << " " << __func__ << dendl;
 
+  on_finish = create_context_callback<Context>(on_finish, this);
+
   on_finish = create_async_context_callback(m_image_ctx, on_finish);
 
   // inject our handler into the object dispatcher chain
@@ -581,6 +585,8 @@ void Journal<I>::close(Context *on_finish) {
   CephContext *cct = m_image_ctx.cct;
   ldout(cct, 20) << this << " " << __func__ << dendl;
 
+  on_finish = create_context_callback<Context>(on_finish, this);
+
   on_finish = new FunctionContext([this, on_finish](int r) {
       // remove our handler from object dispatcher chain - preserve error
       auto ctx = new FunctionContext([on_finish, r](int _) {
@@ -958,6 +964,8 @@ void Journal<I>::flush_event(uint64_t tid, Context *on_safe) {
   ldout(cct, 20) << this << " " << __func__ << ": tid=" << tid << ", "
                  << "on_safe=" << on_safe << dendl;
 
+  on_safe = create_context_callback<Context>(on_safe, this);
+
   Future future;
   {
     Mutex::Locker event_locker(m_event_lock);
@@ -975,6 +983,8 @@ void Journal<I>::wait_event(uint64_t tid, Context *on_safe) {
   ldout(cct, 20) << this << " " << __func__ << ": tid=" << tid << ", "
                  << "on_safe=" << on_safe << dendl;
 
+  on_safe = create_context_callback<Context>(on_safe, this);
+
   Mutex::Locker event_locker(m_event_lock);
   wait_event(m_lock, tid, on_safe);
 }
@@ -1128,7 +1138,8 @@ void Journal<I>::destroy_journaler(int r) {
       Mutex::Locker locker(m_lock);
       m_journaler->shut_down(ctx);
     });
-  m_async_journal_op_tracker.wait(m_image_ctx, ctx);
+  ctx = create_async_context_callback(m_image_ctx, ctx);
+  m_async_journal_op_tracker.wait_for_ops(ctx);
 }
 
 template <typename I>
@@ -1248,6 +1259,8 @@ void Journal<I>::handle_replay_ready() {
     m_processing_entry = true;
   }
 
+  m_async_journal_op_tracker.start_op();
+
   bufferlist data = replay_entry.get_data();
   auto it = data.cbegin();
 
@@ -1309,6 +1322,10 @@ void Journal<I>::handle_replay_complete(int r) {
       // ensure the commit position is flushed to disk
       m_journaler->flush_commit_position(ctx);
     });
+  ctx = create_async_context_callback(m_image_ctx, ctx);
+  ctx = new FunctionContext([this, ctx](int r) {
+      m_async_journal_op_tracker.wait_for_ops(ctx);
+    });
   ctx = new FunctionContext([this, cct, cancel_ops, ctx](int r) {
       ldout(cct, 20) << this << " handle_replay_complete: "
                      << "shut down replay" << dendl;
@@ -1372,11 +1389,13 @@ void Journal<I>::handle_replay_process_safe(ReplayEntry replay_entry, int r) {
           m_journal_replay->shut_down(true, ctx);
         });
       m_journaler->stop_replay(ctx);
+      m_async_journal_op_tracker.finish_op();
       return;
     } else if (m_state == STATE_FLUSHING_REPLAY) {
       // end-of-replay flush in-progress -- we need to restart replay
       transition_state(STATE_FLUSHING_RESTART, r);
       m_lock.Unlock();
+      m_async_journal_op_tracker.finish_op();
       return;
     }
   } else {
@@ -1384,6 +1403,7 @@ void Journal<I>::handle_replay_process_safe(ReplayEntry replay_entry, int r) {
     m_journaler->committed(replay_entry);
   }
   m_lock.Unlock();
+  m_async_journal_op_tracker.finish_op();
 }
 
 template <typename I>
@@ -1643,14 +1663,14 @@ int Journal<I>::check_resync_requested(bool *do_resync) {
 }
 
 struct C_RefreshTags : public Context {
-  util::AsyncOpTracker &async_op_tracker;
+  AsyncOpTracker &async_op_tracker;
   Context *on_finish = nullptr;
 
   Mutex lock;
   uint64_t tag_tid = 0;
   journal::TagData tag_data;
 
-  explicit C_RefreshTags(util::AsyncOpTracker &async_op_tracker)
+  explicit C_RefreshTags(AsyncOpTracker &async_op_tracker)
     : async_op_tracker(async_op_tracker),
       lock("librbd::Journal::C_RefreshTags::lock") {
     async_op_tracker.start_op();
diff --git a/src/librbd/Journal.h b/src/librbd/Journal.h
index e63cc4a7..fcc2c57c 100644
--- a/src/librbd/Journal.h
+++ b/src/librbd/Journal.h
@@ -8,9 +8,11 @@
 #include "include/Context.h"
 #include "include/interval_set.h"
 #include "include/rados/librados_fwd.hpp"
+#include "common/AsyncOpTracker.h"
 #include "common/Cond.h"
 #include "common/Mutex.h"
 #include "common/Cond.h"
+#include "common/RefCountedObj.h"
 #include "common/WorkQueue.h"
 #include "journal/Future.h"
 #include "journal/JournalMetadataListener.h"
@@ -38,7 +40,7 @@ class ImageCtx;
 namespace journal { template <typename> class Replay; }
 
 template <typename ImageCtxT = ImageCtx>
-class Journal {
+class Journal : public RefCountedObject {
 public:
   /**
    * @verbatim
@@ -303,7 +305,7 @@ private:
 
   journal::Replay<ImageCtxT> *m_journal_replay;
 
-  util::AsyncOpTracker m_async_journal_op_tracker;
+  AsyncOpTracker m_async_journal_op_tracker;
 
   struct MetadataListener : public ::journal::JournalMetadataListener {
     Journal<ImageCtxT> *journal;
diff --git a/src/librbd/ObjectMap.cc b/src/librbd/ObjectMap.cc
index 50cbfda8..704a6b54 100644
--- a/src/librbd/ObjectMap.cc
+++ b/src/librbd/ObjectMap.cc
@@ -32,9 +32,12 @@
 
 namespace librbd {
 
+using librbd::util::create_context_callback;
+
 template <typename I>
 ObjectMap<I>::ObjectMap(I &image_ctx, uint64_t snap_id)
-  : m_image_ctx(image_ctx), m_snap_id(snap_id),
+  : RefCountedObject(image_ctx.cct),
+    m_image_ctx(image_ctx), m_snap_id(snap_id),
     m_update_guard(new UpdateGuard(m_image_ctx.cct)) {
 }
 
@@ -153,19 +156,23 @@ bool ObjectMap<I>::update_required(const ceph::BitVector<2>::Iterator& it,
 
 template <typename I>
 void ObjectMap<I>::open(Context *on_finish) {
+  Context *ctx = create_context_callback<Context>(on_finish, this);
+
   auto req = object_map::RefreshRequest<I>::create(
-    m_image_ctx, &m_object_map, m_snap_id, on_finish);
+    m_image_ctx, &m_object_map, m_snap_id, ctx);
   req->send();
 }
 
 template <typename I>
 void ObjectMap<I>::close(Context *on_finish) {
+  Context *ctx = create_context_callback<Context>(on_finish, this);
+
   if (m_snap_id != CEPH_NOSNAP) {
-    m_image_ctx.op_work_queue->queue(on_finish, 0);
+    m_image_ctx.op_work_queue->queue(ctx, 0);
     return;
   }
 
-  auto req = object_map::UnlockRequest<I>::create(m_image_ctx, on_finish);
+  auto req = object_map::UnlockRequest<I>::create(m_image_ctx, ctx);
   req->send();
 }
 
@@ -185,8 +192,10 @@ void ObjectMap<I>::rollback(uint64_t snap_id, Context *on_finish) {
   ceph_assert(m_image_ctx.snap_lock.is_locked());
   ceph_assert(m_image_ctx.object_map_lock.is_wlocked());
 
+  Context *ctx = create_context_callback<Context>(on_finish, this);
+
   object_map::SnapshotRollbackRequest *req =
-    new object_map::SnapshotRollbackRequest(m_image_ctx, snap_id, on_finish);
+    new object_map::SnapshotRollbackRequest(m_image_ctx, snap_id, ctx);
   req->send();
 }
 
@@ -196,9 +205,11 @@ void ObjectMap<I>::snapshot_add(uint64_t snap_id, Context *on_finish) {
   ceph_assert((m_image_ctx.features & RBD_FEATURE_OBJECT_MAP) != 0);
   ceph_assert(snap_id != CEPH_NOSNAP);
 
+  Context *ctx = create_context_callback<Context>(on_finish, this);
+
   object_map::SnapshotCreateRequest *req =
     new object_map::SnapshotCreateRequest(m_image_ctx, &m_object_map, snap_id,
-                                          on_finish);
+                                          ctx);
   req->send();
 }
 
@@ -208,9 +219,11 @@ void ObjectMap<I>::snapshot_remove(uint64_t snap_id, Context *on_finish) {
   ceph_assert((m_image_ctx.features & RBD_FEATURE_OBJECT_MAP) != 0);
   ceph_assert(snap_id != CEPH_NOSNAP);
 
+  Context *ctx = create_context_callback<Context>(on_finish, this);
+
   object_map::SnapshotRemoveRequest *req =
     new object_map::SnapshotRemoveRequest(m_image_ctx, &m_object_map, snap_id,
-                                          on_finish);
+                                          ctx);
   req->send();
 }
 
@@ -228,8 +241,10 @@ void ObjectMap<I>::aio_save(Context *on_finish) {
   }
   cls_client::object_map_save(&op, m_object_map);
 
+  Context *ctx = create_context_callback<Context>(on_finish, this);
+
   std::string oid(object_map_name(m_image_ctx.id, m_snap_id));
-  librados::AioCompletion *comp = util::create_rados_callback(on_finish);
+  librados::AioCompletion *comp = util::create_rados_callback(ctx);
 
   int r = m_image_ctx.md_ctx.aio_operate(oid, comp, &op);
   ceph_assert(r == 0);
@@ -247,9 +262,11 @@ void ObjectMap<I>::aio_resize(uint64_t new_size, uint8_t default_object_state,
   ceph_assert(m_image_ctx.exclusive_lock == nullptr ||
               m_image_ctx.exclusive_lock->is_lock_owner());
 
+  Context *ctx = create_context_callback<Context>(on_finish, this);
+
   object_map::ResizeRequest *req = new object_map::ResizeRequest(
     m_image_ctx, &m_object_map, m_snap_id, new_size, default_object_state,
-    on_finish);
+    ctx);
   req->send();
 }
 
diff --git a/src/librbd/ObjectMap.h b/src/librbd/ObjectMap.h
index c930a5b5..b6d2c8b6 100644
--- a/src/librbd/ObjectMap.h
+++ b/src/librbd/ObjectMap.h
@@ -9,6 +9,7 @@
 #include "include/rados/librados_fwd.hpp"
 #include "include/rbd/object_map_types.h"
 #include "common/bit_vector.hpp"
+#include "common/RefCountedObj.h"
 #include "librbd/Utils.h"
 #include <boost/optional.hpp>
 
@@ -23,7 +24,7 @@ struct BlockGuardCell;
 class ImageCtx;
 
 template <typename ImageCtxT = ImageCtx>
-class ObjectMap {
+class ObjectMap : public RefCountedObject {
 public:
   static ObjectMap *create(ImageCtxT &image_ctx, uint64_t snap_id) {
     return new ObjectMap(image_ctx, snap_id);
diff --git a/src/librbd/Operations.cc b/src/librbd/Operations.cc
index ffb8f5c8..04312aa4 100644
--- a/src/librbd/Operations.cc
+++ b/src/librbd/Operations.cc
@@ -41,6 +41,12 @@
 #include <boost/bind.hpp>
 #include <boost/scope_exit.hpp>
 
+#ifdef WITH_GLOBAL_CACHE
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMgr.h"
+#include "client_adaptor/ClientAdaptorMsg.h"
+#endif
+
 #define dout_subsys ceph_subsys_rbd
 #undef dout_prefix
 #define dout_prefix *_dout << "librbd::Operations: "
@@ -213,7 +219,8 @@ struct C_InvokeAsyncRequest : public Context {
     Context *ctx = util::create_async_context_callback(
       image_ctx, util::create_context_callback<
         C_InvokeAsyncRequest<I>,
-        &C_InvokeAsyncRequest<I>::handle_acquire_exclusive_lock>(this));
+        &C_InvokeAsyncRequest<I>::handle_acquire_exclusive_lock>(
+        this, image_ctx.exclusive_lock));
 
     if (request_lock) {
       // current lock owner doesn't support op -- try to perform
@@ -245,8 +252,21 @@ struct C_InvokeAsyncRequest : public Context {
       return;
     }
 
+#ifdef WITH_GLOBAL_CACHE
+    if (name.compare("snap_create") != 0) {
+        send_remote_request();
+    }
+#else
     send_remote_request();
+#endif
     owner_lock.put_read();
+#ifdef WITH_GLOBAL_CACHE
+    if (name.compare("snap_create") == 0) {
+        ldout(cct, 10) << __func__ << " " << name << " can not send remote request, go on to refresh image" << dendl;
+        usleep(500000);     // 0.5s
+        send_refresh_image();
+    }
+#endif
   }
 
   void send_remote_request() {
@@ -732,6 +752,26 @@ void Operations<I>::snap_create(const cls::rbd::SnapshotNamespace &snap_namespac
     return;
   }
   m_image_ctx.snap_lock.put_read();
+  
+#ifdef WITH_GLOBAL_CACHE
+  if (m_image_ctx.md_ctx.check_acc()) {
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+
+    if (!plugin || !plugin->msg_ref) {
+        lderr(cct) << "global_cache plugin not loaded, plugin=" << plugin << dendl;
+        on_finish->complete(-EINVAL);
+        return;
+    }
+
+    if (plugin->msg_ref->is_gc_snap(snap_name)) {
+        lderr(cct) << "create " << snap_name << " with prefix " << plugin->msg_ref->gc_snap_prefix()
+                    << " which be used by gc internal, not allowed" << dendl;
+        on_finish->complete(-EBUSY);
+        return;
+    }
+  }
+#endif
 
   C_InvokeAsyncRequest<I> *req = new C_InvokeAsyncRequest<I>(
     m_image_ctx, "snap_create", exclusive_lock::OPERATION_REQUEST_TYPE_GENERAL,
@@ -811,6 +851,39 @@ int Operations<I>::snap_rollback(const cls::rbd::SnapshotNamespace& snap_namespa
       }
     }
 
+#ifdef WITH_GLOBAL_CACHE
+    if (m_image_ctx.md_ctx.check_acc()) {
+        PluginRegistry *reg = cct->get_plugin_registry();
+        auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+        int mgr_ret = -ELIBACC;
+        if (plugin && plugin->mgr_ref && plugin->msg_ref) {
+            int64_t md_pool_id;
+            int64_t data_pool_id;
+            md_pool_id = m_image_ctx.md_ctx.get_id();
+            if (!m_image_ctx.data_ctx.is_valid()) {
+                data_pool_id = md_pool_id;
+            } else {
+                data_pool_id = m_image_ctx.data_ctx.get_id();
+            }
+            if (plugin->msg_ref->is_gc_snap(snap_name)) {
+                lderr(cct) << snap_name << " is gc internal snap, rollback not allowed" << dendl;
+                return -EBUSY;
+            }
+            ldout(cct, 10) << " check if rollback " << md_pool_id << "/" << data_pool_id << "/" << m_image_ctx.id << dendl;
+            mgr_ret = plugin->mgr_ref->gc_is_rollbacking(md_pool_id, data_pool_id, m_image_ctx.id);
+            if (mgr_ret < 0) {
+                return mgr_ret;
+            } else if (mgr_ret == 1) {
+                lderr(cct) << " Client Adaptor: " << md_pool_id << "(" << data_pool_id << ")/" << m_image_ctx.id
+                    << " GC backend is rollbacking, image another rollback not allowed, please wait."<< dendl;
+                return -EBUSY;
+            }
+        } else {
+            return mgr_ret;
+        }
+    }
+#endif
+
     r = prepare_image_update(exclusive_lock::OPERATION_REQUEST_TYPE_GENERAL,
                              false);
     if (r < 0) {
@@ -913,6 +986,93 @@ void Operations<I>::snap_remove(const cls::rbd::SnapshotNamespace& snap_namespac
                    (m_image_ctx.features & RBD_FEATURE_JOURNALING) != 0);
   m_image_ctx.snap_lock.put_read();
 
+#ifdef WITH_GLOBAL_CACHE
+  if (m_image_ctx.md_ctx.check_acc()) {
+    ldout(cct, 10) << "snap_remove acc_pool"  << dendl;
+    bool is_protected;
+    m_image_ctx.snap_lock.get_read();
+    uint64_t snap_id = m_image_ctx.get_snap_id(cls::rbd::UserSnapshotNamespace(), snap_name);
+    int r = m_image_ctx.is_snap_protected(snap_id, &is_protected);
+    m_image_ctx.snap_lock.put_read();
+    if (r < 0) {
+        on_finish->complete(r);
+        return;
+    } else if (is_protected) {
+        lderr(cct) << "snapshot is protected" << dendl;
+        on_finish->complete(-EBUSY);
+        return;
+    }
+    if (m_image_ctx.operations_disabled || m_image_ctx.read_only) {
+        on_finish->complete(-EROFS);
+        return;
+    }
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+    int mgr_ret = -ELIBACC;
+
+    if (plugin && plugin->mgr_ref) {
+        int64_t pool_id;
+        string name_space;
+        if (!m_image_ctx.data_ctx.is_valid()) {
+            pool_id = m_image_ctx.md_ctx.get_id();
+            name_space = m_image_ctx.md_ctx.get_namespace();
+            ldout(cct, 10) << "data ctx invalid poolId=" << pool_id << dendl;
+        } else {
+            pool_id = m_image_ctx.data_ctx.get_id();
+            name_space = m_image_ctx.data_ctx.get_namespace();
+            ldout(cct, 10) << "data ctx valid poolId=" << pool_id << dendl;
+        }
+
+        if (plugin->msg_ref->is_gc_snap(snap_name) ) {
+            lderr(cct) << snap_name << " is gc internal snap, remove not allowed"<< dendl;
+            on_finish->complete(-EBUSY);
+            return;
+        }
+
+        mgr_ret = plugin->mgr_ref->gc_snap_is_rollbacking(pool_id, m_image_ctx.id, snap_id);
+        if (mgr_ret < 0) {
+            on_finish->complete(mgr_ret);
+            return;
+        } else if (mgr_ret == 1) {
+            lderr(cct) << " Client Adaptor: " << pool_id << "/" << m_image_ctx.id << "@" << snap_id
+                << " GC backend is rollbacking, this snap delete not allowed, please wait."<< dendl;
+            on_finish->complete(-EAGAIN);
+            return;
+        }
+
+        mgr_ret = plugin->mgr_ref->remove_snap_from_gc(pool_id, name_space, m_image_ctx.id, snap_id);
+        if (mgr_ret < 0) {
+            lderr(cct) << " " << __func__ << "remove snap failed, agent return " << mgr_ret << dendl;
+        } else {
+            bool exist = false;
+            int t = 0;
+            do {
+                if (exist) {
+                    ldout(cct, 20) << "snap still exists snap_name= " << snap_name << dendl;
+                    usleep(500000);     // 0.5s
+                }
+                if (t < 10) {
+                    mgr_ret = snap_exists(&m_image_ctx, cls::rbd::UserSnapshotNamespace(),
+                        snap_name.c_str(), &exist);
+                    t++;
+                } else {
+                    mgr_ret = snap_exists_with_refresh(&m_image_ctx, cls::rbd::UserSnapshotNamespace(),
+                        snap_name.c_str(), &exist);
+                    t = 0;
+                }
+                if (mgr_ret < 0) {
+                    lderr(cct) << " " << __func__ << ": refresh failed, ret=" << mgr_ret << dendl;
+                }
+            } while(exist);
+        }
+    } else {
+        lderr(cct) << " " << __func__ << ": load plugin failed! plugin=" << plugin << dendl;
+    }
+    on_finish->complete(mgr_ret);
+    return;
+  }
+#endif
+
   if (proxy_op) {
     auto request_type = exclusive_lock::OPERATION_REQUEST_TYPE_GENERAL;
     if (cls::rbd::get_snap_namespace_type(snap_namespace) ==
@@ -1010,6 +1170,28 @@ int Operations<I>::snap_rename(const char *srcname, const char *dstname) {
     }
   }
 
+#ifdef WITH_GLOBAL_CACHE
+  if (m_image_ctx.md_ctx.check_acc()) {
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+
+    if (!plugin || !plugin->msg_ref) {
+        lderr(cct) << "global_cache plugin not loaded, plugin=" << plugin << dendl;
+        return -EINVAL;
+    }
+
+    if (plugin->msg_ref->is_gc_snap(srcname)) {
+        lderr(cct) << srcname << " is gc internal snap, rename not allowed" << dendl;
+        return -EBUSY;
+    }
+
+    if (plugin->msg_ref->is_gc_snap(dstname)) {
+        lderr(cct) << dstname << " is gc internal snap, rename not allowed" << dendl;
+        return -EBUSY;
+    }
+  }
+#endif
+
   if (m_image_ctx.test_features(RBD_FEATURE_JOURNALING)) {
     r = invoke_async_request("snap_rename",
                              exclusive_lock::OPERATION_REQUEST_TYPE_GENERAL,
@@ -1111,6 +1293,22 @@ int Operations<I>::snap_protect(const cls::rbd::SnapshotNamespace& snap_namespac
     }
   }
 
+#ifdef WITH_GLOBAL_CACHE
+  if (m_image_ctx.md_ctx.check_acc()) {
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+    if (!plugin || !plugin->msg_ref) {
+        lderr(cct) << "global_cache plugin not loaded, plugin=" << plugin << dendl;
+        return -EINVAL;
+    }
+
+    if (plugin->msg_ref->is_gc_snap(snap_name)) {
+        lderr(cct) << snap_name << " is gc internal snap, protect not allowed" << dendl;
+        return -EBUSY;
+    }
+  }
+#endif
+
   if (m_image_ctx.test_features(RBD_FEATURE_JOURNALING)) {
     r = invoke_async_request("snap_protect",
                              exclusive_lock::OPERATION_REQUEST_TYPE_GENERAL,
diff --git a/src/librbd/Types.h b/src/librbd/Types.h
index 3f110447..e33023fb 100644
--- a/src/librbd/Types.h
+++ b/src/librbd/Types.h
@@ -22,6 +22,14 @@ enum {
   l_librbd_wr,
   l_librbd_wr_bytes,
   l_librbd_wr_latency,
+#ifdef WITH_GLOBAL_CACHE
+  l_librbd_rd_before_queue_op_lat,
+  l_librbd_wr_before_queue_op_lat,
+  l_librbd_after_dequeue_op_lat,
+  l_librbd_send_lat,
+  l_librbd_wr_queue,
+  l_librbd_rd_queue,
+#endif
   l_librbd_discard,
   l_librbd_discard_bytes,
   l_librbd_discard_latency,
diff --git a/src/librbd/Utils.h b/src/librbd/Utils.h
index c0b68b9f..07910039 100644
--- a/src/librbd/Utils.h
+++ b/src/librbd/Utils.h
@@ -8,6 +8,7 @@
 #include "include/rbd_types.h"
 #include "include/Context.h"
 #include "common/zipkin_trace.h"
+#include "common/RefCountedObj.h"
 
 #include <atomic>
 #include <type_traits>
@@ -57,6 +58,23 @@ protected:
   }
 };
 
+template <typename T, void (T::*MF)(int)>
+class C_RefCallbackAdapter : public Context {
+  RefCountedPtr refptr;
+  Context *on_finish;
+
+public:
+  C_RefCallbackAdapter(T *obj, RefCountedPtr refptr)
+    : refptr(std::move(refptr)),
+      on_finish(new C_CallbackAdapter<T, MF>(obj)) {
+  }
+
+protected:
+  void finish(int r) override {
+    on_finish->complete(r);
+  }
+};
+
 template <typename T, Context*(T::*MF)(int*), bool destroy>
 class C_StateCallbackAdapter : public Context {
   T *obj;
@@ -79,6 +97,23 @@ protected:
   }
 };
 
+template <typename T, Context*(T::*MF)(int*)>
+class C_RefStateCallbackAdapter : public Context {
+  RefCountedPtr refptr;
+  Context *on_finish;
+
+public:
+  C_RefStateCallbackAdapter(T *obj, RefCountedPtr refptr)
+    : refptr(std::move(refptr)),
+      on_finish(new C_StateCallbackAdapter<T, MF, true>(obj)) {
+  }
+
+protected:
+  void finish(int r) override {
+    on_finish->complete(r);
+  }
+};
+
 template <typename WQ>
 struct C_AsyncCallback : public Context {
   WQ *op_work_queue;
@@ -137,6 +172,30 @@ Context *create_context_callback(T *obj) {
   return new detail::C_StateCallbackAdapter<T, MF, destroy>(obj);
 }
 
+//for reference counting objects
+template <typename T, void(T::*MF)(int) = &T::complete>
+Context *create_context_callback(T *obj, RefCountedPtr refptr) {
+  return new detail::C_RefCallbackAdapter<T, MF>(obj, refptr);
+}
+
+template <typename T, Context*(T::*MF)(int*)>
+Context *create_context_callback(T *obj, RefCountedPtr refptr) {
+  return new detail::C_RefStateCallbackAdapter<T, MF>(obj, refptr);
+}
+
+//for objects that don't inherit from RefCountedObj, to handle unit tests
+template <typename T, void(T::*MF)(int) = &T::complete, typename R>
+typename std::enable_if<not std::is_base_of<RefCountedPtr, R>::value, Context*>::type
+create_context_callback(T *obj, R *refptr) {
+  return new detail::C_CallbackAdapter<T, MF>(obj);
+}
+
+template <typename T, Context*(T::*MF)(int*), typename R, bool destroy=true>
+typename std::enable_if<not std::is_base_of<RefCountedPtr, R>::value, Context*>::type
+create_context_callback(T *obj, R *refptr) {
+  return new detail::C_StateCallbackAdapter<T, MF, destroy>(obj);
+}
+
 template <typename I>
 Context *create_async_context_callback(I &image_ctx, Context *on_finish) {
   // use async callback to acquire a clean lock context
@@ -156,39 +215,6 @@ inline ImageCtx *get_image_ctx(ImageCtx *image_ctx) {
   return image_ctx;
 }
 
-/// helper for tracking in-flight async ops when coordinating
-/// a shut down of the invoking class instance
-class AsyncOpTracker {
-public:
-  void start_op() {
-    m_refs++;
-  }
-
-  void finish_op() {
-    if (--m_refs == 0 && m_on_finish != nullptr) {
-      Context *on_finish = nullptr;
-      std::swap(on_finish, m_on_finish);
-      on_finish->complete(0);
-    }
-  }
-
-  template <typename I>
-  void wait(I &image_ctx, Context *on_finish) {
-    ceph_assert(m_on_finish == nullptr);
-
-    on_finish = create_async_context_callback(image_ctx, on_finish);
-    if (m_refs == 0) {
-      on_finish->complete(0);
-      return;
-    }
-    m_on_finish = on_finish;
-  }
-
-private:
-  std::atomic<uint64_t> m_refs = { 0 };
-  Context *m_on_finish = nullptr;
-};
-
 uint64_t get_rbd_default_features(CephContext* cct);
 
 bool calc_sparse_extent(const bufferptr &bp,
diff --git a/src/librbd/api/Image.cc b/src/librbd/api/Image.cc
index 8f526f40..2d527116 100644
--- a/src/librbd/api/Image.cc
+++ b/src/librbd/api/Image.cc
@@ -20,6 +20,11 @@
 #include "librbd/image/PreRemoveRequest.h"
 #include <boost/scope_exit.hpp>
 
+#ifdef WITH_GLOBAL_CACHE
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMgr.h"
+#endif
+
 #define dout_subsys ceph_subsys_rbd
 #undef dout_prefix
 #define dout_prefix *_dout << "librbd::api::Image: " << __func__ << ": "
@@ -578,6 +583,35 @@ int Image<I>::deep_copy(I *src, librados::IoCtx& dest_md_ctx,
     return -ENOSYS;
   }
 
+#ifdef WITH_GLOBAL_CACHE
+    if (src->md_ctx.check_acc()) {
+        PluginRegistry *reg = src->cct->get_plugin_registry();
+        auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+        int mgr_ret = -ELIBACC;
+        if (plugin && plugin->mgr_ref) {
+            int64_t md_pool_id;
+            int64_t data_pool_id;
+            md_pool_id = src->md_ctx.get_id();
+            if (!src->data_ctx.is_valid()) {
+                data_pool_id = md_pool_id;
+            } else {
+                data_pool_id = src->data_ctx.get_id();
+            }
+            ldout(src->cct, 10) << " check if rollback " << md_pool_id << "(" << data_pool_id << ")/" << src->id << dendl;
+            mgr_ret = plugin->mgr_ref->gc_is_rollbacking(md_pool_id, data_pool_id, src->id);
+            if (mgr_ret < 0) {
+                return mgr_ret;
+            } else if (mgr_ret == 1) {
+                lderr(src->cct) << " Client Adaptor: " << md_pool_id << "(" << data_pool_id << ")/" << src->id
+                    << " GC backend is rollbacking, deep copy not allowed, please wait."<< dendl;
+                return -EBUSY;
+            }
+        } else {
+            return mgr_ret;
+        }
+    }
+#endif
+
   uint64_t flatten = 0;
   if (opts.get(RBD_IMAGE_OPTION_FLATTEN, &flatten) == 0) {
     opts.unset(RBD_IMAGE_OPTION_FLATTEN);
diff --git a/src/librbd/api/Mirror.cc b/src/librbd/api/Mirror.cc
index 4e7b7dc8..fe816d5d 100644
--- a/src/librbd/api/Mirror.cc
+++ b/src/librbd/api/Mirror.cc
@@ -8,7 +8,6 @@
 #include "common/dout.h"
 #include "common/errno.h"
 #include "cls/rbd/cls_rbd_client.h"
-#include "librbd/ExclusiveLock.h"
 #include "librbd/ImageCtx.h"
 #include "librbd/ImageState.h"
 #include "librbd/Journal.h"
diff --git a/src/librbd/exclusive_lock/PostAcquireRequest.cc b/src/librbd/exclusive_lock/PostAcquireRequest.cc
index 7e67e41c..54158b84 100644
--- a/src/librbd/exclusive_lock/PostAcquireRequest.cc
+++ b/src/librbd/exclusive_lock/PostAcquireRequest.cc
@@ -156,7 +156,7 @@ void PostAcquireRequest<I>::send_allocate_journal_tag() {
   RWLock::RLocker snap_locker(m_image_ctx.snap_lock);
   using klass = PostAcquireRequest<I>;
   Context *ctx = create_context_callback<
-    klass, &klass::handle_allocate_journal_tag>(this);
+    klass, &klass::handle_allocate_journal_tag>(this, m_journal);
   m_image_ctx.get_journal_policy()->allocate_tag_on_lock(ctx);
 }
 
@@ -225,7 +225,7 @@ void PostAcquireRequest<I>::handle_open_object_map(int r) {
 
   if (r < 0) {
     lderr(cct) << "failed to open object map: " << cpp_strerror(r) << dendl;
-    delete m_object_map;
+    m_object_map->put();
     m_object_map = nullptr;
 
     if (r != -EFBIG) {
@@ -290,8 +290,12 @@ void PostAcquireRequest<I>::revert() {
   m_image_ctx.object_map = nullptr;
   m_image_ctx.journal = nullptr;
 
-  delete m_object_map;
-  delete m_journal;
+  if (m_object_map) {
+    m_object_map->put();
+  }
+  if (m_journal) {
+    m_journal->put();
+  }
 
   ceph_assert(m_error_result < 0);
 }
diff --git a/src/librbd/exclusive_lock/PreReleaseRequest.cc b/src/librbd/exclusive_lock/PreReleaseRequest.cc
index 7dbae6c5..3eb27cea 100644
--- a/src/librbd/exclusive_lock/PreReleaseRequest.cc
+++ b/src/librbd/exclusive_lock/PreReleaseRequest.cc
@@ -240,7 +240,8 @@ void PreReleaseRequest<I>::handle_close_journal(int r) {
     lderr(cct) << "failed to close journal: " << cpp_strerror(r) << dendl;
   }
 
-  delete m_journal;
+  m_journal->put();
+  m_journal = nullptr;
 
   send_close_object_map();
 }
@@ -262,7 +263,7 @@ void PreReleaseRequest<I>::send_close_object_map() {
 
   using klass = PreReleaseRequest<I>;
   Context *ctx = create_context_callback<
-    klass, &klass::handle_close_object_map>(this);
+    klass, &klass::handle_close_object_map>(this, m_object_map);;
   m_object_map->close(ctx);
 }
 
@@ -274,8 +275,8 @@ void PreReleaseRequest<I>::handle_close_object_map(int r) {
   if (r < 0) {
     lderr(cct) << "failed to close object map: " << cpp_strerror(r) << dendl;
   }
+  m_object_map->put();
 
-  delete m_object_map;
   send_unlock();
 }
 
diff --git a/src/librbd/image/CloseRequest.cc b/src/librbd/image/CloseRequest.cc
index 73d671dc..ac1deb3e 100644
--- a/src/librbd/image/CloseRequest.cc
+++ b/src/librbd/image/CloseRequest.cc
@@ -110,8 +110,8 @@ void CloseRequest<I>::send_shut_down_exclusive_lock() {
 
     // if reading a snapshot -- possible object map is open
     RWLock::WLocker snap_locker(m_image_ctx->snap_lock);
-    if (m_exclusive_lock == nullptr) {
-      delete m_image_ctx->object_map;
+    if (m_exclusive_lock == nullptr && m_image_ctx->object_map) {
+      m_image_ctx->object_map->put();
       m_image_ctx->object_map = nullptr;
     }
   }
@@ -145,7 +145,7 @@ void CloseRequest<I>::handle_shut_down_exclusive_lock(int r) {
     ceph_assert(m_image_ctx->object_map == nullptr);
   }
 
-  delete m_exclusive_lock;
+  m_exclusive_lock->put();
   m_exclusive_lock = nullptr;
 
   save_result(r);
diff --git a/src/librbd/image/PreRemoveRequest.cc b/src/librbd/image/PreRemoveRequest.cc
index 3326c143..fe3d9596 100644
--- a/src/librbd/image/PreRemoveRequest.cc
+++ b/src/librbd/image/PreRemoveRequest.cc
@@ -11,6 +11,11 @@
 #include "librbd/journal/DisabledPolicy.h"
 #include "librbd/operation/SnapshotRemoveRequest.h"
 
+#ifdef WITH_GLOBAL_CACHE
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMsg.h"
+#endif
+
 #define dout_subsys ceph_subsys_rbd
 #undef dout_prefix
 #define dout_prefix *_dout << "librbd::image::PreRemoveRequest: " << this \
@@ -22,6 +27,7 @@ namespace image {
 namespace {
 
 bool auto_delete_snapshot(const SnapInfo& snap_info) {
+
   auto snap_namespace_type = cls::rbd::get_snap_namespace_type(
     snap_info.snap_namespace);
   switch (snap_namespace_type) {
@@ -31,6 +37,18 @@ bool auto_delete_snapshot(const SnapInfo& snap_info) {
     return false;
   }
 }
+#ifdef WITH_GLOBAL_CACHE
+bool is_gc_snapshot(CephContext *cct, const SnapInfo& snap_info) {
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+
+  if (!plugin || !plugin->msg_ref) {
+      return false;
+  }
+
+  return plugin->msg_ref->is_gc_snap(snap_info.name);
+}
+#endif
 
 } // anonymous namespace
 
@@ -68,10 +86,12 @@ void PreRemoveRequest<I>::acquire_exclusive_lock() {
     m_image_ctx->set_journal_policy(new journal::DisabledPolicy());
   }
 
+  m_exclusive_lock = m_image_ctx->exclusive_lock;
+
   auto ctx = create_context_callback<
-    PreRemoveRequest<I>, &PreRemoveRequest<I>::handle_exclusive_lock>(this);
+    PreRemoveRequest<I>, &PreRemoveRequest<I>::handle_exclusive_lock>(this, m_exclusive_lock);
 
-  m_image_ctx->exclusive_lock->try_acquire_lock(ctx);
+  m_exclusive_lock->try_acquire_lock(ctx);
 }
 
 template <typename I>
@@ -118,7 +138,7 @@ void PreRemoveRequest<I>::handle_shut_down_exclusive_lock(int r) {
   auto cct = m_image_ctx->cct;
   ldout(cct, 5) << "r=" << r << dendl;
 
-  delete m_exclusive_lock;
+  m_exclusive_lock->put();
   m_exclusive_lock = nullptr;
 
   if (r < 0) {
@@ -154,7 +174,11 @@ void PreRemoveRequest<I>::check_image_snaps() {
 
   m_image_ctx->snap_lock.get_read();
   for (auto& snap_info : m_image_ctx->snap_info) {
+#ifdef WITH_GLOBAL_CACHE
+    if (auto_delete_snapshot(snap_info.second) || is_gc_snapshot(cct, snap_info.second)) {
+#else
     if (auto_delete_snapshot(snap_info.second)) {
+#endif
       m_snap_infos.insert(snap_info);
     } else {
       m_image_ctx->snap_lock.put_read();
diff --git a/src/librbd/image/RefreshRequest.cc b/src/librbd/image/RefreshRequest.cc
index 7ec565d6..2ba11178 100644
--- a/src/librbd/image/RefreshRequest.cc
+++ b/src/librbd/image/RefreshRequest.cc
@@ -1055,7 +1055,7 @@ Context *RefreshRequest<I>::handle_v2_open_object_map(int *result) {
   if (*result < 0) {
     lderr(cct) << "failed to open object map: " << cpp_strerror(*result)
                << dendl;
-    delete m_object_map;
+    m_object_map->put();
     m_object_map = nullptr;
 
     if (*result != -EFBIG) {
@@ -1152,7 +1152,7 @@ Context *RefreshRequest<I>::handle_v2_shut_down_exclusive_lock(int *result) {
   }
 
   ceph_assert(m_exclusive_lock != nullptr);
-  delete m_exclusive_lock;
+  m_exclusive_lock->put();
   m_exclusive_lock = nullptr;
 
   return send_v2_close_journal();
@@ -1187,7 +1187,7 @@ Context *RefreshRequest<I>::handle_v2_close_journal(int *result) {
   }
 
   ceph_assert(m_journal != nullptr);
-  delete m_journal;
+  m_journal->put();
   m_journal = nullptr;
 
   ceph_assert(m_blocked_writes);
@@ -1225,7 +1225,7 @@ Context *RefreshRequest<I>::handle_v2_close_object_map(int *result) {
   }
 
   ceph_assert(m_object_map != nullptr);
-  delete m_object_map;
+  m_object_map->put();
   m_object_map = nullptr;
 
   return send_flush_aio();
diff --git a/src/librbd/image/RemoveRequest.cc b/src/librbd/image/RemoveRequest.cc
index 8e029f8b..33b2c725 100644
--- a/src/librbd/image/RemoveRequest.cc
+++ b/src/librbd/image/RemoveRequest.cc
@@ -14,6 +14,10 @@
 #include "librbd/journal/RemoveRequest.h"
 #include "librbd/mirror/DisableRequest.h"
 #include "librbd/operation/TrimRequest.h"
+#ifdef WITH_GLOBAL_CACHE
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMgr.h"
+#endif
 
 #define dout_subsys ceph_subsys_rbd
 #undef dout_prefix
@@ -58,6 +62,15 @@ template<typename I>
 void RemoveRequest<I>::send() {
   ldout(m_cct, 20) << dendl;
 
+#ifdef WITH_GLOBAL_CACHE
+  PluginRegistry *reg = m_cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  if (plugin == NULL) {
+    ldout(m_cct, 5) << "global_cache plugin not loaded" << dendl;
+    finish(-ELIBACC);
+    return;
+  }
+#endif
   open_image();
 }
 
@@ -127,10 +140,17 @@ void RemoveRequest<I>::handle_pre_remove_image(int r) {
   }
 
   if (!m_image_ctx->data_ctx.is_valid()) {
+#ifdef WITH_GLOBAL_CACHE
+    m_data_pool_id = m_image_ctx->md_ctx.get_id();
+    ldout(m_cct, 20) << " data pool not valid " << m_data_pool_id << dendl;
+#endif
     detach_child();
     return;
   }
-
+#ifdef WITH_GLOBAL_CACHE
+  m_data_pool_id = m_image_ctx->data_ctx.get_id();
+  ldout(m_cct, 20) << " data pool valid " << m_data_pool_id << dendl;
+#endif
   trim_image();
 }
 
@@ -393,6 +413,11 @@ void RemoveRequest<I>::handle_mirror_image_remove(int r) {
   if (m_from_trash_remove) {
     // both the id object and the directory entry have been removed in
     // a previous call to trash_move.
+#ifdef WITH_GLOBAL_CACHE
+  if (m_ioctx.check_acc()) {
+    remove_from_gc();
+  }
+#endif
     finish(0);
     return;
   }
@@ -433,7 +458,9 @@ void RemoveRequest<I>::handle_remove_v1_image(int r) {
       lderr(m_cct) << "error removing image from v1 directory: "
                    << cpp_strerror(r) << dendl;
     }
-
+#ifdef WITH_GLOBAL_CACHE
+    remove_from_gc();
+#endif
     m_on_finish->complete(r);
     delete this;
     return;
@@ -587,10 +614,34 @@ void RemoveRequest<I>::handle_dir_remove_image(int r) {
     lderr(m_cct) << "error removing image from v2 directory: "
                  << cpp_strerror(r) << dendl;
   }
-
+#ifdef WITH_GLOBAL_CACHE
+  if (m_ioctx.check_acc()) {
+    remove_from_gc();
+  }
+#endif
   finish(r);
 }
 
+#ifdef WITH_GLOBAL_CACHE
+template<typename I>
+void RemoveRequest<I>::remove_from_gc() {
+
+    ldout(m_cct, 20) << "remove_from_gc pool_id=" << m_data_pool_id
+                    << "image_id=" << m_image_id
+                     << " image_name=" << m_image_name
+                     << dendl;
+    PluginRegistry *reg = m_cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+    ceph_assert(plugin);
+    int64_t ret = plugin->mgr_ref->remove_gc_image_resource(m_data_pool_id, m_image_id);
+    if (ret == 0) {
+        ldout(m_cct, 20) << "remove image from gc successfully, image_id=" << m_image_id << dendl;
+    } else {
+        ldout(m_cct, 5) <<"remove image from gc failed, image_id=" << m_image_id << " ret=" << ret << dendl;
+    }
+}
+#endif
+
 template<typename I>
 void RemoveRequest<I>::finish(int r) {
   ldout(m_cct, 20) << "r=" << r << dendl;
diff --git a/src/librbd/image/RemoveRequest.h b/src/librbd/image/RemoveRequest.h
index 98d59764..5b676357 100644
--- a/src/librbd/image/RemoveRequest.h
+++ b/src/librbd/image/RemoveRequest.h
@@ -96,6 +96,10 @@ private:
    * |               |                /  |
    * |               \-------<-------/   |
    * |                                   v
+   * |                            REMOVE GC SNAP INFO
+   * |                                   |
+   * |                                   |
+   * |                                   v
    * \------------------>------------<finish>
    *
    * @endverbatim
@@ -113,6 +117,9 @@ private:
   librados::IoCtx &m_ioctx;
   std::string m_image_name;
   std::string m_image_id;
+#ifdef WITH_GLOBAL_CACHE
+  int64_t m_data_pool_id;
+#endif
   ImageCtxT *m_image_ctx = nullptr;
   bool m_force;
   bool m_from_trash_remove;
@@ -187,6 +194,10 @@ private:
   void dir_remove_image();
   void handle_dir_remove_image(int r);
 
+#ifdef WITH_GLOBAL_CACHE
+  void remove_from_gc();
+#endif
+
   void finish(int r);
 };
 
diff --git a/src/librbd/image/SetSnapRequest.cc b/src/librbd/image/SetSnapRequest.cc
index f342147f..c4a72041 100644
--- a/src/librbd/image/SetSnapRequest.cc
+++ b/src/librbd/image/SetSnapRequest.cc
@@ -32,8 +32,12 @@ template <typename I>
 SetSnapRequest<I>::~SetSnapRequest() {
   ceph_assert(!m_writes_blocked);
   delete m_refresh_parent;
-  delete m_object_map;
-  delete m_exclusive_lock;
+  if (m_object_map) {
+    m_object_map->put();
+  }
+  if (m_exclusive_lock) {
+    m_exclusive_lock->put();
+  }
 }
 
 template <typename I>
@@ -276,7 +280,7 @@ Context *SetSnapRequest<I>::handle_open_object_map(int *result) {
   if (*result < 0) {
     lderr(cct) << "failed to open object map: " << cpp_strerror(*result)
                << dendl;
-    delete m_object_map;
+    m_object_map->put();
     m_object_map = nullptr;
   }
 
diff --git a/src/librbd/internal.cc b/src/librbd/internal.cc
index 89b538d6..9d4d7d74 100644
--- a/src/librbd/internal.cc
+++ b/src/librbd/internal.cc
@@ -56,6 +56,11 @@
 #include <boost/variant.hpp>
 #include "include/ceph_assert.h"
 
+#ifdef WITH_GLOBAL_CACHE
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMsg.h"
+#endif
+
 #define dout_subsys ceph_subsys_rbd
 #undef dout_prefix
 #define dout_prefix *_dout << "librbd: "
@@ -1120,14 +1125,18 @@ int validate_pool(IoCtx &io_ctx, CephContext *cct) {
     CephContext *cct = ictx->cct;
     ldout(cct, 20) << __func__ << ": ictx=" << ictx << dendl;
 
-    if (!ictx->test_features(RBD_FEATURE_EXCLUSIVE_LOCK)) {
-      lderr(cct) << "exclusive-lock feature is not enabled" << dendl;
-      return -EINVAL;
-    }
-
     managed_lock::Locker locker;
     C_SaferCond get_owner_ctx;
-    ExclusiveLock<>(*ictx).get_locker(&locker, &get_owner_ctx);
+    {
+      RWLock::RLocker owner_locker{ictx->owner_lock};
+
+      if (ictx->exclusive_lock == nullptr) {
+        lderr(cct) << "exclusive-lock feature is not enabled" << dendl;
+        return -EINVAL;
+      }
+
+      ictx->exclusive_lock->get_locker(&locker, &get_owner_ctx);
+    }
     int r = get_owner_ctx.wait();
     if (r == -ENOENT) {
       return r;
@@ -1239,6 +1248,22 @@ int validate_pool(IoCtx &io_ctx, CephContext *cct) {
     return 0;
   }
 
+#ifdef WITH_GLOBAL_CACHE
+  int snap_exists_with_refresh(ImageCtx *ictx, const cls::rbd::SnapshotNamespace& snap_namespace,
+		  const char *snap_name, bool *exists)
+  {
+    ldout(ictx->cct, 20) << "snap_exists_with_refresh " << ictx << " " << snap_name << dendl;
+
+    int r = ictx->state->refresh();
+    if (r < 0)
+      return r;
+
+    RWLock::RLocker l(ictx->snap_lock);
+    *exists = ictx->get_snap_id(snap_namespace, snap_name) != CEPH_NOSNAP;
+    return 0;
+  }
+#endif
+
   int snap_remove(ImageCtx *ictx, const char *snap_name, uint32_t flags,
 		  ProgressContext& pctx)
   {
@@ -1580,7 +1605,63 @@ int validate_pool(IoCtx &io_ctx, CephContext *cct) {
       prog_ctx.update_progress(src_size, src_size);
     return r;
   }
+#ifdef WITH_GLOBAL_CACHE
+  int internal_get_data_dst_addr(ImageCtx *image_ctx,
+                        uint64_t off,
+                        uint64_t *obj_offset,
+                        char *obj_addr,
+                        uint32_t *obj_id)
+  {
+      CephContext *cct = image_ctx->cct;
+      ldout(cct, 20) << " get dst data: " << image_ctx->name 
+                    << " off: " << off
+                    << " format: " << image_ctx->format_string
+                    << " layout: " << image_ctx->layout << dendl;
+      std::vector<ObjectExtent> object_extents;
+      Striper::file_to_extents(cct, image_ctx->format_string, &image_ctx->layout,
+                               off, 1, 0, object_extents);
+      ceph_assert(object_extents.size() == 1);
+      string obj_name;
+      for (std::vector<ObjectExtent>::const_iterator p = object_extents.begin();
+                    p != object_extents.end(); ++p) {
+          ldout(cct, 20) << "oid " << p->oid << " " << p->offset << "~" << p->length
+                   << " from " << p->buffer_extents << dendl;
+          *obj_offset = p->offset;
+          obj_name = p->oid.name;
+      }
+
+      int ret = sscanf(obj_name.c_str(), image_ctx->format_string, obj_id);
+      if (ret != 1) {
+          lderr(cct) << __func__ << " parse format string error: " << ret << dendl;
+          return ret;
+      }
 
+      PluginRegistry *reg = cct->get_plugin_registry();
+      auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+      int mgr_ret = -ELIBACC;
+      if (plugin && plugin->msg_ref) {
+        uint32_t pt_id;
+        uint64_t pool_id = image_ctx->md_ctx.get_id();
+        int32_t clusterId = image_ctx->md_ctx.get_cluster_id();
+        int32_t node_id = plugin->msg_ref->get_node_id(clusterId, obj_name, pool_id, pt_id);
+        if (node_id < 0){
+            lderr(cct) << __func__ << " Get node id failed ret " << node_id << dendl;
+            return mgr_ret;
+        }
+        string node_ip = "";
+        uint32_t mgr_ret = plugin->msg_ref->get_node_raw_ip(clusterId, node_id, node_ip);
+        if (mgr_ret) {
+            lderr(cct) << __func__ << " Get node ip failed, ret " << mgr_ret << dendl;
+            return mgr_ret;
+        }
+        ldout(cct, 20) << "node_ip " << node_ip << dendl;
+        strncpy(obj_addr, node_ip.c_str(), node_ip.length() + 1);
+      } else {
+          lderr(cct) <<  __func__ << " load plugin failed! plugin=" << plugin << dendl;
+      }
+      return mgr_ret;
+  }
+#endif
   int list_lockers(ImageCtx *ictx,
 		   std::list<locker_t> *lockers,
 		   bool *exclusive,
diff --git a/src/librbd/internal.h b/src/librbd/internal.h
index 1e1864f3..10a1748e 100644
--- a/src/librbd/internal.h
+++ b/src/librbd/internal.h
@@ -98,6 +98,12 @@ namespace librbd {
   int snap_list(ImageCtx *ictx, std::vector<snap_info_t>& snaps);
   int snap_exists(ImageCtx *ictx, const cls::rbd::SnapshotNamespace& snap_namespace,
 		  const char *snap_name, bool *exists);
+
+#ifdef WITH_GLOBAL_CACHE
+  int snap_exists_with_refresh(ImageCtx *ictx, const cls::rbd::SnapshotNamespace& snap_namespace,
+		  const char *snap_name, bool *exists);
+#endif
+
   int snap_get_limit(ImageCtx *ictx, uint64_t *limit);
   int snap_set_limit(ImageCtx *ictx, uint64_t limit);
   int snap_get_timestamp(ImageCtx *ictx, uint64_t snap_id, struct timespec *timestamp);
@@ -139,6 +145,10 @@ namespace librbd {
   int64_t read_iterate(ImageCtx *ictx, uint64_t off, uint64_t len,
 		       int (*cb)(uint64_t, size_t, const char *, void *),
 		       void *arg);
+#ifdef WITH_GLOBAL_CACHE
+  int internal_get_data_dst_addr(ImageCtx *ictx, uint64_t off, uint64_t *obj_offset,
+                                char *obj_addr, uint32_t *obj_id);
+#endif
   void readahead(ImageCtx *ictx,
                  const vector<pair<uint64_t,uint64_t> >& image_extents);
 
diff --git a/src/librbd/io/ImageDispatchSpec.h b/src/librbd/io/ImageDispatchSpec.h
index 93c53a0f..7551fb0c 100644
--- a/src/librbd/io/ImageDispatchSpec.h
+++ b/src/librbd/io/ImageDispatchSpec.h
@@ -121,7 +121,11 @@ public:
     return new ImageDispatchSpec(image_ctx, aio_comp, {}, Flush{flush_source},
                                  0, parent_trace);
   }
-
+#ifdef WITH_GLOBAL_CACHE
+  AioCompletion* get_completion() {
+    return m_aio_comp;
+  }
+#endif
   void send();
   void fail(int r);
 
diff --git a/src/librbd/io/ImageRequestWQ.cc b/src/librbd/io/ImageRequestWQ.cc
index 34f2c2cf..eee8eeb2 100644
--- a/src/librbd/io/ImageRequestWQ.cc
+++ b/src/librbd/io/ImageRequestWQ.cc
@@ -23,6 +23,9 @@
                            << " " << __func__ << ": "
 
 namespace librbd {
+
+using util::create_context_callback;
+
 namespace io {
 
 namespace {
@@ -286,7 +289,13 @@ void ImageRequestWQ<I>::aio_read(AioCompletion *c, uint64_t off, uint64_t len,
   RWLock::RLocker owner_locker(m_image_ctx.owner_lock);
   if (m_image_ctx.non_blocking_aio || writes_blocked() || !writes_empty() ||
       require_lock_on_read()) {
+#ifdef WITH_GLOBAL_CACHE
+    ceph::timespan elapsed = coarse_mono_clock::now() - c->start_time;
+    m_image_ctx.perfcounter->tinc(l_librbd_rd_before_queue_op_lat, elapsed);
+    queue(ImageDispatchSpec<I>::create_read_request(
+#else
     queue(ImageDispatchSpec<I>::create_read_request(
+#endif 
             m_image_ctx, c, {{off, len}}, std::move(read_result), op_flags,
             trace));
   } else {
@@ -325,7 +334,13 @@ void ImageRequestWQ<I>::aio_write(AioCompletion *c, uint64_t off, uint64_t len,
 
   RWLock::RLocker owner_locker(m_image_ctx.owner_lock);
   if (m_image_ctx.non_blocking_aio || writes_blocked()) {
+#ifdef WITH_GLOBAL_CACHE
+    ceph::timespan elapsed = coarse_mono_clock::now() - c->start_time;
+    m_image_ctx.perfcounter->tinc(l_librbd_wr_before_queue_op_lat, elapsed);
     queue(ImageDispatchSpec<I>::create_write_request(
+#else
+    queue(ImageDispatchSpec<I>::create_write_request(
+#endif 
             m_image_ctx, c, {{off, len}}, std::move(bl), op_flags, trace));
   } else {
     c->start_op();
@@ -755,7 +770,11 @@ void *ImageRequestWQ<I>::_void_dequeue() {
       } else {
         // stall IO until the acquire completes
         ++m_io_blockers;
-        m_image_ctx.exclusive_lock->acquire_lock(new C_AcquireLock(this, item));
+        Context *ctx = new C_AcquireLock(this, item);
+        ctx = create_context_callback<
+          Context, &Context::complete>(
+            ctx, m_image_ctx.exclusive_lock);
+        m_image_ctx.exclusive_lock->acquire_lock(ctx);
       }
     } else {
       // raced with the exclusive lock being disabled
@@ -790,8 +809,16 @@ void ImageRequestWQ<I>::process(ImageDispatchSpec<I> *req) {
   CephContext *cct = m_image_ctx.cct;
   ldout(cct, 20) << "ictx=" << &m_image_ctx << ", "
                  << "req=" << req << dendl;
-
+#ifdef WITH_GLOBAL_CACHE
+  ceph::timespan elapsed = coarse_mono_clock::now() - req->get_completion()->start_time;
+  m_image_ctx.perfcounter->tinc(l_librbd_after_dequeue_op_lat, elapsed);
+  coarse_mono_time before_send = coarse_mono_clock::now();
+#endif
   req->send();
+#ifdef WITH_GLOBAL_CACHE
+  ceph::timespan send_time = coarse_mono_clock::now() - before_send;
+  m_image_ctx.perfcounter->tinc(l_librbd_send_lat, send_time);
+#endif
 
   finish_queued_io(req);
   if (req->is_write_op()) {
@@ -905,6 +932,10 @@ void ImageRequestWQ<I>::queue(ImageDispatchSpec<I> *req) {
   } else {
     m_queued_reads++;
   }
+#ifdef WITH_GLOBAL_CACHE
+  m_image_ctx.perfcounter->set(l_librbd_rd_queue, m_queued_reads);
+  m_image_ctx.perfcounter->set(l_librbd_wr_queue, m_queued_writes);
+#endif
 
   ThreadPool::PointerWQ<ImageDispatchSpec<I> >::queue(req);
 }
diff --git a/src/librbd/journal/ObjectDispatch.cc b/src/librbd/journal/ObjectDispatch.cc
index 737f5efe..9a514cec 100644
--- a/src/librbd/journal/ObjectDispatch.cc
+++ b/src/librbd/journal/ObjectDispatch.cc
@@ -18,6 +18,8 @@
 namespace librbd {
 namespace journal {
 
+using util::create_context_callback;
+
 namespace {
 
 template <typename I>
@@ -91,7 +93,8 @@ bool ObjectDispatch<I>::discard(
   *on_finish = new C_CommitIOEvent<I>(m_image_ctx, m_journal, object_no,
                                       object_off, object_len, *journal_tid,
                                       *object_dispatch_flags, *on_finish);
-
+  *on_finish = create_context_callback<
+    Context, &Context::complete>(*on_finish, m_journal);
   *dispatch_result = io::DISPATCH_RESULT_CONTINUE;
   wait_or_flush_event(*journal_tid, *object_dispatch_flags, on_dispatched);
   return true;
@@ -115,7 +118,8 @@ bool ObjectDispatch<I>::write(
   *on_finish = new C_CommitIOEvent<I>(m_image_ctx, m_journal, object_no,
                                       object_off, data.length(), *journal_tid,
                                       *object_dispatch_flags, *on_finish);
-
+  *on_finish = create_context_callback<
+    Context, &Context::complete>(*on_finish, m_journal);
   *dispatch_result = io::DISPATCH_RESULT_CONTINUE;
   wait_or_flush_event(*journal_tid, *object_dispatch_flags, on_dispatched);
   return true;
@@ -140,7 +144,8 @@ bool ObjectDispatch<I>::write_same(
   *on_finish = new C_CommitIOEvent<I>(m_image_ctx, m_journal, object_no,
                                       object_off, object_len, *journal_tid,
                                       *object_dispatch_flags, *on_finish);
-
+  *on_finish = create_context_callback<
+    Context, &Context::complete>(*on_finish, m_journal);
   *dispatch_result = io::DISPATCH_RESULT_CONTINUE;
   wait_or_flush_event(*journal_tid, *object_dispatch_flags, on_dispatched);
   return true;
@@ -168,7 +173,8 @@ bool ObjectDispatch<I>::compare_and_write(
                                       object_off, write_data.length(),
                                       *journal_tid, *object_dispatch_flags,
                                       *on_finish);
-
+  *on_finish = create_context_callback<
+    Context, &Context::complete>(*on_finish, m_journal);
   *dispatch_result = io::DISPATCH_RESULT_CONTINUE;
   wait_or_flush_event(*journal_tid, *object_dispatch_flags, on_dispatched);
   return true;
@@ -182,14 +188,16 @@ void ObjectDispatch<I>::extent_overwritten(
   ldout(cct, 20) << object_no << " " << object_off << "~" << object_len
                  << dendl;
 
-  auto ctx = new C_CommitIOEvent<I>(m_image_ctx, m_journal, object_no,
-                                    object_off, object_len, journal_tid, false,
-                                    nullptr);
+  Context *ctx = new C_CommitIOEvent<I>(m_image_ctx, m_journal, object_no,
+                                        object_off, object_len, journal_tid, false,
+                                        nullptr);
   if (new_journal_tid != 0) {
     // ensure new journal event is safely committed to disk before
     // committing old event
     m_journal->flush_event(new_journal_tid, ctx);
   } else {
+    ctx = create_context_callback<
+      Context, &Context::complete>(ctx, m_journal);
     ctx->complete(0);
   }
 }
diff --git a/src/librbd/journal/Replay.cc b/src/librbd/journal/Replay.cc
index f96153e7..66e138e9 100644
--- a/src/librbd/journal/Replay.cc
+++ b/src/librbd/journal/Replay.cc
@@ -178,6 +178,7 @@ Replay<I>::Replay(I &image_ctx)
 
 template <typename I>
 Replay<I>::~Replay() {
+  std::lock_guard locker{m_lock};
   ceph_assert(m_in_flight_aio_flush == 0);
   ceph_assert(m_in_flight_aio_modify == 0);
   ceph_assert(m_aio_modify_unsafe_contexts.empty());
diff --git a/src/librbd/librbd.cc b/src/librbd/librbd.cc
index 749f5cb5..d63b3b5d 100644
--- a/src/librbd/librbd.cc
+++ b/src/librbd/librbd.cc
@@ -2154,6 +2154,39 @@ namespace librbd {
     tracepoint(librbd, read_iterate2_exit, r);
     return (int)r;
   }
+#ifdef WITH_GLOBAL_CACHE
+  int Image::get_data_dst_addr(uint64_t off, uint64_t *obj_offset,
+                            char *obj_addr, uint32_t *obj_id)
+  {
+      ImageCtx *ictx = (ImageCtx *)ctx;
+      int64_t r = librbd::internal_get_data_dst_addr(ictx, off, obj_offset, obj_addr, obj_id);
+      return (int)r;
+  }
+
+  ssize_t Image::client_image_read(uint32_t objId, uint32_t objOffset,
+                            char* buf, size_t len)
+  {
+    ImageCtx *ictx = (ImageCtx *)ctx;
+    uint64_t ofs = (uint64_t)objId * ictx->layout.object_size + objOffset;
+    tracepoint(librbd, read_enter, ictx, ictx->name.c_str(), ictx->snap_name.c_str(), ictx->read_only, ofs, len);
+    uint32_t r = ictx->io_work_queue->read(ofs, len, librbd::io::ReadResult{buf, len},
+                                    0);
+    tracepoint(librbd, read_exit, r);
+    return r;
+  }
+
+  ssize_t Image::client_image_aio_read(uint32_t objId, uint32_t objOffset,
+                            char* buf, size_t len, RBD::AioCompletion *c)
+  {
+    ImageCtx *ictx = (ImageCtx *)ctx;
+    uint64_t off = (uint64_t)objId * ictx->layout.object_size + objOffset;
+    tracepoint(librbd, aio_read_enter, ictx, ictx->name.c_str(), ictx->snap_name.c_str(), ictx->read_only, off, len, buf, c->pc);
+    ictx->io_work_queue->aio_read(get_aio_completion(c), off, len,
+                                    librbd::io::ReadResult{buf, len}, 0);
+    tracepoint(librbd, aio_read_exit, 0);
+    return 0;
+  }
+#endif
 
   int Image::diff_iterate(const char *fromsnapname,
 			  uint64_t ofs, uint64_t len,
@@ -5129,6 +5162,39 @@ extern "C" int rbd_read_iterate2(rbd_image_t image, uint64_t ofs, uint64_t len,
   tracepoint(librbd, read_iterate2_exit, r);
   return (int)r;
 }
+#ifdef WITH_GLOBAL_CACHE
+extern "C" void rbd_get_date_dts_addr(rbd_image_t image, uint64_t offset, uint64_t *objOffset,
+                    char *objAddr, uint32_t *objId)
+{
+    librbd::ImageCtx *ictx = (librbd::ImageCtx *)image;
+    librbd::internal_get_data_dst_addr(ictx, offset, objOffset, objAddr, objId);
+}
+
+extern "C" int rbd_client_image_read(rbd_image_t image, uint32_t objId, uint32_t objOffset,
+                    char* buf, size_t len)
+{
+    librbd::ImageCtx *ictx = (librbd::ImageCtx *)image;
+    uint64_t ofs = (uint64_t)objId * ictx->layout.object_size + objOffset;
+    tracepoint(librbd, read_enter, ictx, ictx->name.c_str(), ictx->snap_name.c_str(), ictx->read_only, ofs, len);
+    int r = ictx->io_work_queue->read(ofs, len, librbd::io::ReadResult{buf, len},
+                                    0);
+    tracepoint(librbd, read_exit, r);
+    return r;
+}
+
+extern "C" int rbd_client_image_aio_read(rbd_image_t image, uint32_t objId, uint32_t objOffset,
+                char *buf, size_t len, rbd_completion_t c)
+{
+  librbd::ImageCtx *ictx = (librbd::ImageCtx *)image;
+  librbd::RBD::AioCompletion *comp = (librbd::RBD::AioCompletion *)c;
+  uint64_t off = (uint64_t)objId * ictx->layout.object_size + objOffset;
+  tracepoint(librbd, aio_read_enter, ictx, ictx->name.c_str(), ictx->snap_name.c_str(), ictx->read_only, off, len, buf, comp->pc);
+  ictx->io_work_queue->aio_read(get_aio_completion(comp), off, len,
+                                librbd::io::ReadResult{buf, len}, 0);
+  tracepoint(librbd, aio_read_exit, 0);
+  return 0;
+}
+#endif
 
 extern "C" int rbd_diff_iterate(rbd_image_t image,
 				const char *fromsnapname,
diff --git a/src/librbd/mirror/DemoteRequest.cc b/src/librbd/mirror/DemoteRequest.cc
index c5d38752..7f5a5859 100644
--- a/src/librbd/mirror/DemoteRequest.cc
+++ b/src/librbd/mirror/DemoteRequest.cc
@@ -88,7 +88,8 @@ void DemoteRequest<I>::acquire_lock() {
   ldout(cct, 20) << dendl;
 
   auto ctx = create_context_callback<
-    DemoteRequest<I>, &DemoteRequest<I>::handle_acquire_lock>(this);
+    DemoteRequest<I>,
+    &DemoteRequest<I>::handle_acquire_lock>(this, m_image_ctx.exclusive_lock);
   m_image_ctx.exclusive_lock->acquire_lock(ctx);
   m_image_ctx.owner_lock.put_read();
 }
@@ -154,7 +155,8 @@ void DemoteRequest<I>::release_lock() {
   }
 
   auto ctx = create_context_callback<
-    DemoteRequest<I>, &DemoteRequest<I>::handle_release_lock>(this);
+     DemoteRequest<I>,
+    &DemoteRequest<I>::handle_release_lock>(this, m_image_ctx.exclusive_lock);
   m_image_ctx.exclusive_lock->release_lock(ctx);
   m_image_ctx.owner_lock.put_read();
 }
diff --git a/src/librbd/operation/DisableFeaturesRequest.cc b/src/librbd/operation/DisableFeaturesRequest.cc
index dc58a989..41cd826b 100644
--- a/src/librbd/operation/DisableFeaturesRequest.cc
+++ b/src/librbd/operation/DisableFeaturesRequest.cc
@@ -124,20 +124,15 @@ Context *DisableFeaturesRequest<I>::handle_block_writes(int *result) {
     }
   }
 
-  send_acquire_exclusive_lock();
-  return nullptr;
+  return send_acquire_exclusive_lock(result);
 }
 
 template <typename I>
-void DisableFeaturesRequest<I>::send_acquire_exclusive_lock() {
+Context *DisableFeaturesRequest<I>::send_acquire_exclusive_lock(int *result) {
   I &image_ctx = this->m_image_ctx;
   CephContext *cct = image_ctx.cct;
   ldout(cct, 20) << this << " " << __func__ << dendl;
 
-  Context *ctx = create_context_callback<
-    DisableFeaturesRequest<I>,
-    &DisableFeaturesRequest<I>::handle_acquire_exclusive_lock>(this);
-
   {
     RWLock::WLocker locker(image_ctx.owner_lock);
     // if disabling features w/ exclusive lock supported, we need to
@@ -145,13 +140,17 @@ void DisableFeaturesRequest<I>::send_acquire_exclusive_lock() {
     if (image_ctx.exclusive_lock != nullptr &&
 	!image_ctx.exclusive_lock->is_lock_owner()) {
       m_acquired_lock = true;
-
+      
+      Context *ctx = create_context_callback<
+        DisableFeaturesRequest<I>,
+        &DisableFeaturesRequest<I>::handle_acquire_exclusive_lock>(
+          this, image_ctx.exclusive_lock);
       image_ctx.exclusive_lock->acquire_lock(ctx);
-      return;
+      return nullptr;
     }
   }
 
-  ctx->complete(0);
+  return handle_acquire_exclusive_lock(result);
 }
 
 template <typename I>
@@ -385,7 +384,7 @@ Context *DisableFeaturesRequest<I>::handle_close_journal(int *result) {
   }
 
   ceph_assert(m_journal != nullptr);
-  delete m_journal;
+  m_journal->put();
   m_journal = nullptr;
 
   send_remove_journal();
@@ -607,7 +606,8 @@ void DisableFeaturesRequest<I>::send_release_exclusive_lock() {
 
   Context *ctx = create_context_callback<
     DisableFeaturesRequest<I>,
-    &DisableFeaturesRequest<I>::handle_release_exclusive_lock>(this);
+    &DisableFeaturesRequest<I>::handle_release_exclusive_lock>(
+      this, image_ctx.exclusive_lock);
 
   image_ctx.exclusive_lock->release_lock(ctx);
 }
diff --git a/src/librbd/operation/DisableFeaturesRequest.h b/src/librbd/operation/DisableFeaturesRequest.h
index b064bc45..bb446e80 100644
--- a/src/librbd/operation/DisableFeaturesRequest.h
+++ b/src/librbd/operation/DisableFeaturesRequest.h
@@ -124,7 +124,7 @@ private:
   void send_block_writes();
   Context *handle_block_writes(int *result);
 
-  void send_acquire_exclusive_lock();
+  Context *send_acquire_exclusive_lock(int *result);
   Context *handle_acquire_exclusive_lock(int *result);
 
   void send_get_mirror_mode();
diff --git a/src/librbd/operation/RebuildObjectMapRequest.cc b/src/librbd/operation/RebuildObjectMapRequest.cc
index f923f36c..8de8dd5a 100644
--- a/src/librbd/operation/RebuildObjectMapRequest.cc
+++ b/src/librbd/operation/RebuildObjectMapRequest.cc
@@ -24,6 +24,8 @@
 namespace librbd {
 namespace operation {
 
+using util::create_context_callback;
+
 template <typename I>
 void RebuildObjectMapRequest<I>::send() {
   send_resize_object_map();
diff --git a/src/librbd/operation/SnapshotCreateRequest.cc b/src/librbd/operation/SnapshotCreateRequest.cc
index 66293609..55675c78 100644
--- a/src/librbd/operation/SnapshotCreateRequest.cc
+++ b/src/librbd/operation/SnapshotCreateRequest.cc
@@ -11,6 +11,11 @@
 #include "librbd/Utils.h"
 #include "librbd/io/ImageRequestWQ.h"
 
+#ifdef WITH_GLOBAL_CACHE
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMgr.h"
+#endif
+
 #define dout_subsys ceph_subsys_rbd
 #undef dout_prefix
 #define dout_prefix *_dout << "librbd::SnapshotCreateRequest: "
@@ -45,6 +50,16 @@ void SnapshotCreateRequest<I>::send_op() {
     return;
   }
 
+#ifdef WITH_GLOBAL_CACHE
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  if (plugin == NULL) {
+      lderr(cct) << "client adaptor plugin not loaded" << dendl;
+      this->async_complete(-ELIBACC);
+      return;
+  }
+#endif
+
   send_suspend_requests();
 }
 
@@ -104,7 +119,11 @@ void SnapshotCreateRequest<I>::send_append_op_event() {
   if (!this->template append_op_event<
         SnapshotCreateRequest<I>,
         &SnapshotCreateRequest<I>::handle_append_op_event>(this)) {
+#ifdef WITH_GLOBAL_CACHE
+    send_allocate_fake_snap_id();
+#else
     send_allocate_snap_id();
+#endif
     return;
   }
 
@@ -124,10 +143,47 @@ Context *SnapshotCreateRequest<I>::handle_append_op_event(int *result) {
                << dendl;
     return this->create_context_finisher(*result);
   }
+#ifdef WITH_GLOBAL_CACHE
+    send_allocate_fake_snap_id();
+#else
+    send_allocate_snap_id();
+#endif
+  return nullptr;
+}
+
+#ifdef WITH_GLOBAL_CACHE
+template <typename I>
+void SnapshotCreateRequest<I>::send_allocate_fake_snap_id() {
+  I &image_ctx = this->m_image_ctx;
+  CephContext *cct = image_ctx.cct;
+  ldout(cct, 5) << this << " " << __func__ << dendl;
+
+  librados::AioCompletion *rados_completion = create_rados_callback<
+    SnapshotCreateRequest<I>,
+    &SnapshotCreateRequest<I>::handle_allocate_fake_snap_id>(this);
+  image_ctx.data_ctx.aio_selfmanaged_snap_create(&m_fake_snap_id, rados_completion);
+  rados_completion->release();
+}
+
+template <typename I>
+Context *SnapshotCreateRequest<I>::handle_allocate_fake_snap_id(int *result) {
+  I &image_ctx = this->m_image_ctx;
+  CephContext *cct = image_ctx.cct;
+  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << ", "
+                << "fake snap_id=" << m_fake_snap_id << dendl;
+
+  if (*result < 0) {
+    save_result(result);
+    image_ctx.io_work_queue->unblock_writes();
+    lderr(cct) << "failed to allocate fake snapshot id: " << cpp_strerror(*result)
+               << dendl;
+    return this->create_context_finisher(*result);
+  }
 
   send_allocate_snap_id();
   return nullptr;
 }
+#endif
 
 template <typename I>
 void SnapshotCreateRequest<I>::send_allocate_snap_id() {
@@ -210,8 +266,50 @@ Context *SnapshotCreateRequest<I>::handle_create_snap(int *result) {
     return nullptr;
   }
 
+#ifdef WITH_GLOBAL_CACHE
+  if (image_ctx.md_ctx.check_acc() && !m_skip_gc) {
+    return send_add_snap_to_gc();
+  } else {
+    return send_create_object_map();
+  }
+#else
   return send_create_object_map();
+#endif
+}
+
+#ifdef WITH_GLOBAL_CACHE
+template <typename I>
+Context *SnapshotCreateRequest<I>::send_add_snap_to_gc() {
+    I &image_ctx = this->m_image_ctx;
+    CephContext *cct = image_ctx.cct;
+    int64_t md_pool_id = image_ctx.md_ctx.get_id();
+    int64_t data_pool_id = image_ctx.data_ctx.get_id();
+    std::string pool_name;
+    ldout(cct, 5) << this << " Client Adaptor: " << __func__
+                                             << " md_pool_id: " << md_pool_id
+                                             << " data_pool_id: " << data_pool_id
+                                             << " image_id: " << image_ctx.id
+                                             << " snap_id: " << m_snap_id
+                                             << dendl;
+
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+    int mgr_ret = -ELIBACC;
+
+    if (plugin && plugin->mgr_ref) {
+        mgr_ret = plugin->mgr_ref->add_snap_to_gc(md_pool_id, data_pool_id, image_ctx.id, m_snap_id);
+    }
+
+    if (mgr_ret < 0) {
+        lderr(cct) << __func__ << " Client Adaptor: " << "gc create snapshot failed" << dendl;
+        save_result(&mgr_ret);
+        send_release_snap();
+        return nullptr;
+    }
+    ldout(cct, 20) << __func__ << " Client Adaptor: " << "gc create snapshot success" << dendl;
+    return send_create_object_map();
 }
+#endif
 
 template <typename I>
 Context *SnapshotCreateRequest<I>::send_create_object_map() {
@@ -257,6 +355,43 @@ Context *SnapshotCreateRequest<I>::handle_create_object_map(int *result) {
   return this->create_context_finisher(0);
 }
 
+#ifdef WITH_GLOBAL_CACHE
+template <typename I>
+void SnapshotCreateRequest<I>::send_release_snap() {
+    I &image_ctx = this->m_image_ctx;
+    CephContext *cct = image_ctx.cct;
+    ldout(cct, 5) << this << " " << __func__ << dendl;
+
+    librados::ObjectWriteOperation op;
+    if (image_ctx.old_format) {
+        cls_client::old_snapshot_remove(&op, m_snap_name);
+    } else {
+        cls_client::snapshot_remove(&op, m_snap_id);
+    }
+
+    librados::AioCompletion *rados_completion = create_rados_callback<
+        SnapshotCreateRequest<I>,
+        &SnapshotCreateRequest<I>::handle_release_snap>(this);
+    int r = image_ctx.md_ctx.aio_operate(image_ctx.header_oid,
+                                        rados_completion, &op);
+    ceph_assert(r == 0);
+    rados_completion->release();
+}
+
+template <typename I>
+Context *SnapshotCreateRequest<I>::handle_release_snap(int *result) {
+    I &image_ctx = this->m_image_ctx;
+    CephContext *cct = image_ctx.cct;
+    ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
+
+    ceph_assert(m_ret_val < 0);
+    *result = m_ret_val;
+
+    send_release_snap_id();
+    return nullptr;
+}
+#endif
+
 template <typename I>
 void SnapshotCreateRequest<I>::send_release_snap_id() {
   I &image_ctx = this->m_image_ctx;
diff --git a/src/librbd/operation/SnapshotCreateRequest.h b/src/librbd/operation/SnapshotCreateRequest.h
index 406d2f01..ff04609c 100644
--- a/src/librbd/operation/SnapshotCreateRequest.h
+++ b/src/librbd/operation/SnapshotCreateRequest.h
@@ -31,26 +31,32 @@ public:
    *           STATE_SUSPEND_REQUESTS
    *               |
    *               v
-   *           STATE_SUSPEND_AIO * * * * * * * * * * * * *
-   *               |                                     *
-   *               v                                     *
-   *           STATE_APPEND_OP_EVENT (skip if journal    *
-   *               |                  disabled)          *
-   *   (retry)     v                                     *
-   *   . . . > STATE_ALLOCATE_SNAP_ID                    *
-   *   .           |                                     *
-   *   .           v                                     *
-   *   . . . . STATE_CREATE_SNAP * * * * * * * * * *     *
-   *               |                               *     *
-   *               v                               *     *
-   *           STATE_CREATE_OBJECT_MAP (skip if    *     *
-   *               |                    disabled)  *     *
-   *               |                               *     *
-   *               |                               v     *
-   *               |              STATE_RELEASE_SNAP_ID  *
-   *               |                     |               *
-   *               |                     v               *
-   *               \----------------> <finish> < * * * * *
+   *           STATE_SUSPEND_AIO * * * * * * * * * * * * * * *
+   *               |                                         *
+   *               v                                         *
+   *           STATE_APPEND_OP_EVENT (skip if journal        *
+   *               |                  disabled)              *
+   *   (retry)     v                                         *
+   *   . . . > STATE_ALLOCATE_SNAP_ID                        *
+   *   .           |                                         *
+   *   .           v                                         *
+   *   . . . . STATE_CREATE_SNAP * * * * * * * * * * * *     *
+   *               |                                   *     *
+   *               v                                   *     *
+   *           STATE_ADD_SNAP_TO_GC  (skip if no       *     *
+   *               |                  gc)  * * * * *   *     *
+   *               v                               *   *     *
+   *           STATE_CREATE_OBJECT_MAP (skip if    *   *     *
+   *               |                    disabled)  *   *     *
+   *               |                               *   *     *
+   *               |                               v   *     *
+   *               |                STATE_RELEASE_SNAP *     *
+   *               |                               *   *     *
+   *               |                               v   v     *
+   *               |                   STATE_RELEASE_SNAP_ID *
+   *               |                     |                   *
+   *               |                     v                   *
+   *               \----------------> <finish> < * * * * * * *
    *
    * @endverbatim
    *
@@ -64,7 +70,11 @@ public:
 		        const std::string &snap_name,
 			uint64_t journal_op_tid,
                         bool skip_object_map);
-
+#ifdef WITH_GLOBAL_CACHE
+  void skip_send_to_gc() {
+    m_skip_gc = true;
+  }
+#endif
 protected:
   void send_op() override;
   bool should_complete(int r) override {
@@ -83,6 +93,10 @@ private:
   bool m_skip_object_map;
 
   int m_ret_val;
+#ifdef WITH_GLOBAL_CACHE
+  bool m_skip_gc = false;
+  uint64_t m_fake_snap_id;
+#endif
 
   uint64_t m_snap_id;
   uint64_t m_size;
@@ -97,15 +111,29 @@ private:
   void send_append_op_event();
   Context *handle_append_op_event(int *result);
 
+#ifdef WITH_GLOBAL_CACHE
+  void send_allocate_fake_snap_id();
+  Context *handle_allocate_fake_snap_id(int *result);
+#endif
+
   void send_allocate_snap_id();
   Context *handle_allocate_snap_id(int *result);
 
   void send_create_snap();
   Context *handle_create_snap(int *result);
 
+#ifdef WITH_GLOBAL_CACHE
+  Context *send_add_snap_to_gc();
+#endif
+
   Context *send_create_object_map();
   Context *handle_create_object_map(int *result);
 
+#ifdef WITH_GLOBAL_CACHE
+  void send_release_snap();
+  Context *handle_release_snap(int *result);
+#endif
+
   void send_release_snap_id();
   Context *handle_release_snap_id(int *result);
 
diff --git a/src/librbd/operation/SnapshotRemoveRequest.cc b/src/librbd/operation/SnapshotRemoveRequest.cc
index 69fbc3e7..4f97c6ba 100644
--- a/src/librbd/operation/SnapshotRemoveRequest.cc
+++ b/src/librbd/operation/SnapshotRemoveRequest.cc
@@ -5,7 +5,6 @@
 #include "common/dout.h"
 #include "common/errno.h"
 #include "cls/rbd/cls_rbd_client.h"
-#include "librbd/ExclusiveLock.h"
 #include "librbd/ImageCtx.h"
 #include "librbd/ObjectMap.h"
 #include "librbd/Utils.h"
diff --git a/src/librbd/operation/SnapshotRenameRequest.cc b/src/librbd/operation/SnapshotRenameRequest.cc
index b25b991f..e1e1871f 100644
--- a/src/librbd/operation/SnapshotRenameRequest.cc
+++ b/src/librbd/operation/SnapshotRenameRequest.cc
@@ -4,7 +4,6 @@
 #include "librbd/operation/SnapshotRenameRequest.h"
 #include "common/dout.h"
 #include "common/errno.h"
-#include "librbd/ExclusiveLock.h"
 #include "librbd/ImageCtx.h"
 
 #define dout_subsys ceph_subsys_rbd
diff --git a/src/librbd/operation/SnapshotRollbackRequest.cc b/src/librbd/operation/SnapshotRollbackRequest.cc
index 596570a3..61d49b36 100644
--- a/src/librbd/operation/SnapshotRollbackRequest.cc
+++ b/src/librbd/operation/SnapshotRollbackRequest.cc
@@ -2,6 +2,8 @@
 // vim: ts=8 sw=2 smarttab
 
 #include "librbd/operation/SnapshotRollbackRequest.h"
+#include "librbd/operation/SnapshotCreateRequest.h"
+#include "librbd/operation/SnapshotRemoveRequest.h"
 #include "include/rados/librados.hpp"
 #include "common/dout.h"
 #include "common/errno.h"
@@ -15,6 +17,11 @@
 #include "osdc/Striper.h"
 #include <boost/lambda/bind.hpp>
 #include <boost/lambda/construct.hpp>
+#ifdef WITH_GLOBAL_CACHE
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMgr.h"
+#include "client_adaptor/ClientAdaptorMsg.h"
+#endif
 
 #define dout_subsys ceph_subsys_rbd
 #undef dout_prefix
@@ -97,8 +104,14 @@ SnapshotRollbackRequest<I>::~SnapshotRollbackRequest() {
   if (m_blocking_writes) {
     image_ctx.io_work_queue->unblock_writes();
   }
-  delete m_object_map;
-  delete m_snap_object_map;
+  if (m_object_map) {
+    m_object_map->put();
+    m_object_map = nullptr;
+  }
+  if (m_snap_object_map) {
+    m_snap_object_map->put();
+    m_snap_object_map = nullptr;
+  }
 }
 
 template <typename I>
@@ -225,7 +238,7 @@ Context *SnapshotRollbackRequest<I>::handle_get_snap_object_map(int *result) {
   if (*result < 0) {
     lderr(cct) << this << " " << __func__ << ": failed to open object map: "
                << cpp_strerror(*result) << dendl;
-    delete m_snap_object_map;
+    m_snap_object_map->put();
     m_snap_object_map = nullptr;
   }
 
@@ -252,7 +265,12 @@ void SnapshotRollbackRequest<I>::send_rollback_object_map() {
       return;
     }
   }
-
+#ifdef WITH_GLOBAL_CACHE
+    if (image_ctx.md_ctx.check_acc()) {
+        send_gc_snap_create(1);
+        return;
+    }
+#endif
   send_rollback_objects();
 }
 
@@ -270,11 +288,181 @@ Context *SnapshotRollbackRequest<I>::handle_rollback_object_map(int *result) {
     apply();
     return this->create_context_finisher(*result);
   }
-
+#ifdef WITH_GLOBAL_CACHE
+    if (image_ctx.md_ctx.check_acc()) {
+        send_gc_snap_create(1);
+        return nullptr;
+    }
+#endif
   send_rollback_objects();
   return nullptr;
 }
 
+#ifdef WITH_GLOBAL_CACHE
+template <typename I>
+void SnapshotRollbackRequest<I>::send_gc_snap_create(int num) {
+    I &image_ctx = this->m_image_ctx;
+    CephContext *cct = image_ctx.cct;
+    ldout(cct, 5) << this << " " << __func__ << dendl;
+
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+
+    if (!plugin || !plugin->msg_ref) {
+        lderr(cct) << " " << __func__ << ": load plugin failed! plugin=" << plugin << dendl;
+        this->complete(-ELIBACC);
+        return;
+    }
+
+    string snap_name;
+    plugin->msg_ref->gen_random_gc_snap(m_snap_id, num, snap_name);
+    if (num == 1) {
+        m_gc_snap_name1 = snap_name;
+    } else {
+        m_gc_snap_name2 = snap_name;
+    }
+    ldout(cct, 20) << this << " : create snap " << snap_name << dendl;
+
+    RWLock::RLocker owner_locker(image_ctx.owner_lock);
+    Context *ctx = create_context_callback<
+        SnapshotRollbackRequest<I>,
+        &SnapshotRollbackRequest<I>::handle_send_gc_snap_create>(this);
+    SnapshotCreateRequest<I> *req = new SnapshotCreateRequest<I>(
+        image_ctx, ctx, m_snap_namespace, snap_name, 0, false);
+    req->skip_send_to_gc();
+    req->send();
+}
+
+template <typename I>
+Context *SnapshotRollbackRequest<I>::handle_send_gc_snap_create(int *result) {
+    I &image_ctx = this->m_image_ctx;
+    CephContext *cct = image_ctx.cct;
+    ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
+    if (*result < 0) {
+        save_result(*result);
+        return send_gc_snap_remove();
+    }
+    if (m_gc_snap_name2.empty()) {
+        m_prog_ctx.update_progress(1, 100);
+        send_gc_snap_create(2);
+        return nullptr;
+    }
+    m_prog_ctx.update_progress(2, 100);
+    send_gc_rollback();
+    return nullptr;
+}
+template <typename I>
+Context *SnapshotRollbackRequest<I>::send_gc_snap_remove() {
+    I &image_ctx = this->m_image_ctx;
+    CephContext *cct = image_ctx.cct;
+    ldout(cct, 5) << this << " " << __func__ << dendl;
+
+    string snap_name;
+    if (!m_gc_snap_name1.empty()) {
+        snap_name = m_gc_snap_name1;
+        m_gc_snap_name1 = "";
+    } else {
+        snap_name = m_gc_snap_name2;
+        m_gc_snap_name2 = "";
+    }
+
+    if (snap_name.empty()) {
+        lderr(cct) << this << " rollback failed, return " << m_ret_val << dendl;
+        this->complete(m_ret_val);
+        return nullptr;
+    }
+    RWLock::RLocker owner_locker(image_ctx.owner_lock);
+    image_ctx.snap_lock.get_read();
+    uint64_t snap_id = image_ctx.get_snap_id(m_snap_namespace, snap_name);
+    if (snap_id == CEPH_NOSNAP) {
+        ldout(cct, 20) << this << " " << __func__ << " "
+                        << snap_name << " not exists" << dendl;
+        image_ctx.snap_lock.put_read();
+        this->complete(m_ret_val);
+        return nullptr;
+    }
+    image_ctx.snap_lock.put_read();
+
+    Context *ctx = create_context_callback<
+        SnapshotRollbackRequest<I>,
+        &SnapshotRollbackRequest<I>::handle_send_gc_snap_remove>(this);
+    operation::SnapshotRemoveRequest<I> *req = new operation::SnapshotRemoveRequest<I>(
+        image_ctx, ctx, m_snap_namespace, snap_name, snap_id);
+    req->send();
+    return nullptr;
+}
+template <typename I>
+Context *SnapshotRollbackRequest<I>::handle_send_gc_snap_remove(int *result) {
+    I &image_ctx = this->m_image_ctx;
+    CephContext *cct = image_ctx.cct;
+    ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
+    if (*result < 0) {
+        this->complete(m_ret_val);
+        return nullptr;
+    }
+
+    return send_gc_snap_remove();
+}
+
+template <typename I>
+void SnapshotRollbackRequest<I>::send_gc_rollback() {
+    I &image_ctx = this->m_image_ctx;
+    CephContext *cct = image_ctx.cct;
+    ldout(cct, 5) << this << " " << __func__ << dendl;
+    this->m_image_ctx.op_work_queue->queue(create_context_callback<
+                                SnapshotRollbackRequest<I>,
+                                &SnapshotRollbackRequest<I>::handle_send_gc_rollback>(this), 0);
+}
+
+template <typename I>
+Context *SnapshotRollbackRequest<I>::handle_send_gc_rollback(int *result) {
+    I &image_ctx = this->m_image_ctx;
+    CephContext *cct = image_ctx.cct;
+    ldout(cct, 5) << this << " " << __func__ << dendl;
+
+    int64_t pool_id = image_ctx.md_ctx.get_id();
+    int64_t data_pool_id = image_ctx.data_ctx.get_id();
+
+    image_ctx.snap_lock.get_read();
+    uint64_t tp_snap_id1 = image_ctx.get_snap_id(m_snap_namespace, m_gc_snap_name1);
+    uint64_t tp_snap_id2 = image_ctx.get_snap_id(m_snap_namespace, m_gc_snap_name2);
+    uint64_t num_objs = Striper::get_num_objects(image_ctx.layout, image_ctx.get_current_size());
+    image_ctx.snap_lock.put_read();
+
+    ceph_assert(tp_snap_id1 != CEPH_NOSNAP && tp_snap_id2 != CEPH_NOSNAP);
+    uint64_t snap_seq = 0;
+
+    // 通知ccm，等待返回
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+    int mgr_ret = -ELIBACC;
+    if (plugin && plugin->mgr_ref && plugin->msg_ref) {
+        ldout(cct, 3) << " send to gc rollback image " << pool_id << "-" << data_pool_id << "/" << image_ctx.id << dendl;
+        ldout(cct, 3) << " send to gc rollback " << m_snap_id << " => [" << tp_snap_id1 << "-" << tp_snap_id2
+                        << "]" << " seq=" << snap_seq << " num objs=" << num_objs << dendl;
+        mgr_ret = plugin->mgr_ref->rollback_gc_snap(pool_id, data_pool_id, 
+                                                    image_ctx.id, num_objs, snap_seq,
+                                                    m_snap_id, tp_snap_id1, tp_snap_id2);
+        if (mgr_ret < 0) {
+            lderr(cct) << " " << __func__ << "rollback snap failed, agent return " << mgr_ret << dendl;
+        } else {
+            ldout(cct, 20) << " gc snap rollback successful! rollback " << pool_id << "/" << image_ctx.id << "@" 
+                            << m_snap_id << dendl;
+        }
+    } else {
+        lderr(cct) << " " << __func__ << ": load plugin failed! plugin=" << plugin << dendl;
+    }
+    if (mgr_ret < 0) {
+        save_result(mgr_ret);
+        return send_gc_snap_remove();
+    } else {
+        m_prog_ctx.update_progress(100, 100);
+        send_refresh_object_map();
+    }
+    return nullptr;
+}
+#endif
+
 template <typename I>
 void SnapshotRollbackRequest<I>::send_rollback_objects() {
   I &image_ctx = this->m_image_ctx;
@@ -355,7 +543,7 @@ Context *SnapshotRollbackRequest<I>::handle_refresh_object_map(int *result) {
   if (*result < 0) {
     lderr(cct) << this << " " << __func__ << ": failed to open object map: "
                << cpp_strerror(*result) << dendl;
-    delete m_object_map;
+    m_object_map->put();
     m_object_map = nullptr;
     apply();
 
@@ -375,10 +563,18 @@ Context *SnapshotRollbackRequest<I>::send_invalidate_cache() {
   ldout(cct, 5) << this << " " << __func__ << dendl;
 
   RWLock::RLocker owner_lock(image_ctx.owner_lock);
-  Context *ctx = create_context_callback<
-    SnapshotRollbackRequest<I>,
-    &SnapshotRollbackRequest<I>::handle_invalidate_cache>(this);
-  image_ctx.io_object_dispatcher->invalidate_cache(ctx);
+  if(m_object_map != nullptr) {
+    Context *ctx = create_context_callback<
+      SnapshotRollbackRequest<I>,
+      &SnapshotRollbackRequest<I>::handle_invalidate_cache>(this, m_object_map);
+    image_ctx.io_object_dispatcher->invalidate_cache(ctx);
+  }
+  else {
+    Context *ctx = create_context_callback<
+      SnapshotRollbackRequest<I>,
+      &SnapshotRollbackRequest<I>::handle_invalidate_cache>(this);
+    image_ctx.io_object_dispatcher->invalidate_cache(ctx);
+  }
   return nullptr;
 }
 
diff --git a/src/librbd/operation/SnapshotRollbackRequest.h b/src/librbd/operation/SnapshotRollbackRequest.h
index e58a618f..2638e11a 100644
--- a/src/librbd/operation/SnapshotRollbackRequest.h
+++ b/src/librbd/operation/SnapshotRollbackRequest.h
@@ -83,6 +83,11 @@ private:
   uint64_t m_snap_size;
   uint64_t m_head_num_objects;
   ProgressContext &m_prog_ctx;
+#ifdef WITH_GLOBAL_CACHE
+  int m_ret_val = 0;
+  string m_gc_snap_name1;
+  string m_gc_snap_name2;
+#endif
 
   NoOpProgressContext m_no_op_prog_ctx;
 
@@ -110,7 +115,19 @@ private:
 
   Context *send_invalidate_cache();
   Context *handle_invalidate_cache(int *result);
-
+#ifdef WITH_GLOBAL_CACHE
+  void send_gc_snap_create(int num);
+  Context *handle_send_gc_snap_create(int *result);
+  Context *send_gc_snap_remove();
+  Context *handle_send_gc_snap_remove(int *result);
+  void send_gc_rollback();
+  Context *handle_send_gc_rollback(int *result);
+  void save_result(int result) {
+    if (m_ret_val == 0 && result < 0) {
+      m_ret_val = result;
+    }
+  }
+#endif
   void apply();
 };
 
diff --git a/src/librbd/trash/MoveRequest.cc b/src/librbd/trash/MoveRequest.cc
index 526e92ab..82b81fa3 100644
--- a/src/librbd/trash/MoveRequest.cc
+++ b/src/librbd/trash/MoveRequest.cc
@@ -5,7 +5,6 @@
 #include "common/dout.h"
 #include "common/errno.h"
 #include "cls/rbd/cls_rbd_client.h"
-#include "librbd/ExclusiveLock.h"
 #include "librbd/ImageCtx.h"
 #include "librbd/ImageState.h"
 #include "librbd/Utils.h"
diff --git a/src/msg/Message.cc b/src/msg/Message.cc
index d36a95eb..e5384c3e 100644
--- a/src/msg/Message.cc
+++ b/src/msg/Message.cc
@@ -202,6 +202,8 @@
 #include "messages/MOSDPGUpdateLogMissing.h"
 #include "messages/MOSDPGUpdateLogMissingReply.h"
 
+#include "msg/Messenger.h"
+
 #define DEBUGLVL  10    // debug level of output
 
 #define dout_subsys ceph_subsys_ms
@@ -932,12 +934,12 @@ void Message::decode_trace(bufferlist::const_iterator &p, bool create)
   const auto msgr = connection->get_messenger();
   const auto endpoint = msgr->get_trace_endpoint();
   if (info.trace_id) {
-    trace.init(get_type_name(), endpoint, &info, true);
+    trace.init(get_type_name().data(), endpoint, &info, true);
     trace.event("decoded trace");
   } else if (create || (msgr->get_myname().is_osd() &&
                         msgr->cct->_conf->osd_blkin_trace_all)) {
     // create a trace even if we didn't get one on the wire
-    trace.init(get_type_name(), endpoint);
+    trace.init(get_type_name().data(), endpoint);
     trace.event("created trace");
   }
   trace.keyval("tid", get_tid());
diff --git a/src/msg/async/AsyncConnection.cc b/src/msg/async/AsyncConnection.cc
index cab4145d..98a69dd3 100644
--- a/src/msg/async/AsyncConnection.cc
+++ b/src/msg/async/AsyncConnection.cc
@@ -360,8 +360,6 @@ void AsyncConnection::process() {
   last_active = ceph::coarse_mono_clock::now();
   recv_start_time = ceph::mono_clock::now();
 
-  ldout(async_msgr->cct, 20) << __func__ << dendl;
-
   switch (state) {
     case STATE_NONE: {
       ldout(async_msgr->cct, 20) << __func__ << " enter none state" << dendl;
@@ -758,12 +756,30 @@ void AsyncConnection::tick(uint64_t id)
   } else {
     auto idle_period = std::chrono::duration_cast<std::chrono::microseconds>
       (now - last_active).count();
+
     if (inactive_timeout_us < (uint64_t)idle_period) {
+#ifdef WITH_GLOBAL_CACHE
+      int con_port = target_addr.get_port();
+      if (con_port >= lower_port && con_port <= upper_port) {
+        ldout(async_msgr->cct, 1) << __func__ << " idle (" << idle_period
+                                << ") for more than " << inactive_timeout_us
+                                << " us, keep establish."
+                                << dendl;
+        last_tick_id = center->create_time_event(inactive_timeout_us, tick_handler);
+      } else {
+        ldout(async_msgr->cct, 1) << __func__ << " idle (" << idle_period
+                                << ") for more than " << inactive_timeout_us
+                                << " us, fault."
+                                << dendl;
+        protocol->fault();
+      }
+#else
       ldout(async_msgr->cct, 1) << __func__ << " idle (" << idle_period
                                 << ") for more than " << inactive_timeout_us
                                 << " us, fault."
                                 << dendl;
       protocol->fault();
+#endif
     } else {
       last_tick_id = center->create_time_event(inactive_timeout_us, tick_handler);
     }
diff --git a/src/msg/async/AsyncConnection.h b/src/msg/async/AsyncConnection.h
index 5b914cc5..8701b538 100644
--- a/src/msg/async/AsyncConnection.h
+++ b/src/msg/async/AsyncConnection.h
@@ -136,6 +136,16 @@ class AsyncConnection : public Connection {
     return target_addr;
   }
 
+#ifdef WITH_GLOBAL_CACHE
+  uint32_t get_port_lower_boundary() const {
+    return lower_port; 
+  }
+
+  uint32_t get_port_upper_boundary() const {
+    return upper_port;
+  }
+#endif
+
   int get_con_mode() const override;
 
  private:
@@ -202,6 +212,11 @@ class AsyncConnection : public Connection {
 
   entity_addr_t _infer_target_addr(const entity_addrvec_t& av);
 
+#ifdef WITH_GLOBAL_CACHE
+  const uint32_t lower_port = 7880;
+  const uint32_t upper_port = 7889;
+#endif
+
   // used only by "read_until"
   uint64_t state_offset;
   Worker *worker;
diff --git a/src/msg/async/ProtocolV2.cc b/src/msg/async/ProtocolV2.cc
index 4b03f5eb..a2c05c5b 100644
--- a/src/msg/async/ProtocolV2.cc
+++ b/src/msg/async/ProtocolV2.cc
@@ -13,6 +13,12 @@
 #include "auth/AuthClient.h"
 #include "auth/AuthServer.h"
 
+#ifdef WITH_GLOBAL_CACHE
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMsg.h"
+#include <iomanip>
+#endif
+
 #define dout_subsys ceph_subsys_ms
 #undef dout_prefix
 #define dout_prefix _conn_prefix(_dout)
@@ -360,7 +366,18 @@ CtPtr ProtocolV2::_fault() {
       if (backoff > cct->_conf->ms_max_backoff)
         backoff.set_from_double(cct->_conf->ms_max_backoff);
     }
-
+#ifdef WITH_GLOBAL_CACHE
+    entity_addr_t con_target_addr = connection->get_peer_socket_addr();
+    int con_port = con_target_addr.get_port();
+    uint32_t gc_lower_port = connection->get_port_lower_boundary();
+    uint32_t gc_upper_port = connection->get_port_upper_boundary();
+    if (backoff.sec() >= (__u32)trunc(cct->_conf->ms_max_backoff) && con_port >= gc_lower_port && con_port <= gc_upper_port){
+      ldout(cct, 1) << __func__ << " reconnect tiomeout more reset connection con_port "  << con_port <<  dendl;
+      stop();
+      connection->dispatch_queue->queue_reset(connection);
+      return nullptr;
+    }
+#endif
     if (server_cookie) {
       connect_seq++;
     }
@@ -1708,6 +1725,40 @@ CtPtr ProtocolV2::send_auth_request(std::vector<uint32_t> &allowed_methods) {
   vector<uint32_t> preferred_modes;
   auto am = auth_meta;
   connection->lock.unlock();
+#ifdef WITH_GLOBAL_CACHE
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ceph_assert(plugin);
+  std::shared_lock<std::shared_mutex> rlock(plugin->msg_ref->connlock);
+  bool is_gc_conn = plugin->msg_ref->connections.find(connection) != plugin->msg_ref->connections.end();
+  rlock.unlock();
+  if (is_gc_conn) {
+    ldout(cct, 3) << __func__ << " Client Adaptor: dummy get_auth_request." << dendl; 
+    am->auth_method = CEPH_AUTH_NONE;
+    preferred_modes = { CEPH_CON_MODE_CRC };
+    connection->lock.lock();
+    if (state != AUTH_CONNECTING) {
+      ldout(cct, 1) << __func__ << " state changed!" << dendl;
+      return _fault();
+    }
+  } else {
+    int r = messenger->auth_client->get_auth_request(
+      connection, am.get(),
+      &am->auth_method, &preferred_modes, &bl);
+      connection->lock.lock();
+      if (state != AUTH_CONNECTING) {
+        ldout(cct, 1) << __func__ << " state changed!" << dendl;
+        return _fault();
+      }
+      if (r < 0) {
+        ldout(cct, 0) << __func__ << " get_initial_auth_request returned " << r
+          << dendl;
+        stop();
+        connection->dispatch_queue->queue_reset(connection);
+        return nullptr;
+      }
+  }
+#else
   int r = messenger->auth_client->get_auth_request(
     connection, am.get(),
     &am->auth_method, &preferred_modes, &bl);
@@ -1723,6 +1774,7 @@ CtPtr ProtocolV2::send_auth_request(std::vector<uint32_t> &allowed_methods) {
     connection->dispatch_queue->queue_reset(connection);
     return nullptr;
   }
+#endif
 
   INTERCEPT(9);
 
@@ -1811,6 +1863,40 @@ CtPtr ProtocolV2::handle_auth_done(ceph::bufferlist &payload)
   ceph_assert(messenger->auth_client);
   auto am = auth_meta;
   connection->lock.unlock();
+#ifdef WITH_GLOBAL_CACHE
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ceph_assert(plugin);
+  std::shared_lock<std::shared_mutex> rlock(plugin->msg_ref->connlock);
+  bool is_gc_conn = plugin->msg_ref->connections.find(connection) != plugin->msg_ref->connections.end();
+  rlock.unlock();
+  if (is_gc_conn) {
+    ldout(cct, 3) << __func__ << " Client Adaptor: dummy handle_auth_done." << dendl; 
+    connection->lock.lock();
+    if (state != AUTH_CONNECTING) {
+      ldout(cct, 1) << __func__ << " state changed!" << dendl;
+      return _fault();
+    }
+  } else {
+    int r = messenger->auth_client->handle_auth_done(
+      connection,
+      am.get(),
+      auth_done.global_id(),
+      auth_done.con_mode(),
+      auth_done.auth_payload(),
+      &am->session_key,
+      &am->connection_secret);
+
+    connection->lock.lock();
+    if (state != AUTH_CONNECTING) {
+      ldout(cct, 1) << __func__ << " state changed!" << dendl;
+      return _fault();
+    }
+    if (r < 0) {
+      return _fault();
+    }
+  }
+#else
   int r = messenger->auth_client->handle_auth_done(
     connection,
     am.get(),
@@ -1819,6 +1905,7 @@ CtPtr ProtocolV2::handle_auth_done(ceph::bufferlist &payload)
     auth_done.auth_payload(),
     &am->session_key,
     &am->connection_secret);
+
   connection->lock.lock();
   if (state != AUTH_CONNECTING) {
     ldout(cct, 1) << __func__ << " state changed!" << dendl;
@@ -1827,6 +1914,7 @@ CtPtr ProtocolV2::handle_auth_done(ceph::bufferlist &payload)
   if (r < 0) {
     return _fault();
   }
+#endif
   auth_meta->con_mode = auth_done.con_mode();
   session_stream_handlers = \
     ceph::crypto::onwire::rxtx_t::create_handler_pair(cct, *auth_meta, false);
diff --git a/src/osdc/Objecter.cc b/src/osdc/Objecter.cc
index bc39114a..4a0f9884 100644
--- a/src/osdc/Objecter.cc
+++ b/src/osdc/Objecter.cc
@@ -51,6 +51,18 @@
 #include "common/errno.h"
 #include "common/EventTrace.h"
 
+#ifdef WITH_GLOBAL_CACHE
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMsg.h"
+#include "client_adaptor/ClientAdaptorMgr.h"
+#include "client_adaptor/ClientAdaptorPerf.h"
+#include "common/address_helper.h"
+#include <iomanip>
+
+#include <sys/syscall.h>
+#define gettid() syscall(__NR_gettid)
+#endif
+
 using ceph::real_time;
 using ceph::real_clock;
 
@@ -73,7 +85,11 @@ enum {
   l_osdc_op_send_bytes,
   l_osdc_op_resend,
   l_osdc_op_reply,
-
+#ifdef WITH_GLOBAL_CACHE
+  l_osdc_op_gc_retry,
+  l_osdc_op_gc_hangon,
+  l_osdc_op_gc_resend,
+#endif
   l_osdc_op,
   l_osdc_op_r,
   l_osdc_op_w,
@@ -236,6 +252,30 @@ void Objecter::init()
 {
   ceph_assert(!initialized);
 
+#ifdef WITH_GLOBAL_CACHE
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ceph_assert(plugin);
+  int32_t ccm_ret = (static_cast<ClientAdaptorPlugin *>(plugin))->mgr_ref->init_mgr(this);
+  if (ccm_ret){
+    ldout(cct, 3) << "Client Adaptor: " << __func__ << " Initiate manager failed ret " << ccm_ret <<dendl;
+    (static_cast<ClientAdaptorPlugin *>(plugin))->mgr_ref->set_init_flag(false);
+    ceph_abort();
+  }
+  (static_cast<ClientAdaptorPlugin *>(plugin))->mgr_ref->set_init_flag(true);
+  if (cct->_conf.get_val<bool>("global_cache")) {
+    if ((static_cast<ClientAdaptorPlugin *>(plugin))->msg_ref->das_init(this)){
+      ldout(cct, 3) << "Client Adaptor: " << __func__ << " Initiate DAS failed, close prefetch" << dendl;
+    }
+  }
+  ldout(cct, 3) << __func__ << " Client Adaptor: PID: " << dec << getpid() << " TID: " << gettid() << dendl;
+  ldout(cct, 3) << __func__ << " Client Adaptor: Objecter pointer: " << hex << this << dendl;
+  if (cct->_conf.get_val<bool>("global_cache_tick")) {
+    plugin->perf_ref->start_record(plugin);
+  }
+  gc_perf = cct->_conf.get_val<bool>("gc_perf");
+#endif
+
   if (!logger) {
     PerfCountersBuilder pcb(cct, "objecter", l_osdc_first, l_osdc_last);
 
@@ -246,6 +286,14 @@ void Objecter::init()
     pcb.add_u64_counter(l_osdc_op_send_bytes, "op_send_bytes", "Sent data", NULL, 0, unit_t(UNIT_BYTES));
     pcb.add_u64_counter(l_osdc_op_resend, "op_resend", "Resent operations");
     pcb.add_u64_counter(l_osdc_op_reply, "op_reply", "Operation reply");
+#ifdef WITH_GLOBAL_CACHE
+    pcb.add_u64_counter(l_osdc_op_gc_resend, "op_gc_resend",
+            "Operation being resent to gc");
+    pcb.add_u64_counter(l_osdc_op_gc_retry, "op_gc_retry",
+            "Operation need to be retried to gc, because of error");
+    pcb.add_u64_counter(l_osdc_op_gc_hangon, "op_gc_hangon",
+            "Operation being hanging because of abnormal PT");
+#endif
 
     pcb.add_u64_counter(l_osdc_op, "op", "Operations");
     pcb.add_u64_counter(l_osdc_op_r, "op_r", "Read operations", "rd",
@@ -400,6 +448,38 @@ void Objecter::shutdown()
 {
   ceph_assert(initialized);
 
+#ifdef WITH_GLOBAL_CACHE
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ceph_assert(plugin);
+  if (cct->_conf.get_val<bool>("global_cache_tick")) {
+    plugin->perf_ref->tick_done = true;
+    plugin->perf_ref->threads[0].join();
+    plugin->perf_ref->outfile.close();
+  }
+  if (plugin){
+    plugin->msg_ref->das_remove(this);
+    plugin->mgr_ref->ccm_deregister(this);
+    std::lock_guard l(reg->lock);
+    reg->remove("global_cache", "client_adaptor_plugin");
+  }
+ 
+  while(!retry_op.op_waiting_for_retry.empty()) {
+    map<uint32_t, std::queue<Op*>>::iterator i = retry_op.op_waiting_for_retry.begin();
+    retry_op.op_waiting_for_retry.erase(i->first);
+  }
+
+  while(!retry_op.reboot_retry_ops.empty()) {
+    map<ceph_tid_t,Op*>::iterator i = retry_op.reboot_retry_ops.begin();
+    retry_op.reboot_retry_ops.erase(i->first);
+  }
+
+  while(!retry_op.hangon_retry_submit_ops.empty()) {
+    retry_op.hangon_retry_submit_ops.pop_back();
+  }
+  ldout(cct, 3) << __func__ << " Client Adaptor: PID: " << dec << getpid() << " TID: " << gettid() << dendl;
+  ldout(cct, 3) << __func__ << " Client Adaptor: Objecter pointer: " << hex << this << dendl;
+#endif
   unique_lock wl(rwlock);
 
   initialized = false;
@@ -1062,6 +1142,15 @@ void Objecter::_scan_requests(
   while (p != s->ops.end()) {
     Op *op = p->second;
     ++p;   // check_op_pool_dne() may touch ops; prevent iterator invalidation
+#ifdef WITH_GLOBAL_CACHE
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+    ceph_assert(plugin);
+    if (check_osd_value(s->osd) && plugin->msg_ref->filter_msg_by_op(op)) {
+        ldout(cct, 10) << " dont need to resend op here, tid=" << op->tid << ", waiting for nodeView event" << dendl;
+        continue;
+    }
+#endif
     ldout(cct, 10) << " checking op " << op->tid << dendl;
     _prune_snapc(osdmap->get_new_removed_snaps(), op);
     if (skipped_map) {
@@ -1229,17 +1318,41 @@ void Objecter::handle_osd_map(MOSDMap *m)
 	for (map<int,OSDSession*>::iterator p = osd_sessions.begin();
 	     p != osd_sessions.end(); ) {
 	  OSDSession *s = p->second;
-	  _scan_requests(s, skipped_map, cluster_full,
-			 &pool_full_map, need_resend,
-			 need_resend_linger, need_resend_command, sul,
-			 &m->gap_removed_snaps);
+#ifdef WITH_GLOBAL_CACHE
+    if (!check_osd_value(s->osd)) {
+      _scan_requests(s, skipped_map, cluster_full,
+			  &pool_full_map, need_resend,
+			  need_resend_linger, need_resend_command, sul,
+			  &m->gap_removed_snaps);
+    }
+#else
+      _scan_requests(s, skipped_map, cluster_full,
+			  &pool_full_map, need_resend,
+			  need_resend_linger, need_resend_command, sul,
+			  &m->gap_removed_snaps);
+
+#endif
 	  ++p;
+#ifdef WITH_GLOBAL_CACHE
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+    ceph_assert(plugin);
+    if (check_osd_value(s->osd)) {
+      // osd means one Global Cache connection
+      ldout(cct, 3) << "Client Adaptor: " << __func__ << " bypass close osd session for 0x" << hex << s->osd << dendl;
+    } else if (!osdmap->is_up(s->osd) ||
+	      (s->con &&
+	       s->con->get_peer_addrs() != osdmap->get_addrs(s->osd))) {
+	    close_session(s);
+	  }
+#else
 	  // osd down or addr change?
 	  if (!osdmap->is_up(s->osd) ||
 	      (s->con &&
 	       s->con->get_peer_addrs() != osdmap->get_addrs(s->osd))) {
 	    close_session(s);
 	  }
+#endif
 	}
 
 	ceph_assert(e == osdmap->get_epoch());
@@ -1390,6 +1503,41 @@ void Objecter::consume_blacklist_events(std::set<entity_addr_t> *events)
   }
 }
 
+#ifdef WITH_GLOBAL_CACHE
+void Objecter::set_acc_pool_set(int64_t poolid, int32_t clusterId)
+{
+	acc_pool_set[poolid] = clusterId;
+}
+
+bool Objecter::get_acc_pool_set(int64_t poolid)
+{
+    return acc_pool_set.count(poolid) > 0;
+}
+
+int32_t Objecter::get_cluster_id(int64_t poolId)
+{
+	if (!acc_pool_set.count(poolId)) {
+		ldout(cct, 3) << __func__ << " incorrect call" << dendl;
+      	ceph_abort();		
+	}
+	return acc_pool_set[poolId];
+}
+
+bool Objecter::check_osd_value(int osd)
+{
+    if (!(osd == -1) && (osd >> 20)) {
+        return true;
+    }
+    return false;
+}
+
+int32_t Objecter::get_clusterId_from_osd(int osd)
+{
+    return (osd & 0xF0000) >> 16;
+}
+
+#endif
+
 void Objecter::emit_blacklist_events(const OSDMap::Incremental &inc)
 {
   if (!blacklist_events_enabled) {
@@ -1772,6 +1920,56 @@ int Objecter::_get_session(int osd, OSDSession **session, shunique_lock& sul)
     return 0;
   }
 
+#ifdef WITH_GLOBAL_CACHE
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ceph_assert(plugin);
+  map<int,OSDSession*>::iterator p = osd_sessions.find(osd);
+
+  if (p != osd_sessions.end()) {
+    OSDSession *s = p->second;
+    s->get();
+    *session = s;
+    ldout(cct, 20) << __func__ << " s=" << s << " osd=" << osd << " "
+		   << s->get_nref() << dendl;
+    return 0;
+  }
+  if (!sul.owns_lock()) {
+    return -EAGAIN;
+  }
+
+  OSDSession *s = nullptr;
+  // osd_entry = osd;
+  if (check_osd_value(osd)) {
+    string node_ip = "";
+    int32_t clusterId = get_clusterId_from_osd(osd);
+    ldout(cct, 3) << "Client Adaptor: " << __func__ << " osd = 0x" << hex << osd  << " clusterId " << clusterId << dendl;
+    uint32_t ret = plugin->msg_ref->get_node_ip(clusterId, osd, node_ip);
+    if (ret) {
+      ldout(cct, 3) << "Client Adaptor: " << __func__ << " Get node ip failed, ret " << ret << dendl;
+      ceph_abort();
+    }
+
+    ldout(cct, 3) << "Client Adaptor: " << __func__ << " ip address = " << node_ip.c_str() << dendl;
+    entity_addr_t node_addr;
+    entity_addr_from_url(&node_addr, node_ip.c_str());
+    node_addr.set_type(entity_addr_t::TYPE_MSGR2);
+    entity_addrvec_t node_addrs(node_addr);
+    s = new OSDSession(cct, osd);
+    osd_sessions[osd] = s;
+    s->con = messenger->connect_to_osd(node_addrs);
+    std::unique_lock<std::shared_mutex> wlock(plugin->msg_ref->connlock);
+    plugin->msg_ref->connections.insert((void *)(s->con.get()));
+    for (auto it : plugin->msg_ref->connections) {
+      ldout(cct, 3) << "Client Adaptor: con = " << it << dendl;
+    }
+    wlock.unlock();
+  } else {
+    s = new OSDSession(cct, osd);
+    osd_sessions[osd] = s;
+    s->con = messenger->connect_to_osd(osdmap->get_addrs(osd));
+  }
+#else
   map<int,OSDSession*>::iterator p = osd_sessions.find(osd);
   if (p != osd_sessions.end()) {
     OSDSession *s = p->second;
@@ -1787,6 +1985,7 @@ int Objecter::_get_session(int osd, OSDSession **session, shunique_lock& sul)
   OSDSession *s = new OSDSession(cct, osd);
   osd_sessions[osd] = s;
   s->con = messenger->connect_to_osd(osdmap->get_addrs(osd));
+#endif
   s->con->set_priv(RefCountedPtr{s});
   logger->inc(l_osdc_osd_session_open);
   logger->set(l_osdc_osd_sessions, osd_sessions.size());
@@ -2180,7 +2379,12 @@ void Objecter::tick()
       (*i)->con->send_message(new MPing);
     }
   }
-
+#ifdef WITH_GLOBAL_CACHE
+  RetryOp::unique_lock retry_op_rl(retry_op.retrylock);
+  ldout(cct, 2) <<" tick hangon_retry_submit_ops size " <<retry_op.hangon_retry_submit_ops.size()<< dendl;
+  ldout(cct, 2) <<" tick op_waiting_for_retry size " <<retry_op.op_waiting_for_retry.size()<< dendl;
+  retry_op_rl.unlock();
+#endif
   // Make sure we don't reschedule if we wake up after shutdown
   if (initialized) {
     tick_event = timer.reschedule_me(ceph::make_timespan(
@@ -2363,10 +2567,25 @@ void Objecter::_op_submit(Op *op, shunique_lock& sul, ceph_tid_t *ptid)
   // pick target
   ceph_assert(op->session == NULL);
   OSDSession *s = NULL;
+#ifdef WITH_GLOBAL_CACHE
+  bool pt_stat = true;
+  bool check_for_latest_map = _calc_pt_target(&op->target, nullptr, pt_stat)
+    == RECALC_OP_TARGET_POOL_DNE;
 
+  if (!pt_stat) {
+    unique_lock rl(retry_op.retrylock);
+    retry_op.hangon_retry_submit_ops.push_back(op);
+    rl.unlock();
+    if (gc_perf) {
+        logger->inc(l_osdc_op_gc_hangon);
+    }
+    ldout(cct, 1) << " this "<< this<< " " << __func__ << " op " << op << " pt unnormal, hang on IO waitting for retry by pt normal trigger " << dendl;
+    return;
+  }
+#else
   bool check_for_latest_map = _calc_target(&op->target, nullptr)
     == RECALC_OP_TARGET_POOL_DNE;
-
+#endif
   // Try to get a session, including a retry if we need to take write lock
   int r = _get_session(op->target.osd, &s, sul);
   if (r == -EAGAIN ||
@@ -2382,8 +2601,24 @@ void Objecter::_op_submit(Op *op, shunique_lock& sul, ceph_tid_t *ptid)
       // map changed; recalculate mapping
       ldout(cct, 10) << __func__ << " relock raced with osdmap, recalc target"
 		     << dendl;
+#ifdef WITH_GLOBAL_CACHE
+      check_for_latest_map = _calc_pt_target(&op->target, nullptr, pt_stat)
+        == RECALC_OP_TARGET_POOL_DNE;
+
+      if (!pt_stat) {
+        unique_lock rl(retry_op.retrylock);
+        retry_op.hangon_retry_submit_ops.push_back(op);
+        rl.unlock();
+        if (gc_perf) {
+            logger->inc(l_osdc_op_gc_hangon);
+        }
+        ldout(cct, 1) << __func__ << " op " << op << " pt unnormal, hang on IO waitting for retry by pt normal trigger " << dendl;
+        return;
+      }
+#else
       check_for_latest_map = _calc_target(&op->target, nullptr)
-	== RECALC_OP_TARGET_POOL_DNE;
+        == RECALC_OP_TARGET_POOL_DNE;
+#endif
       if (s) {
 	put_session(s);
 	s = NULL;
@@ -2453,6 +2688,17 @@ void Objecter::_op_submit(Op *op, shunique_lock& sul, ceph_tid_t *ptid)
   _session_op_assign(s, op);
 
   if (need_send) {
+#ifdef WITH_GLOBAL_CACHE
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+    ceph_assert(plugin);
+    if (check_osd_value(s->osd) && plugin->msg_ref->filter_msg_by_op(op)){
+      plugin->msg_ref->das_update_info(get_clusterId_from_osd(s->osd), this, op);
+      if (cct->_conf.get_val<bool>("global_cache_tick")) {
+        plugin->perf_ref->start_tick(op);
+      }
+    }
+#endif
     _send_op(op);
   }
 
@@ -2770,6 +3016,232 @@ void Objecter::_prune_snapc(
   }
 }
 
+#ifdef WITH_GLOBAL_CACHE
+int Objecter::_calc_pt_target(op_target_t *t, Connection *con, bool &pt_status, bool any_change)
+{
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ceph_assert(plugin);
+  if (get_acc_pool_set(t->base_oloc.pool) && plugin->msg_ref->filter_msg(t)){
+    t->target_oid = t->base_oid;
+    t->target_oloc = t->base_oloc;
+    ldout(cct, 3) << "Client Adaptor: " << __func__ << " msg filter pass to Global Cache" << dendl;
+    int64_t pool_id = t->base_oloc.pool;
+    int32_t clusterId = get_cluster_id(pool_id);
+    uint32_t pt_id = 0;
+    int32_t node_id = plugin->msg_ref->get_node_id(clusterId, t->base_oid.name, pool_id, pt_id);
+    if (node_id < 0){
+      ldout(cct, 3) << "Client Adaptor: " << __func__ << " Get node id failed ret " << node_id << dendl;
+      ceph_abort();
+    }
+    ldout(cct, 3) << "Client Adaptor: " << __func__ << " Send to PT " << pt_id << dendl;
+    t->actual_pgid.pgid.set_pool(t->base_oloc.pool);
+    ldout(cct, 3) << "Client Adaptor: " << __func__ << " Pool ID =  " << t->actual_pgid.pgid.m_pool << dendl;
+    ldout(cct, 3) << "Client Adaptor: " << __func__ << " Seed =  " << t->actual_pgid.pgid.m_seed << dendl;
+    t->actual_pgid.pgid.set_ps(pt_id);
+    t->osd = node_id;
+    pt_status = plugin->mgr_ref->get_pt_status(clusterId, pt_id);
+    return RECALC_OP_TARGET_NO_ACTION;
+  } else {
+    // rwlock is locked
+    bool is_read = t->flags & CEPH_OSD_FLAG_READ;
+    bool is_write = t->flags & CEPH_OSD_FLAG_WRITE;
+    t->epoch = osdmap->get_epoch();
+    ldout(cct,20) << __func__ << " epoch " << t->epoch
+      << " base " << t->base_oid << " " << t->base_oloc
+      << " precalc_pgid " << (int)t->precalc_pgid
+      << " pgid " << t->base_pgid
+      << (is_read ? " is_read" : "")
+      << (is_write ? " is_write" : "")
+      << dendl;
+
+    const pg_pool_t *pi = osdmap->get_pg_pool(t->base_oloc.pool);
+    if (!pi) {
+      t->osd = -1;
+      return RECALC_OP_TARGET_POOL_DNE;
+    }
+    ldout(cct,30) << __func__ << "  base pi " << pi
+      << " pg_num " << pi->get_pg_num() << dendl;
+
+    bool force_resend = false;
+    if (osdmap->get_epoch() == pi->last_force_op_resend) {
+      if (t->last_force_resend < pi->last_force_op_resend) {
+        t->last_force_resend = pi->last_force_op_resend;
+        force_resend = true;
+      } else if (t->last_force_resend == 0) {
+        force_resend = true;
+      }
+    }
+
+    // apply tiering
+    t->target_oid = t->base_oid;
+    t->target_oloc = t->base_oloc;
+    if ((t->flags & CEPH_OSD_FLAG_IGNORE_OVERLAY) == 0) {
+      if (is_read && pi->has_read_tier())
+        t->target_oloc.pool = pi->read_tier;
+      if (is_write && pi->has_write_tier())
+        t->target_oloc.pool = pi->write_tier;
+      pi = osdmap->get_pg_pool(t->target_oloc.pool);
+      if (!pi) {
+        t->osd = -1;
+        return RECALC_OP_TARGET_POOL_DNE;
+      }
+    }
+
+    pg_t pgid;
+    if (t->precalc_pgid) {
+      ceph_assert(t->flags & CEPH_OSD_FLAG_IGNORE_OVERLAY);
+      ceph_assert(t->base_oid.name.empty()); // make sure this is a pg op
+      ceph_assert(t->base_oloc.pool == (int64_t)t->base_pgid.pool());
+      pgid = t->base_pgid;
+    } else {
+      int ret = osdmap->object_locator_to_pg(t->target_oid, t->target_oloc,
+              pgid);
+      if (ret == -ENOENT) {
+        t->osd = -1;
+        return RECALC_OP_TARGET_POOL_DNE;
+      }
+    }
+    ldout(cct,20) << __func__ << " target " << t->target_oid << " "
+      << t->target_oloc << " -> pgid " << pgid << dendl;
+    ldout(cct,30) << __func__ << "  target pi " << pi
+      << " pg_num " << pi->get_pg_num() << dendl;
+    t->pool_ever_existed = true;
+
+    int size = pi->size;
+    int min_size = pi->min_size;
+    unsigned pg_num = pi->get_pg_num();
+    unsigned pg_num_pending = pi->get_pg_num_pending();
+    int up_primary, acting_primary;
+    vector<int> up, acting;
+    osdmap->pg_to_up_acting_osds(pgid, &up, &up_primary,
+              &acting, &acting_primary);
+    bool sort_bitwise = osdmap->test_flag(CEPH_OSDMAP_SORTBITWISE);
+    bool recovery_deletes = osdmap->test_flag(CEPH_OSDMAP_RECOVERY_DELETES);
+    unsigned prev_seed = ceph_stable_mod(pgid.ps(), t->pg_num, t->pg_num_mask);
+    pg_t prev_pgid(prev_seed, pgid.pool());
+    if (any_change && PastIntervals::is_new_interval(
+    t->acting_primary,
+    acting_primary,
+    t->acting,
+    acting,
+    t->up_primary,
+    up_primary,
+    t->up,
+    up,
+    t->size,
+    size,
+    t->min_size,
+    min_size,
+    t->pg_num,
+    pg_num,
+    t->pg_num_pending,
+    pg_num_pending,
+    t->sort_bitwise,
+    sort_bitwise,
+    t->recovery_deletes,
+    recovery_deletes,
+    prev_pgid)) {
+      force_resend = true;
+    }
+
+    bool unpaused = false;
+    bool should_be_paused = target_should_be_paused(t);
+    if (t->paused && !should_be_paused) {
+      unpaused = true;
+    }
+    t->paused = should_be_paused;
+
+    bool legacy_change =
+      t->pgid != pgid ||
+        is_pg_changed(
+    t->acting_primary, t->acting, acting_primary, acting,
+    t->used_replica || any_change);
+    bool split_or_merge = false;
+    if (t->pg_num) {
+      split_or_merge =
+        prev_pgid.is_split(t->pg_num, pg_num, nullptr) ||
+        prev_pgid.is_merge_source(t->pg_num, pg_num, nullptr) ||
+        prev_pgid.is_merge_target(t->pg_num, pg_num);
+    }
+
+    if (legacy_change || split_or_merge || force_resend) {
+      t->pgid = pgid;
+      t->acting = acting;
+      t->acting_primary = acting_primary;
+      t->up_primary = up_primary;
+      t->up = up;
+      t->size = size;
+      t->min_size = min_size;
+      t->pg_num = pg_num;
+      t->pg_num_mask = pi->get_pg_num_mask();
+      t->pg_num_pending = pg_num_pending;
+      osdmap->get_primary_shard(
+        pg_t(ceph_stable_mod(pgid.ps(), t->pg_num, t->pg_num_mask), pgid.pool()),
+        &t->actual_pgid);
+      t->sort_bitwise = sort_bitwise;
+      t->recovery_deletes = recovery_deletes;
+      ldout(cct, 10) << __func__ << " "
+        << " raw pgid " << pgid << " -> actual " << t->actual_pgid
+        << " acting " << acting
+        << " primary " << acting_primary << dendl;
+      t->used_replica = false;
+      if (acting_primary == -1) {
+        t->osd = -1;
+      } else {
+        int osd;
+        bool read = is_read && !is_write;
+        if (read && (t->flags & CEPH_OSD_FLAG_BALANCE_READS)) {
+    int p = rand() % acting.size();
+    if (p)
+      t->used_replica = true;
+    osd = acting[p];
+    ldout(cct, 10) << " chose random osd." << osd << " of " << acting
+            << dendl;
+        } else if (read && (t->flags & CEPH_OSD_FLAG_LOCALIZE_READS) &&
+      acting.size() > 1) {
+    // look for a local replica.  prefer the primary if the
+    // distance is the same.
+    int best = -1;
+    int best_locality = 0;
+    for (unsigned i = 0; i < acting.size(); ++i) {
+      int locality = osdmap->crush->get_common_ancestor_distance(
+      cct, acting[i], crush_location);
+      ldout(cct, 20) << __func__ << " localize: rank " << i
+        << " osd." << acting[i]
+        << " locality " << locality << dendl;
+      if (i == 0 ||
+          (locality >= 0 && best_locality >= 0 &&
+          locality < best_locality) ||
+          (best_locality < 0 && locality >= 0)) {
+        best = i;
+        best_locality = locality;
+        if (i)
+          t->used_replica = true;
+      }
+    }
+    ceph_assert(best >= 0);
+    osd = acting[best];
+        } else {
+    osd = acting_primary;
+        }
+        t->osd = osd;
+      }
+    }
+    if (legacy_change || unpaused || force_resend) {
+      return RECALC_OP_TARGET_NEED_RESEND;
+    }
+    if (split_or_merge &&
+        (osdmap->require_osd_release >= CEPH_RELEASE_LUMINOUS ||
+        HAVE_FEATURE(osdmap->get_xinfo(acting_primary).features,
+          RESEND_ON_SPLIT))) {
+      return RECALC_OP_TARGET_NEED_RESEND;
+    }
+    return RECALC_OP_TARGET_NO_ACTION;
+  }
+}
+#endif
+
 int Objecter::_calc_target(op_target_t *t, Connection *con, bool any_change)
 {
   // rwlock is locked
@@ -2969,6 +3441,7 @@ int Objecter::_calc_target(op_target_t *t, Connection *con, bool any_change)
   return RECALC_OP_TARGET_NO_ACTION;
 }
 
+
 int Objecter::_map_session(op_target_t *target, OSDSession **s,
 			   shunique_lock& sul)
 {
@@ -3139,7 +3612,6 @@ void Objecter::_finish_op(Op *op, int r)
   }
 
   logger->dec(l_osdc_op_active);
-
   ceph_assert(check_latest_map_ops.find(op->tid) == check_latest_map_ops.end());
 
   inflight_ops--;
@@ -3271,6 +3743,38 @@ void Objecter::_send_op(Op *op)
   if (op->trace.valid()) {
     m->trace.init("op msg", nullptr, &op->trace);
   }
+
+#ifdef WITH_GLOBAL_CACHE
+  ldout(cct, 3) << "Client Adaptor: " << __func__ << " msg-type = 0x" << hex << m->get_type() << dendl;
+  if (m->get_type() == CEPH_MSG_OSD_OP) {
+    MOSDOp *mosdop = static_cast<MOSDOp *>(m);
+    ldout(cct, 3) << "Client Adaptor: " << __func__ << " MOSDOp object name = " << mosdop->get_oid().name << dendl;
+    ldout(cct, 3) << "Client Adaptor: " << __func__ << " Request ID = " << mosdop->get_reqid().tid << dendl;
+    uint32_t pt_index = mosdop->get_pg().m_seed;
+    uint64_t pool_id = mosdop->get_pg().m_pool;
+    ldout(cct, 3) << "Client Adaptor: " << __func__ << " PT ID = " << pt_index << " Pool ID = " << pool_id << dendl;
+    int index = 0;
+    for (auto op : mosdop->ops) {
+      ldout(cct, 3) << "Client Adaptor: " << __func__ << " index = " << index 
+              << " op-code = 0x" << hex << op.op.op << dendl;
+
+      index++;
+      if (op.op.op == CEPH_OSD_OP_READ || op.op.op == CEPH_OSD_OP_WRITE || op.op.op == CEPH_OSD_OP_SPARSE_READ ||
+             op.op.op == CEPH_OSD_OP_WRITEFULL || op.op.op == CEPH_OSD_OP_SYNC_READ) {
+        ldout(cct, 3) << "Client Adaptor: " << __func__ << " offset = 0x" << hex << op.op.extent.offset 
+                    << " length = 0x" << hex << op.op.extent.length << dendl;
+      }
+      if (op.op.op == CEPH_OSD_OP_CALL) {
+        string cname, mname;
+        auto bp = op.indata.cbegin();
+        bp.copy(op.op.cls.class_len, cname);
+        bp.copy(op.op.cls.method_len, mname);
+        ldout(cct, 3) << "Client Adaptor: " << __func__ << " op call class: " << cname << " method: " << mname << dendl;
+      }
+    }
+  }
+#endif
+
   op->session->con->send_message(m);
 }
 
@@ -3326,6 +3830,148 @@ int Objecter::take_linger_budget(LingerOp *info)
   return 1;
 }
 
+#ifdef WITH_GLOBAL_CACHE
+void Objecter::nodeview_change_retry_op_submit(int32_t clusterId, set<uint32_t> available_nodes)
+{
+    ldout(cct, 3) << "Enter NodeView Change Retry OP Submit. clusterId= " << clusterId
+        << " available_nodes=" << available_nodes << dendl;
+    map<ceph_tid_t, Op *> need_resend;
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+    ceph_assert(plugin);
+    unique_lock sul(rwlock);
+    for (map<int, OSDSession *>::iterator p = osd_sessions.begin(); p != osd_sessions.end();) {
+        OSDSession *s = p->second;
+        int osd = p->first;
+        ldout(cct, 3) << "NodeView Change osd=" << osd << " ops=" << s->ops << dendl;
+        if (!check_osd_value(osd) || 
+            get_clusterId_from_osd(osd) != clusterId ||
+            available_nodes.find((osd & 0xFFFF) >> 4) != available_nodes.end()) {
+            ++p;
+            continue;
+        }
+        OSDSession::unique_lock sl(s->lock);
+        map<ceph_tid_t, Op *>::iterator it = s->ops.begin();
+        while (it != s->ops.end()) {
+            need_resend[it->second->tid] = it->second;
+            _session_op_remove(it->second->session, it->second);
+            it = s->ops.begin();
+        }
+        if (s->con) {
+            std::unique_lock<std::shared_mutex> wlock(plugin->msg_ref->connlock);
+            auto connection = s->con.get();
+            plugin->msg_ref->connections.erase((void *)connection);
+            wlock.unlock();
+            ldout(cct, 3) << "NodeView Change need remove connection :" << connection << dendl;
+        }
+        ++p;
+        sl.unlock();
+        // 上边的解锁到里边的加锁中间的时间差可能会被插入 op，插入的这部分 op 在 close session 之后会进入 homeless_session
+        // 所以之后还需要对 homeless_session 进行处理
+        close_session(s);
+    }
+
+    // here need to resend op in homeless_session
+    OSDSession *s = homeless_session;
+    OSDSession::unique_lock sl(s->lock);
+    map<ceph_tid_t,Op*>::iterator p = s->ops.begin();
+    while (p != s->ops.end()) {
+        Op *op = p->second;
+        ++p;
+        if (plugin->msg_ref->filter_msg_by_op(op)) {
+            ldout(cct, 3) << "NodeView Change: need resend homeless op: " << op->tid << dendl;
+            _session_op_remove(op->session, op);
+            need_resend[op->tid] = op;
+        }
+    }
+    sl.unlock();
+
+    sul.unlock();
+    ldout(cct, 3) << "NodeView Change Retry OP Submit: need_resend size: " << need_resend.size() << dendl;
+    for (map<ceph_tid_t, Op *>::iterator it = need_resend.begin(); it != need_resend.end(); it++) {
+        shunique_lock sul(rwlock, ceph::acquire_shared);
+        ldout(cct, 3) << "NodeView Change Retry OP Submit. TID: " << it->second->tid << dendl;
+        logger->dec(l_osdc_op_active);
+        _op_submit(it->second, sul, &(it->second->tid));
+    }
+}
+
+void Objecter::retry_op_submit(vector<uint32_t> ready_pt_id)
+{
+  if (!ready_pt_id.size()) {
+    ldout(cct, 3) << __func__ << "ccm pt change notfiy, normal pt size 0 " << dendl;
+    return;
+  }
+  std::queue<std::queue<Op*>> deal_op;
+  map<uint32_t, std::queue<Op*>>::iterator iter;
+  unique_lock rl(retry_op.retrylock);
+  for (uint32_t i = 0; i < ready_pt_id.size(); i++) {
+       iter = retry_op.op_waiting_for_retry.find(ready_pt_id[i]);
+       if (iter != retry_op.op_waiting_for_retry.end()) {
+          deal_op.push(iter->second);
+          retry_op.op_waiting_for_retry.erase(iter);
+       }
+  }
+  rl.unlock();
+  ldout(cct, 3) << __func__ << "resend op queue size " << deal_op.size() << "  remain resend size " << retry_op.op_waiting_for_retry.size()<< dendl;
+
+  uint32_t resend_errort_op_num = 0;
+  while (!deal_op.empty()) {
+       std::queue<Op*> op_queue = deal_op.front();
+       deal_op.pop();
+       while (!op_queue.empty()) {
+         Op* op = op_queue.front();
+         op_queue.pop();
+         if (gc_perf) {
+            logger->dec(l_osdc_op_gc_retry);
+         }
+         shunique_lock sul(rwlock, ceph::acquire_shared);
+         _op_submit(op, sul, NULL);
+         resend_errort_op_num++;
+       }
+  }
+  ldout(cct, 3) << __func__ << "resend errort op number " << resend_errort_op_num << dendl;
+
+
+  //reboot inflight ops
+  
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ceph_assert(plugin);
+
+  rl.lock();
+  
+  std::queue<Op*> op_queue;
+  // hang on io retry
+  uint32_t resend_hangon_op_num = 0;
+  for (auto iter = retry_op.hangon_retry_submit_ops.begin(); iter != retry_op.hangon_retry_submit_ops.end(); ) {
+    Op *op = static_cast<Op*>(*iter);
+    uint32_t pt_id = op->target.actual_pgid.pgid.m_seed;
+    int32_t clusterId = get_cluster_id(op->target.base_oloc.pool); 
+    if (plugin->mgr_ref->get_pt_status(clusterId, pt_id)) {
+      op_queue.push(op);
+      resend_hangon_op_num++;
+      retry_op.hangon_retry_submit_ops.erase(iter);
+    } else {
+      ldout(cct, 1) << __func__ << " resend hangon_retry_submit_ops pt  " << pt_id << " unnormal, resend failed"<< dendl;
+      ++iter;
+    }
+  }
+  ldout(cct, 3) << __func__ << " should resend hangon op number " << resend_hangon_op_num << " left hangon size " << retry_op.hangon_retry_submit_ops.size()<< dendl;
+  rl.unlock();
+
+  while (!op_queue.empty()) {
+    Op* op = op_queue.front();
+    op_queue.pop();
+    if (gc_perf) {
+        logger->dec(l_osdc_op_gc_hangon);
+    }
+    shunique_lock sul(rwlock, ceph::acquire_shared);
+    _op_submit(op, sul, NULL);
+  }
+}
+#endif
+
 /* This function DOES put the passed message before returning */
 void Objecter::handle_osd_op_reply(MOSDOpReply *m)
 {
@@ -3348,7 +3994,11 @@ void Objecter::handle_osd_op_reply(MOSDOpReply *m)
     m->put();
     return;
   }
-
+#ifdef WITH_GLOBAL_CACHE
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ceph_assert(plugin);
+#endif
   OSDSession::unique_lock sl(s->lock);
 
   map<ceph_tid_t, Op *>::iterator iter = s->ops.find(tid);
@@ -3406,7 +4056,6 @@ void Objecter::handle_osd_op_reply(MOSDOpReply *m)
   Context *onfinish = 0;
 
   int rc = m->get_result();
-
   if (m->is_redirect_reply()) {
     ldout(cct, 5) << " got redirect reply; redirecting" << dendl;
     if (op->onfinish)
@@ -3438,13 +4087,58 @@ void Objecter::handle_osd_op_reply(MOSDOpReply *m)
     op->target.flags &= ~(CEPH_OSD_FLAG_BALANCE_READS |
 			  CEPH_OSD_FLAG_LOCALIZE_READS);
     op->target.pgid = pg_t();
+#ifdef WITH_GLOBAL_CACHE
+  if (get_acc_pool_set(op->target.target_oloc.pool)) {
+    logger->dec(l_osdc_op_active);
+  }
+#endif
     _op_submit(op, sul, NULL);
     m->put();
     return;
   }
 
+#ifdef WITH_GLOBAL_CACHE
+  if (get_acc_pool_set(op->target.target_oloc.pool) && errort_filter(rc) && m->get_oid().name.find("rbd_data") != string::npos) {
+       ldout(cct, 1) <<  " op " << op << " error code " << rc << ", client resubmitting" << dendl;
+       if (op->onfinish)
+         num_in_flight--;
+       _session_op_remove(s, op);
+       sl.unlock();
+
+       op->tid = 0;
+       op->target.flags &= ~(CEPH_OSD_FLAG_BALANCE_READS |
+                         CEPH_OSD_FLAG_LOCALIZE_READS);
+       op->target.pgid = pg_t();
+       unique_lock rl(retry_op.retrylock);
+       std::queue<Op*> insert_op;
+       uint32_t pt_id = m->get_pg().m_seed;
+       map<uint32_t, std::queue<Op*>>::iterator iter = retry_op.op_waiting_for_retry.find(pt_id);
+       if (iter != retry_op.op_waiting_for_retry.end()) {
+               iter->second.push(op);
+       } else {
+               insert_op.push(op);
+               retry_op.op_waiting_for_retry[pt_id] = insert_op;
+       }
+       rl.unlock();
+       if (gc_perf) {
+                logger->inc(l_osdc_op_gc_retry);
+       }
+       m->put();
+       return;
+  }
+#endif
   sul.unlock();
 
+#ifdef WITH_GLOBAL_CACHE
+  if (cct->_conf.get_val<bool>("global_cache_tick") && get_acc_pool_set(op->target.target_oloc.pool)) {
+    if (plugin->msg_ref->filter_msg_by_op(op)){
+      plugin->perf_ref->end_tick(op);
+      plugin->perf_ref->record_op(op);
+      plugin->perf_ref->total_in_flight += num_in_flight;
+    }
+  }
+#endif
+
   if (op->objver)
     *op->objver = m->get_user_version();
   if (op->reply_epoch)
@@ -4399,6 +5093,53 @@ bool Objecter::ms_handle_reset(Connection *con)
     if (session) {
       ldout(cct, 1) << "ms_handle_reset " << con << " session " << session
 		    << " osd." << session->osd << dendl;
+#ifdef WITH_GLOBAL_CACHE
+  if (check_osd_value(session->osd)) {
+    PluginRegistry *reg = cct->get_plugin_registry();
+    auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+    ceph_assert(plugin);
+    OSDSession::unique_lock sl(session->lock);
+    if (session->con) {
+        std::unique_lock<std::shared_mutex> wlock(plugin->msg_ref->connlock);
+    	plugin->msg_ref->connections.erase((void *)(session->con.get()));
+        wlock.unlock();
+    }
+    map<ceph_tid_t,Op*> resend;
+    for (map<ceph_tid_t, Op*>::iterator p = session->ops.begin(); p != session->ops.end(); ++p) {
+      	Op *op = p->second;
+      	resend[op->tid] = op;
+    }
+
+    ldout(cct, 3) << __func__ << " resend size " << resend.size()  << dendl;
+    for (map<ceph_tid_t,Op*>::iterator p = resend.begin(); p != resend.end(); ++p ) {
+	Op *op = p->second;
+      	if (op->onfinish) {
+	    num_in_flight--;
+        }
+        _session_op_remove(session, op);
+    }
+    sl.unlock();
+    close_session(session);
+
+    if (!(initialized && osdmap->is_up(session->osd))) {
+	ldout(cct, 1) << "ms_handle_reset aborted,initialized=" << initialized << dendl;
+	wl.unlock();
+
+	for (map<ceph_tid_t,Op*>::iterator p = resend.begin(); p != resend.end(); ++p ) {
+            Op *op = p->second;
+            shunique_lock sul(rwlock, ceph::acquire_shared);
+            ldout(cct, 3) << __func__ << " resend submit op " << op <<" tid=" <<op->tid << dendl;
+            if (gc_perf && plugin->msg_ref->filter_msg_by_op(op)) {
+                logger->dec(l_osdc_op_active);
+                logger->inc(l_osdc_op_gc_resend);
+            }
+            _op_submit(op, sul, NULL);
+        }
+
+	return false;
+    }
+ } 
+#endif
       // the session maybe had been closed if new osdmap just handled
       // says the osd down
       if (!(initialized && osdmap->is_up(session->osd))) {
diff --git a/src/osdc/Objecter.h b/src/osdc/Objecter.h
index ca8d85f7..e2b80623 100644
--- a/src/osdc/Objecter.h
+++ b/src/osdc/Objecter.h
@@ -258,7 +258,14 @@ struct ObjectOperation {
     }
   };
   void stat(uint64_t *psize, ceph::real_time *pmtime, int *prval) {
+#ifdef WITH_GLOBAL_CACHE
+    OSDOp& osd_op = add_op(CEPH_OSD_OP_STAT);
+    if (!psize) {
+        osd_op.op.flags = 1;
+    }
+#else
     add_op(CEPH_OSD_OP_STAT);
+#endif
     unsigned p = ops.size() - 1;
     C_ObjectOperation_stat *h = new C_ObjectOperation_stat(psize, pmtime, NULL, NULL,
 							   prval);
@@ -267,7 +274,14 @@ struct ObjectOperation {
     out_rval[p] = prval;
   }
   void stat(uint64_t *psize, time_t *ptime, int *prval) {
+#ifdef WITH_GLOBAL_CACHE
+    OSDOp& osd_op = add_op(CEPH_OSD_OP_STAT);
+    if (!psize) {
+        osd_op.op.flags = 1;
+    }
+#else
     add_op(CEPH_OSD_OP_STAT);
+#endif
     unsigned p = ops.size() - 1;
     C_ObjectOperation_stat *h = new C_ObjectOperation_stat(psize, NULL, ptime, NULL,
 							   prval);
@@ -276,7 +290,14 @@ struct ObjectOperation {
     out_rval[p] = prval;
   }
   void stat(uint64_t *psize, struct timespec *pts, int *prval) {
+#ifdef WITH_GLOBAL_CACHE
+    OSDOp& osd_op = add_op(CEPH_OSD_OP_STAT);
+    if (!psize) {
+        osd_op.op.flags = 1;
+    }
+#else
     add_op(CEPH_OSD_OP_STAT);
+#endif
     unsigned p = ops.size() - 1;
     C_ObjectOperation_stat *h = new C_ObjectOperation_stat(psize, NULL, NULL, pts,
 							   prval);
@@ -1232,7 +1253,18 @@ public:
   void maybe_request_map();
 
   void enable_blacklist_events();
+
+#ifdef WITH_GLOBAL_CACHE
+  void set_acc_pool_set(int64_t poolid, int32_t clusterId);
+  bool get_acc_pool_set(int64_t poolid);
+  int32_t get_cluster_id(int64_t poolId);
+  bool check_osd_value(int osd);
+  int32_t get_clusterId_from_osd(int osd);
+#endif
 private:
+#ifdef WITH_GLOBAL_CACHE
+  std::map<int64_t, int32_t> acc_pool_set;
+#endif
 
   void _maybe_request_map();
 
@@ -1341,7 +1373,13 @@ public:
     int incarnation;
 
     op_target_t target;
-
+#ifdef WITH_GLOBAL_CACHE
+    struct perf_tick_t {
+      struct timeval start;
+      struct timeval end;
+    };
+    perf_tick_t perf_tick;
+#endif
     ConnectionRef con;  // for rx buffer only
     uint64_t features;  // explicitly specified op features
 
@@ -1863,9 +1901,32 @@ public:
 
   bool osdmap_full_flag() const;
   bool osdmap_pool_full(const int64_t pool_id) const;
+#ifdef WITH_GLOBAL_CACHE
+  
+
+  struct RetryOp {
+    map<uint32_t, std::queue<Op*>>op_waiting_for_retry; //error code retry
+    map<ceph_tid_t,Op*> reboot_retry_ops;  //reboot retry ops
+    std::vector<Op*> hangon_retry_submit_ops; //reboot hang on ops
+    mutable std::shared_mutex retrylock;
+    using unique_lock = std::unique_lock<decltype(retrylock)>;
+  };
+
+  RetryOp retry_op;
+
+  void retry_op_submit(vector<uint32_t> ready_pt_id);
 
+  void nodeview_change_retry_op_submit(int32_t clusterId, set<uint32_t> available_nodes);
+
+  bool gc_perf;
+#endif
  private:
 
+#ifdef WITH_GLOBAL_CACHE
+  int _calc_pt_target(op_target_t *t, Connection *con,
+		   bool &pt_status, bool any_change = false);
+ 
+#endif
   /**
    * Test pg_pool_t::FLAG_FULL on a pool
    *
@@ -2057,6 +2118,34 @@ private:
     return std::forward<Callback>(cb)(*osdmap, std::forward<Args>(args)...);
   }
 
+  bool errort_filter(errorcode32_t returnCode)
+  {
+    switch (returnCode) {
+      case -EINTR:
+      case -EBUSY:
+      case -ETXTBSY:
+      case -ENOSPC:
+      case -EDEADLK:
+      case -EWOULDBLOCK:
+      case -ETIME:
+      case -ECOMM:
+      case -ERESTART:
+      case -ENETDOWN:
+      case -ENETRESET:
+      case -ECONNRESET:
+      case -ENOBUFS:
+      case -ETIMEDOUT:
+      case -EHOSTDOWN:
+      case -EALREADY:
+      case -ENOMEDIUM:
+      case -ECANCELED:
+        return true;
+      default:
+        return false;
+    }
+    return false;
+  }
+
 
   /**
    * Tell the objecter to throttle outgoing ops according to its
@@ -2395,6 +2484,11 @@ public:
     vector<OSDOp> ops;
     int i = init_ops(ops, 1, extra_ops);
     ops[i].op.op = CEPH_OSD_OP_STAT;
+#ifdef WITH_GLOBAL_CACHE
+    if (!psize) {
+        ops[i].op.flags = 1;
+    }
+#endif
     C_Stat *fin = new C_Stat(psize, pmtime, onfinish);
     Op *o = new Op(oid, oloc, ops, flags | global_op_flags |
 		   CEPH_OSD_FLAG_READ, fin, objver);
diff --git a/src/test/CMakeLists.txt b/src/test/CMakeLists.txt
index 5dcee169..5bce74b2 100644
--- a/src/test/CMakeLists.txt
+++ b/src/test/CMakeLists.txt
@@ -31,6 +31,13 @@ add_subdirectory(fs)
 add_subdirectory(journal)
 add_subdirectory(libcephfs)
 add_subdirectory(librados)
+
+# Client adaptor
+if(WITH_GLOBAL_CACHE)
+add_subdirectory(ClientAdaptorTest)
+add_subdirectory(ServerAdaptorSimulate)
+endif()
+
 add_subdirectory(librados_test_stub)
 if(WITH_LIBRADOSSTRIPER)
   add_subdirectory(libradosstriper)
diff --git a/src/test/ClientAdaptorTest/CMakeLists.txt b/src/test/ClientAdaptorTest/CMakeLists.txt
new file mode 100644
index 00000000..2eb494c3
--- /dev/null
+++ b/src/test/ClientAdaptorTest/CMakeLists.txt
@@ -0,0 +1,11 @@
+# unittest_client_adaptor
+
+add_executable(client_adaptor_plugin_test
+  ClientAdaptorTest.cc
+  $<TARGET_OBJECTS:unit-main>
+  )
+target_link_libraries(client_adaptor_plugin_test global ${UNITTEST_LIBS} ceph_client_adaptor_plugin)
+
+# add_ceph_unittest(client_adaptor_test)
+
+message(STATUS "Client adaptor test cmake executing...")
diff --git a/src/test/ClientAdaptorTest/ClientAdaptorTest.cc b/src/test/ClientAdaptorTest/ClientAdaptorTest.cc
new file mode 100644
index 00000000..76ba074c
--- /dev/null
+++ b/src/test/ClientAdaptorTest/ClientAdaptorTest.cc
@@ -0,0 +1,424 @@
+/* License:LGPL-2.1
+*
+* Copyright (c) 2021 Huawei Technologies Co., Ltd All rights reserved.
+*
+  */
+
+#include <iostream>
+#include <string.h>
+#include <iomanip>
+
+#include "gtest/gtest.h"
+#include "global/global_context.h"
+
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMsg.h"
+#include "client_adaptor/ClientAdaptorMgr.h"
+#include "client_adaptor/ClientAdaptorPerf.h"
+#include "client_adaptor/open_ccm.h"
+#include "osdc/Objecter.h"
+
+class ClientAdaptorCcmMock : public ClientAdaptorMgr{
+public:
+  ClientAdaptorCcmMock(){}
+  ~ClientAdaptorCcmMock() override {}
+  int32_t init_mgr(Objecter *obj) override {
+    std::cout << "Client Adaptor: Init CCM Mock successfully" << std::endl;
+    return 0;
+  }
+
+  int32_t get_pt_num(int32_t clusterid, uint32_t& num) override {
+    num = 32;
+    std::cout << "Client Adaptor: Get total PT number is " << num << std::endl;
+
+    return 0;
+  }
+
+int32_t get_pt_entry(int32_t clusterid, uint32_t pt_index, PTViewPtEntry* entry) override {
+  std::cout << "Client Adaptor: PT index is " << pt_index << std::endl;
+  entry->curNodeInfo.nodeId = pt_index % 3;  // Assume 3 nodes in one cluster
+  std::cout << "Client Adaptor: PT entry master node id is " << entry->curNodeInfo.nodeId << std::endl;
+  return 0;
+}
+
+int32_t get_node_info(int32_t clusterid, uint32_t node_id, NodeInfo* node_info) override {
+  strcpy(node_info->publicAddrStr, "172.0.0.1");
+  node_info->ports[0] = 68;
+  node_info->portNum = 1;
+  return 0;
+}
+
+int32_t add_snap_to_gc(int64_t md_pool_id, int64_t data_pool_id, const std::string &image_id, uint64_t snap_id) {
+  return 0;
+}
+
+int32_t remove_snap_from_gc(int64_t data_pool_id, const std::string &name_space, 
+                            const std::string &image_id, uint64_t snap_id) {
+  return 0;
+}
+
+int32_t remove_gc_image_resource(const int64_t pool_id, const std::string image_id) {
+  return 0;
+}
+
+int32_t get_node_from_ma(const int64_t pool_id, int32_t *nodeId) {
+  return 0;
+}
+
+int32_t rollback_gc_snap(int64_t pool_id, int64_t data_pool_id, 
+                        const std::string image_id, uint64_t num_objs, uint64_t snap_seq,
+                        uint64_t rb_snap_id, uint64_t tp_snap_id1, uint64_t tp_snap_id2) {
+  return 0;
+}
+
+int32_t gc_is_rollbacking(int64_t md_pool_id, int64_t data_pool_id, const std::string image_id) {
+  return 0;
+}
+
+int32_t gc_snap_is_rollbacking(int64_t data_pool_id, const std::string image_id, int64_t snap_id) {
+  return 0;
+}
+
+const string name() override {
+    return "ClientAdaptorCcmMock";
+  }
+  bool get_pt_status(int32_t clusterId, uint32_t pt_id) {
+    return true;
+  }
+  void ccm_deregister(Objecter *obj) {}
+};
+
+class ClientAdaptorTest : public ::testing::Test,
+			public ::testing::WithParamInterface<const char*> {
+public:
+  string plugin;
+
+  ClientAdaptorTest() {
+  }
+  ~ClientAdaptorTest() override {
+  }
+
+  void SetUp() override {
+    std::cout << "Client Adaptor: test setup" << std::endl;
+
+    return;
+  }
+  void TearDown() override {
+    std::cout << "Client Adaptor: test teardown" << std::endl;
+    PluginRegistry *reg = g_ceph_context->get_plugin_registry();
+    lock_guard l(reg->lock);
+    reg->remove("global_cache", "client_adaptor_plugin");
+    
+    return;
+  }
+};
+
+TEST_P(ClientAdaptorTest, GetPtStatus)
+{
+  PluginRegistry *reg = g_ceph_context->get_plugin_registry();
+  ASSERT_TRUE(reg);
+  auto plugin = dynamic_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ASSERT_TRUE(plugin);
+
+  ClientAdaptorCcmMock* ccm_mock = new ClientAdaptorCcmMock();
+  uint32_t pt_id = 32;
+  EXPECT_EQ(true, ccm_mock->get_pt_status(0, pt_id));
+
+}
+
+TEST_P(ClientAdaptorTest, PluginTest)
+{
+  PluginRegistry *reg = g_ceph_context->get_plugin_registry();
+  ASSERT_TRUE(reg);
+  
+  auto dirName = g_ceph_context->_conf.get_val<string>("plugin_dir");
+  std::cout << "Client Adaptor: plugin diractory name = " << dirName << std::endl;
+  
+  auto plugin = dynamic_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ASSERT_TRUE(plugin);
+  std::cout << "Plugin address = " << plugin << std::endl;
+
+  
+  std::cout << "Client Adaptor: plugin name = " << plugin->name() << std::endl;
+  EXPECT_STREQ("ClientAdaptorPlugin", plugin->name().c_str());
+
+  auto msg = plugin->msg_ref;
+  std::cout << "Client Adaptor: msg name = " << msg->name() << std::endl;
+  EXPECT_STREQ("ClientAdaptorMsg", msg->name().c_str());
+
+  auto mgr = plugin->mgr_ref;
+  std::cout << "Client Adaptor: mgr name = " << mgr->name() << std::endl;
+  EXPECT_STREQ("ClientAdaptorCcm", mgr->name().c_str());
+
+  auto perf = plugin->perf_ref;
+  std::cout << "Client Adaptor: perf name = " << mgr->name() << std::endl;
+  EXPECT_STREQ("ClientAdaptorPerf", perf->name().c_str());
+
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+
+  return;
+}
+
+TEST_P(ClientAdaptorTest, PluginRegistryTest)
+{
+  PluginRegistry *reg = g_ceph_context->get_plugin_registry();
+  ASSERT_TRUE(reg);
+  
+  std::cout << "Client Adaptor: Plugin registry map before global cahce insert:" << std::endl; 
+  for(auto it : reg->plugins) {
+    std::cout << it.first << " --- " << it.second << std::endl;
+  }
+
+  std::cout << "Client Adaptor: Plugin registry map after global cache insert:" << std::endl;
+  auto plugin = dynamic_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ASSERT_TRUE(plugin);
+  std::cout << "Client Adaptor: Plugin address = " << plugin << std::endl;
+
+  for(auto it : reg->plugins) {
+    std::cout << "Client Adaptor: " << it.first << " --- " << it.second << std::endl;
+  }  
+
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+  return;
+}
+
+TEST_P(ClientAdaptorTest, CalNodeIpNormalTest)
+{
+  // DI ccm mock
+  PluginRegistry *reg = g_ceph_context->get_plugin_registry();
+  ASSERT_TRUE(reg);
+  auto plugin = dynamic_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ASSERT_TRUE(plugin);
+
+  ClientAdaptorCcmMock* ccm_mock = new ClientAdaptorCcmMock();
+  ClientAdaptorMgr* mgr = plugin->msg_ref->get_mgr();
+  std::cout << "Client Adaptor: Before DI Mgr subclass is " << mgr->name() << std::endl;
+  plugin->msg_ref->set_mgr(ccm_mock);
+  mgr = plugin->msg_ref->get_mgr();
+  std::cout << "Client Adaptor: After DI Mgr subclass is " << mgr->name() << std::endl;
+  EXPECT_STREQ("ClientAdaptorCcmMock", mgr->name().c_str());
+
+  string obj_name = "rbd_data.135421846e0f.0000000000000056";
+  uint64_t pool_id = 3;
+  uint32_t pt_index;
+  int32_t clusterId = 0;
+  uint32_t node_id = plugin->msg_ref->get_node_id(clusterId, obj_name, pool_id, pt_index);
+  std::cout << "Client Adaptor: PT id is " << pt_index << std::endl;
+  std::cout << "Client Adaptor: Hashed node id is 0x" << hex << node_id << std::endl;
+  EXPECT_EQ((uint32_t)0x100010, node_id);
+
+  string node_ip = "";
+  EXPECT_EQ(0, plugin->msg_ref->get_node_ip(clusterId, node_id, node_ip));
+  std::cout << "Client Adaptor: Node IP = " << node_ip << std::endl;
+  EXPECT_STREQ("tcp://172.0.0.1:68", node_ip.c_str());
+
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+  delete ccm_mock;
+  return;
+}
+
+TEST_P(ClientAdaptorTest, DasUpdateInfoTest)
+{
+  // DI ccm mock
+  PluginRegistry *reg = g_ceph_context->get_plugin_registry();
+  ASSERT_TRUE(reg);
+  auto plugin = dynamic_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ASSERT_TRUE(plugin);
+
+  Objecter tObj(g_ceph_context, NULL, NULL, NULL, 0, 0);
+  plugin->msg_ref->das_init(&tObj);
+  const char *cls = "hello";
+  const char *method = "say_hello";
+  string obj_name = "70ac98a7:::7a3ead19-df4f-4019-a4c2-38c52299e348.4389.1_test5";
+  bufferlist indata;
+  vector<OSDOp> nops(1);
+  OSDOp &op = nops[0];
+  int32_t clusterId = 0;
+
+  op.op.op = CEPH_OSD_OP_CALL;
+  op.op.cls.class_len = strlen(cls);
+  op.op.cls.method_len = strlen(method);
+  op.op.cls.indata_len = indata.length();
+  op.indata.append(cls, op.op.cls.class_len);
+  op.indata.append(method, op.op.cls.method_len);
+  op.indata.append(indata);
+  Objecter::Op *objecter_op =
+      new Objecter::Op(object_t(obj_name), object_locator_t(), nops, CEPH_OSD_FLAG_EXEC, NULL, NULL, NULL, nullptr);
+
+  plugin->msg_ref->das_update_info(clusterId, &tObj, objecter_op);
+  plugin->msg_ref->das_update_info(clusterId, &tObj, objecter_op);
+  objecter_op->target.flags = CEPH_OSD_FLAG_WRITE;
+  plugin->msg_ref->das_update_info(clusterId, &tObj, objecter_op);
+  objecter_op->target.flags = CEPH_OSD_FLAG_READ;
+  plugin->msg_ref->das_update_info(clusterId, &tObj, objecter_op);
+  objecter_op->target.base_oid.name = "rbd_data-135421846e0f-0000000000000056";
+  plugin->msg_ref->das_update_info(clusterId, &tObj, objecter_op);
+  objecter_op->target.base_oid.name = "rbd_data.135421846e0f.0000000000000056";
+  plugin->msg_ref->das_update_info(clusterId, &tObj, objecter_op);
+  OSDOp rop;
+  rop.op.op=CEPH_OSD_OP_READ;
+  rop.op.extent.offset = 10;
+  rop.op.extent.length = 4096;
+  objecter_op->ops.push_back(rop);
+  plugin->msg_ref->das_update_info(clusterId, &tObj, objecter_op);
+  objecter_op->put();
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+  return;
+}
+
+extern void das_req_prefetch(DasKvParam *params);
+TEST_P(ClientAdaptorTest, DasPushTest)
+{
+  // DI ccm mock
+  PluginRegistry *reg = g_ceph_context->get_plugin_registry();
+  ASSERT_TRUE(reg);
+  auto plugin = dynamic_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ASSERT_TRUE(plugin);
+  ClientAdaptorCcmMock* ccm_mock = new ClientAdaptorCcmMock();
+  ClientAdaptorMgr* mgr = plugin->msg_ref->get_mgr();
+
+  std::cout << "Client Adaptor: Before DI Mgr subclass is " << mgr->name() << std::endl;
+  plugin->msg_ref->set_mgr(ccm_mock);
+  mgr = plugin->msg_ref->get_mgr();
+  string obj_name = "rbd_data.135421846e0f.0000000000000056";
+  Objecter tObj(g_ceph_context, NULL, NULL, NULL, 0, 0);
+  DasKvParam *params = reinterpret_cast<DasKvParam*>(new char[sizeof(DasKvParam) + 22 + 1]);
+  params->offset = 2048;
+  params->len = 4194512;
+  params->opcode = 0;
+  params->timeStamp = ceph_clock_now().to_nsec();
+  params->cephPoolId = 2;
+  params->algType = DAS_ALG_SEQ;
+  params->objId = 3;
+  params->imageIdLen = 22;
+  memcpy(params->imageIdBuf, obj_name.c_str(), params->imageIdLen);
+  params->handle = plugin->msg_ref;
+  params->ctx = reinterpret_cast<Objecter *>(&tObj);
+  das_req_prefetch(params);
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+  delete ccm_mock;
+  return;
+}
+TEST_P(ClientAdaptorTest, DasExitPushTest)
+{
+  PluginRegistry *reg = g_ceph_context->get_plugin_registry();
+  ASSERT_TRUE(reg);
+  auto plugin = dynamic_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ASSERT_TRUE(plugin);
+
+  string obj_name = "rbd_data.135421846e0f.0000000000000056";
+  Objecter tObj(g_ceph_context, NULL, NULL, NULL, 0, 0);
+  DasKvParam *params = reinterpret_cast<DasKvParam*>(new char[sizeof(DasKvParam) + 22 + 1]);
+  params->offset = 2048;
+  params->len = 4194512;
+  params->opcode = 0;
+  params->timeStamp = ceph_clock_now().to_nsec();
+  params->cephPoolId = 2;
+  params->algType = DAS_ALG_SEQ;
+  params->objId = 3;
+  params->imageIdLen = 22;
+  memcpy(params->imageIdBuf, obj_name.c_str(), params->imageIdLen);
+  params->handle = plugin->msg_ref;
+  params->ctx = reinterpret_cast<Objecter *>(&tObj);
+  das_req_prefetch(params);
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+  das_req_prefetch(params);
+  return;
+}
+
+TEST_P(ClientAdaptorTest, MgrInitTest)
+{
+  // DI ccm mock
+  PluginRegistry *reg = g_ceph_context->get_plugin_registry();
+  ASSERT_TRUE(reg);
+  auto plugin = dynamic_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ASSERT_TRUE(plugin);
+  ClientAdaptorCcmMock* ccm_mock = new ClientAdaptorCcmMock();
+  ClientAdaptorMgr* mgr = plugin->msg_ref->get_mgr();
+  std::cout << "Client Adaptor: Before DI Mgr subclass is " << mgr->name() << std::endl;
+  plugin->msg_ref->set_mgr(ccm_mock);
+  mgr = plugin->msg_ref->get_mgr();
+  int32_t res = mgr->init_mgr(nullptr);
+  bool init_flag = (res==0?true:false);
+  mgr->set_init_flag(init_flag);
+  bool is_succeed = mgr->is_init_succeed();
+  std::cout << "Mgr init result: " << is_succeed << std::endl;
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+  delete ccm_mock;
+  return;
+}
+
+TEST_P(ClientAdaptorTest, MgrInfoTest)
+{
+  PluginRegistry *reg = g_ceph_context->get_plugin_registry();
+  ASSERT_TRUE(reg);
+  auto plugin = dynamic_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ASSERT_TRUE(plugin);
+
+  uint32_t num = 0;
+
+  string obj_name = "rbd_data.135421846e0f.0000000000000056";
+  uint64_t pool_id = 3;
+  uint32_t pt_index;
+  int32_t clusterId = 0;
+  plugin->msg_ref->get_node_id(clusterId, obj_name, pool_id, pt_index);
+  PTViewPtEntry *entry = new PTViewPtEntry();
+  NodeInfo *node_info = new NodeInfo();
+  strcpy(node_info->ipv4AddrStr, "172.0.0.1");
+  node_info->ports[0] = 68;
+  node_info->portNum = 1;
+  plugin->mgr_ref->get_pt_num(clusterId, num);
+  plugin->mgr_ref->get_pt_entry(clusterId, pt_index, entry);
+  delete node_info;
+  delete entry;
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+}
+
+TEST_P(ClientAdaptorTest, MgrInfoTest2)
+{
+  PluginRegistry *reg = g_ceph_context->get_plugin_registry();
+  ASSERT_TRUE(reg);
+  auto plugin = dynamic_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ASSERT_TRUE(plugin);
+  ClientAdaptorCcm* ccm = new ClientAdaptorCcm();
+  string obj_name = "rbd_data.135421846e0f.0000000000000056";
+  uint32_t num = 0;
+  uint64_t pool_id = 3;
+  uint32_t pt_index;
+  uint32_t node_id = 2;
+  int32_t clusterId = 0;
+  plugin->msg_ref->get_node_id(clusterId, obj_name, pool_id, pt_index);
+  PTViewPtEntry *entry = new PTViewPtEntry();
+  NodeInfo *node_info = new NodeInfo();
+  int32_t res = ccm->init_mgr(nullptr);
+  int32_t res1 = ccm->get_pt_num(clusterId, num);
+  int32_t res2 = ccm->get_pt_entry(clusterId, pt_index,entry);
+  int32_t res3 = ccm->get_node_info(clusterId, node_id,node_info);
+ 
+  EXPECT_EQ(0, res);
+  std::cout << "Mgr init result: " << res << std::endl;
+  std::cout << "Mgr init result: " << res1 << std::endl;
+  std::cout << "Mgr init result: " << res2 << std::endl;
+  std::cout << "Mgr init result: " << res3 << std::endl;
+  delete node_info;
+  delete entry;
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+  delete ccm;
+  return;
+ }
+
+
+INSTANTIATE_TEST_CASE_P(
+  ClientAdaptor,
+  ClientAdaptorTest,
+  ::testing::Values("client-adaptor")
+);
diff --git a/src/test/ClientAdaptorTest/ClientAdaptorTest.h b/src/test/ClientAdaptorTest/ClientAdaptorTest.h
new file mode 100644
index 00000000..d22ea15d
--- /dev/null
+++ b/src/test/ClientAdaptorTest/ClientAdaptorTest.h
@@ -0,0 +1,37 @@
+#include "gmock/gmock.h"
+#include "client_adaptor/ClientAdaptorMgr.h"
+
+extern "C"
+{
+#include "client_adaptor/open_ccm.h"
+}
+
+class TestMockClientAdapterCcm : public ClientAdaptorMgr {
+public:
+  TestMockClientAdapterCcm(){}
+  ~TestMockClientAdapterCcm() override {}
+  MOCK_METHOD1(init_mgr, int32_t(Objecter *));
+  MOCK_METHOD2(get_pt_num, int32_t(int32_t, uint32_t&));
+  MOCK_METHOD2(get_node_from_ma, int32_t(const int64_t pool_id, int32_t *nodeId));
+  MOCK_METHOD3(get_pt_entry, int32_t(int32_t, uint32_t, PTViewPtEntry*));
+  MOCK_METHOD3(get_node_info, int32_t(int32_t, uint32_t, NodeInfo*));
+  MOCK_METHOD2(get_pt_status, bool(int32_t, uint32_t));
+  MOCK_METHOD1(ccm_deregister, void(Objecter *));
+  MOCK_METHOD4(add_snap_to_gc, int32_t(int64_t pool_id,
+                                       int64_t data_pool_id,
+                                       const std::string &image_id,
+                                       uint64_t snap_id));
+  MOCK_METHOD4(remove_snap_from_gc, int32_t(int64_t data_pool_id, const std::string &name_space, 
+                                    const std::string &image_id, uint64_t snap_id));
+  MOCK_METHOD2(remove_gc_image_resource, int32_t(const int64_t pool_id, const std::string image_id));
+  MOCK_METHOD4(OpenCreateSnapshot, int32_t(const int64_t poolId, int64_t dataPoolId,
+                                            const char *imageId, const uint64_t SnapId));
+  MOCK_METHOD3(OpenDeleteSnapshot, int32_t(const int64_t poolId, const char *imageId, const uint64_t SnapId));
+  MOCK_METHOD2(OpenReleaseImageResource, int32_t(const int64_t pool_id, const char *imageId));
+  MOCK_METHOD8(rollback_gc_snap, int32_t(int64_t pool_id, int64_t data_pool_id, 
+                                        const std::string image_id, uint64_t num_objs,
+                                        uint64_t snap_seq, uint64_t rb_snap_id, uint64_t tp_snap_id1,
+                                        uint64_t tp_snap_id2));
+  MOCK_METHOD3(gc_is_rollbacking, int32_t(int64_t md_pool_id, int64_t data_pool_id, const std::string image_id));
+  MOCK_METHOD3(gc_snap_is_rollbacking, int32_t(int64_t data_pool_id, const std::string image_id, int64_t snap_id));
+};
diff --git a/src/test/ServerAdaptorSimulate/CMakeLists.txt b/src/test/ServerAdaptorSimulate/CMakeLists.txt
new file mode 100644
index 00000000..9d47682f
--- /dev/null
+++ b/src/test/ServerAdaptorSimulate/CMakeLists.txt
@@ -0,0 +1,9 @@
+add_executable(global_cache_server
+  global_cache_server.cc
+  global_cache_dispatcher.cc
+)
+target_link_libraries(global_cache_server
+  global ceph-common
+  ${EXTRALIBS}
+  ${CMAKE_DL_LIBS}
+)
diff --git a/src/test/ServerAdaptorSimulate/global_cache_dispatcher.cc b/src/test/ServerAdaptorSimulate/global_cache_dispatcher.cc
new file mode 100644
index 00000000..22ededee
--- /dev/null
+++ b/src/test/ServerAdaptorSimulate/global_cache_dispatcher.cc
@@ -0,0 +1,166 @@
+// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-
+// vim: ts=8 sw=2 smarttab
+/*
+ * Ceph - scalable distributed file system
+ *
+ * Copyright (C) 2013 CohortFS, LLC
+ *
+ * This is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License version 2.1, as published by the Free Software
+ * Foundation.  See file COPYING.
+ *
+ */
+
+// #include <string_view>
+#include <string>
+#include <iostream>
+#include <iomanip>
+
+#include "include/compat.h"
+#include "global_cache_dispatcher.h"
+#include "messages/MPing.h"
+#include "messages/MDataPing.h"
+#include "messages/MOSDOpReply.h"
+#include "messages/MOSDOp.h"
+
+using namespace std;
+
+GlobalCacheDispatcher::GlobalCacheDispatcher(Messenger *msgr, int32_t rval, int32_t result) :
+  Dispatcher(msgr->cct),
+  active(false),
+  messenger(msgr),
+  dcount(0),
+  rval(rval),
+  result(result)
+{
+  out_data = std::make_unique<string>(8192, 'c');
+}
+
+GlobalCacheDispatcher::~GlobalCacheDispatcher() {
+  // nothing
+}
+
+bool GlobalCacheDispatcher::ms_dispatch(Message *m)
+{
+  uint64_t dc = 0;
+
+  dc = dcount++;
+
+  ConnectionRef con = m->get_connection();
+  Messenger* msgr = con->get_messenger();
+
+  switch (m->get_type()) {
+    case CEPH_MSG_PING:
+    {
+      cout << "Client Adaptor: " << __func__ << " msg ping " << std::endl;
+      cout << "Client Adaptor: " << __func__ << " connection = " << con << "peer_addr = " 
+              << con->get_peer_addr() << std::endl;
+      break;
+    }
+    case MSG_DATA_PING:
+    {
+      MDataPing* mdp __attribute__((unused)) = static_cast<MDataPing*>(m);
+      cout << "Client Adaptor: " << __func__ << " msg data ping" << std::endl;
+      ConnectionRef con = m->get_connection();
+      con->send_message(m);
+    }
+      break;
+    case CEPH_MSG_OSD_OP:
+    {
+      cout << "Client Adaptor: " << __func__ << " osd op msg" << std::endl;
+      cout << "Client Adaptor: " << __func__ << " connection = " << con << std::endl;
+      cout << "Client Adaptor: " << __func__ << " peer_addr = " << con->get_peer_addr() << std::endl;
+      MOSDOp *mosd_op = static_cast<MOSDOp *>(m);
+      mosd_op->finish_decode();    // call to decode ops value
+      cout << "Client Adaptor: " << __func__ << " MOSDOp " << *mosd_op << std::endl;
+      cout << "Client Adaptor: " << __func__ << " pool id = " << mosd_op->get_pg().pool() << std::endl;
+      cout << "Client Adaptor: " << __func__ << " pt id = " << mosd_op->get_pg().m_seed << std::endl;
+      
+      uint32_t index = 0;
+      vector<OSDOp> &ops = mosd_op->ops;
+      for (vector<OSDOp>::iterator op = ops.begin(); op != ops.end(); index++, ++op) {
+        cout << "Client Adaptor: " << __func__ << " index = " << index 
+                << " op-code = 0x" << hex << op->op.op << std::endl;
+        string cname, mname;
+        switch (op->op.op){
+          case CEPH_OSD_OP_READ:
+          case CEPH_OSD_OP_SYNC_READ:
+          case CEPH_OSD_OP_SPARSE_READ:{
+            cout << "Client Adaptor: " << __func__ << " offset = 0x" << hex << op->op.extent.offset 
+                        << " length = 0x" << hex << op->op.extent.length << std::endl;
+            if (unlikely(op->op.op == CEPH_OSD_OP_SPARSE_READ)){
+              std::map<uint64_t, uint64_t> extents;
+              extents[op->op.extent.offset] = op->op.extent.length;
+              encode(extents, op->outdata);
+              encode(std::string_view(out_data->c_str(), op->op.extent.length), op->outdata);
+            } else {
+              string error;
+              cout << "Client Adaptor: " << __func__ << " read op" << std::endl; 
+              cout << "Client Adaptor: " << __func__ << " before length = 0x" << hex << op->outdata.length() << std::endl; 
+              op->outdata.read_file("/home/xx/ceph/ceph-14.2.8-global/build/writefile.txt", &error);
+              cout << "Client Adaptor: " << __func__ << " after length = 0x" << hex << op->outdata.length() << std::endl; 
+            }
+            op->rval = rval;
+            cout << "Client Adaptor: " << __func__ << " op rval " << op->rval << std::endl;
+            break;}
+          case CEPH_OSD_OP_WRITE:
+          case CEPH_OSD_OP_WRITEFULL:{
+            cout << "Client Adaptor: " << __func__ << " offset = 0x" << hex << op->op.extent.offset 
+                        << " length = 0x" << hex << op->op.extent.length << std::endl;
+            op->indata.write_file("/home/xx/ceph/ceph-14.2.8-global/build/writefile.txt");
+            op->rval = rval;
+            cout << "Client Adaptor: " << __func__ << " op rval " << op->rval << std::endl;
+            break;}
+          case CEPH_OSD_OP_CALL:{
+            auto bp = op->indata.cbegin();
+            bp.copy(op->op.cls.class_len, cname);
+            bp.copy(op->op.cls.method_len, mname);
+            cout << "Client Adaptor: " << __func__ << " op call class: " << cname << " method: " << mname << std::endl;
+            break;}
+          case CEPH_OSD_OP_STAT:{
+            uint64_t psize = 0x400000;
+            time_t ptime = 0;
+            encode(psize, op->outdata);
+            encode(ptime, op->outdata);
+            break;}
+          default:
+            break;
+        }
+      }
+      MOSDOpReply *reply = new MOSDOpReply(mosd_op, 0, 0, CEPH_OSD_FLAG_ACK | CEPH_OSD_FLAG_ONDISK, false);
+      reply->claim_op_out_data(mosd_op->ops);
+      reply->set_result(result);
+      cout << "Client Adaptor: " << __func__ << " Return result " << reply->get_result() << std::endl;
+      cout << "Client Adaptor: " << __func__ << " Retry time " << mosd_op->get_retry_attempt() << std::endl;
+      cout << "Client Adaptor: " << __func__ << " MOSDOpReply " << *reply << std::endl;
+      mosd_op->get_connection()->send_message(reply);
+      mosd_op->put();
+      break;
+    }
+    default:
+      ceph_abort();
+  }
+
+  if (unlikely(msgr->get_magic() & MSG_MAGIC_TRACE_CTR)) {
+    if (unlikely(dc % 65536) == 0) {
+      struct timespec ts;
+      clock_gettime(CLOCK_REALTIME_COARSE, &ts);
+      cout << "Client Adaptor: " << __func__ << " ping " << dc << " nanos: " <<
+	            ts.tv_nsec + (ts.tv_sec * 1000000000)  << std::endl;
+    }
+  } /* trace ctr */
+
+  return true;
+}
+
+bool GlobalCacheDispatcher::ms_handle_reset(Connection *con)
+{
+  return true;
+}
+
+void GlobalCacheDispatcher::ms_handle_remote_reset(Connection *con)
+{
+  // nothing
+}
+
diff --git a/src/test/ServerAdaptorSimulate/global_cache_dispatcher.h b/src/test/ServerAdaptorSimulate/global_cache_dispatcher.h
new file mode 100644
index 00000000..332366e8
--- /dev/null
+++ b/src/test/ServerAdaptorSimulate/global_cache_dispatcher.h
@@ -0,0 +1,107 @@
+// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-
+// vim: ts=8 sw=2 smarttab
+/*
+ * Ceph - scalable distributed file system
+ *
+ * Copyright (C) 2013 CohortFS, LLC
+ *
+ * This is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License version 2.1, as published by the Free Software
+ * Foundation.  See file COPYING.
+ *
+ */
+
+#ifndef GLOBAL_CACHE_DISPATCHER_H_
+#define GLOBAL_CACHE_DISPATCHER_H_
+
+#include "msg/Dispatcher.h"
+#include "msg/Messenger.h"
+
+class GlobalCacheDispatcher: public Dispatcher {
+private:
+  bool active;
+  Messenger *messenger;
+  uint64_t dcount;
+  int32_t rval;
+  int32_t result;
+  unique_ptr<string> out_data;
+
+public:
+  GlobalCacheDispatcher(Messenger *msgr, int32_t rval, int32_t result);
+  ~GlobalCacheDispatcher() override;
+  uint64_t get_dcount() { return dcount; }
+
+  void set_active() {
+    active = true;
+  };
+
+  // how i receive messages
+  bool ms_dispatch(Message *m) override;
+
+  /**
+   * This function will be called whenever a new Connection is made to the
+   * Messenger.
+   *
+   * @param con The new Connection which has been established. You are not
+   * granted a reference to it -- take one if you need one!
+   */
+  void ms_handle_connect(Connection *con) override { };
+
+  /**
+   * Callback indicating we have accepted an incoming connection.
+   *
+   * @param con The (new or existing) Connection associated with the session
+   */
+  void ms_handle_accept(Connection *con) override { };
+
+  /*
+   * this indicates that the ordered+reliable delivery semantics have
+   * been violated.  Messages may have been lost due to a fault
+   * in the network connection.
+   * Only called on lossy Connections or those you've
+   * designated mark_down_on_empty().
+   *
+   * @param con The Connection which broke. You are not granted
+   * a reference to it.
+   */
+  bool ms_handle_reset(Connection *con) override;
+
+  /**
+   * This indicates that the ordered+reliable delivery semantics
+   * have been violated because the remote somehow reset.
+   * It implies that incoming messages were dropped, and
+   * probably some of our previous outgoing messages were too.
+   *
+   * @param con The Connection which broke. You are not granted
+   * a reference to it.
+   */
+  void ms_handle_remote_reset(Connection *con) override;
+  
+  bool ms_handle_refused(Connection *con) override { return false; }
+
+  /**
+   * @defgroup Authentication
+   * @{
+   */
+  /**
+   * Retrieve the AuthAuthorizer for the given peer type. It might not
+   * provide one if it knows there is no AuthAuthorizer for that type.
+   *
+   * @param dest_type The peer type we want the authorizer for.
+   * @param a Double pointer to an AuthAuthorizer. The Dispatcher will fill
+   * in *a with the correct AuthAuthorizer, if it can. Make sure that you have
+   * set *a to NULL before calling in.
+   *
+   * @return True if this function call properly filled in *a, false otherwise.
+   */
+  bool ms_get_authorizer(int dest_type, AuthAuthorizer **a) override {
+    return false;
+  };
+
+  int ms_handle_authentication(Connection *con) override {
+    return 1;
+  }
+};
+
+#endif /* GLOBAL_CACHE_DISPATCHER_H_ */
diff --git a/src/test/ServerAdaptorSimulate/global_cache_server.cc b/src/test/ServerAdaptorSimulate/global_cache_server.cc
new file mode 100644
index 00000000..259240d5
--- /dev/null
+++ b/src/test/ServerAdaptorSimulate/global_cache_server.cc
@@ -0,0 +1,131 @@
+// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-
+// vim: ts=8 sw=2 smarttab
+/*
+ * Ceph - scalable distributed file system
+ *
+ * Copyright (C) 2013 CohortFS, LLC
+ *
+ * This is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License version 2.1, as published by the Free Software
+ * Foundation.  See file COPYING.
+ *
+ */
+
+#include <sys/types.h>
+
+#include <iostream>
+#include <string>
+
+using namespace std;
+
+#include "common/config.h"
+#include "msg/Messenger.h"
+#include "common/Timer.h"
+#include "common/ceph_argparse.h"
+#include "global/global_init.h"
+#include "global/signal_handler.h"
+#include "perfglue/heap_profiler.h"
+#include "common/address_helper.h"
+#include "global_cache_dispatcher.h"
+#include "auth/DummyAuth.h"
+#include "msg/async/AsyncMessenger.h"
+
+#define dout_subsys ceph_subsys_global_cache
+
+void usage(ostream& out)
+{
+  out << "usage: global_cache_server [options]\n"
+    "options:\n"
+    "--rval -ErrorCode\n"
+		"--result -ErrorCode\n"
+		;
+}
+
+int main(int argc, const char **argv)
+{
+	vector<const char*> args;
+	Messenger *messenger;
+	Dispatcher *dispatcher;
+	vector<const char*>::iterator arg_iter;
+	string val;
+	int32_t rval = 0;
+	int32_t result = 0;
+	entity_addr_t bind_addr;
+
+	string addr = "localhost";
+	string port = "1234";
+
+	cout << "Client Adaptor: " << __func__ << " Global Cache Server starting..." << std::endl;
+
+	argv_to_vec(argc, argv, args);
+
+	auto cct = global_init(NULL, args, CEPH_ENTITY_TYPE_ANY,
+			       CODE_ENVIRONMENT_DAEMON,
+			       CINIT_FLAG_NO_DEFAULT_CONFIG_FILE);
+
+	for (arg_iter = args.begin(); arg_iter != args.end();) {
+	  if (ceph_argparse_witharg(args, arg_iter, &val, "--rval", (char*) NULL)){
+	    rval = atoi(val.c_str());
+	  } else if (ceph_argparse_witharg(args, arg_iter, &val, "--result", (char*) NULL)){
+	    result = atoi(val.c_str());
+		} else {
+	    ++arg_iter;
+	  }
+	};
+
+	if (!args.empty()) {
+	  cerr << "What is this? -- " << args[0] << std::endl;
+	  usage(cerr);
+	  exit(1);
+	}
+
+	string dest_str = "tcp://";
+	dest_str += addr;
+	dest_str += ":";
+	dest_str += port;
+	entity_addr_from_url(&bind_addr, dest_str.c_str());
+  entity_addrvec_t bind_addrs(bind_addr);
+
+  string ms_type = g_conf().get_val<std::string>("ms_type");
+  cout << "Client Adaptor: " << __func__ << " ms_type: " << ms_type << std::endl;
+	messenger = Messenger::create(g_ceph_context, ms_type,
+				      entity_name_t::OSD(-1),
+				      "global_cache_server",
+				      0 /* nonce */,
+				      0 /* flags */);
+	// enable timing prints
+	DummyAuthClientServer dummy_auth(g_ceph_context);
+  dummy_auth.auth_registry.refresh_config();
+  messenger->set_auth_client(&dummy_auth);
+	messenger->set_auth_server(&dummy_auth);
+	messenger->set_magic(MSG_MAGIC_TRACE_CTR);
+	messenger->set_default_policy(Messenger::Policy::stateless_server(0));
+
+  // bind_addr.set_type(entity_addr_t::TYPE_LEGACY);
+  bind_addr.set_type(entity_addr_t::TYPE_MSGR2);
+	int32_t r = messenger->bind(bind_addr);
+	if (r < 0)
+		goto out;
+
+	// Set up crypto, daemonize, etc.
+	//global_init_daemonize(g_ceph_context, 0);
+	common_init_finish(g_ceph_context);
+
+	dispatcher = new GlobalCacheDispatcher(messenger, rval, result);
+	dispatcher->ms_set_require_authorizer(false);
+
+	messenger->add_dispatcher_head(dispatcher); // should reach ready()
+	messenger->start();
+        
+  cout << "Client Adaptor: " << __func__ << " server conn = " 
+	        << static_cast<AsyncMessenger *>(messenger)->lookup_conn(bind_addrs) << std::endl;
+	messenger->wait(); // can't be called until ready()
+
+	// done
+	delete messenger;
+
+out:
+	cout << "Client Adaptor: " << __func__ << " Simple Server exit" << std::endl;
+	return r;
+}
\ No newline at end of file
diff --git a/src/test/librbd/exclusive_lock/test_mock_PostAcquireRequest.cc b/src/test/librbd/exclusive_lock/test_mock_PostAcquireRequest.cc
index b38fbed9..ca184d0d 100644
--- a/src/test/librbd/exclusive_lock/test_mock_PostAcquireRequest.cc
+++ b/src/test/librbd/exclusive_lock/test_mock_PostAcquireRequest.cc
@@ -376,22 +376,22 @@ TEST_F(TestMockExclusiveLockPostAcquireRequest, JournalError) {
   InSequence seq;
   expect_is_refresh_required(mock_image_ctx, false);
 
-  MockObjectMap *mock_object_map = new MockObjectMap();
+  MockObjectMap mock_object_map;
   expect_test_features(mock_image_ctx, RBD_FEATURE_OBJECT_MAP, true);
-  expect_create_object_map(mock_image_ctx, mock_object_map);
-  expect_open_object_map(mock_image_ctx, *mock_object_map, 0);
+  expect_create_object_map(mock_image_ctx, &mock_object_map);
+  expect_open_object_map(mock_image_ctx, mock_object_map, 0);
 
-  MockJournal *mock_journal = new MockJournal();
+  MockJournal mock_journal;
   MockJournalPolicy mock_journal_policy;
   expect_test_features(mock_image_ctx, RBD_FEATURE_JOURNALING,
                        mock_image_ctx.snap_lock, true);
   expect_get_journal_policy(mock_image_ctx, mock_journal_policy);
   expect_journal_disabled(mock_journal_policy, false);
-  expect_create_journal(mock_image_ctx, mock_journal);
+  expect_create_journal(mock_image_ctx, &mock_journal);
   expect_handle_prepare_lock_complete(mock_image_ctx);
-  expect_open_journal(mock_image_ctx, *mock_journal, -EINVAL);
-  expect_close_journal(mock_image_ctx, *mock_journal);
-  expect_close_object_map(mock_image_ctx, *mock_object_map);
+  expect_open_journal(mock_image_ctx, mock_journal, -EINVAL);
+  expect_close_journal(mock_image_ctx, mock_journal);
+  expect_close_object_map(mock_image_ctx, mock_object_map);
 
   C_SaferCond acquire_ctx;
   C_SaferCond ctx;
@@ -414,24 +414,24 @@ TEST_F(TestMockExclusiveLockPostAcquireRequest, AllocateJournalTagError) {
   InSequence seq;
   expect_is_refresh_required(mock_image_ctx, false);
 
-  MockObjectMap *mock_object_map = new MockObjectMap();
+  MockObjectMap mock_object_map;
   expect_test_features(mock_image_ctx, RBD_FEATURE_OBJECT_MAP, true);
-  expect_create_object_map(mock_image_ctx, mock_object_map);
-  expect_open_object_map(mock_image_ctx, *mock_object_map, 0);
+  expect_create_object_map(mock_image_ctx, &mock_object_map);
+  expect_open_object_map(mock_image_ctx, mock_object_map, 0);
 
-  MockJournal *mock_journal = new MockJournal();
+  MockJournal mock_journal;
   MockJournalPolicy mock_journal_policy;
   expect_test_features(mock_image_ctx, RBD_FEATURE_JOURNALING,
                        mock_image_ctx.snap_lock, true);
   expect_get_journal_policy(mock_image_ctx, mock_journal_policy);
   expect_journal_disabled(mock_journal_policy, false);
-  expect_create_journal(mock_image_ctx, mock_journal);
+  expect_create_journal(mock_image_ctx, &mock_journal);
   expect_handle_prepare_lock_complete(mock_image_ctx);
-  expect_open_journal(mock_image_ctx, *mock_journal, 0);
+  expect_open_journal(mock_image_ctx, mock_journal, 0);
   expect_get_journal_policy(mock_image_ctx, mock_journal_policy);
   expect_allocate_journal_tag(mock_image_ctx, mock_journal_policy, -EPERM);
-  expect_close_journal(mock_image_ctx, *mock_journal);
-  expect_close_object_map(mock_image_ctx, *mock_object_map);
+  expect_close_journal(mock_image_ctx, mock_journal);
+  expect_close_object_map(mock_image_ctx, mock_object_map);
 
   C_SaferCond acquire_ctx;
   C_SaferCond ctx;
@@ -454,10 +454,10 @@ TEST_F(TestMockExclusiveLockPostAcquireRequest, OpenObjectMapError) {
   InSequence seq;
   expect_is_refresh_required(mock_image_ctx, false);
 
-  MockObjectMap *mock_object_map = new MockObjectMap();
+  MockObjectMap mock_object_map;
   expect_test_features(mock_image_ctx, RBD_FEATURE_OBJECT_MAP, true);
-  expect_create_object_map(mock_image_ctx, mock_object_map);
-  expect_open_object_map(mock_image_ctx, *mock_object_map, -EINVAL);
+  expect_create_object_map(mock_image_ctx, &mock_object_map);
+  expect_open_object_map(mock_image_ctx, mock_object_map, -EINVAL);
   expect_handle_prepare_lock_complete(mock_image_ctx);
 
   C_SaferCond *acquire_ctx = new C_SaferCond();
@@ -482,10 +482,10 @@ TEST_F(TestMockExclusiveLockPostAcquireRequest, OpenObjectMapTooBig) {
   InSequence seq;
   expect_is_refresh_required(mock_image_ctx, false);
 
-  MockObjectMap *mock_object_map = new MockObjectMap();
+  MockObjectMap mock_object_map;
   expect_test_features(mock_image_ctx, RBD_FEATURE_OBJECT_MAP, true);
-  expect_create_object_map(mock_image_ctx, mock_object_map);
-  expect_open_object_map(mock_image_ctx, *mock_object_map, -EFBIG);
+  expect_create_object_map(mock_image_ctx, &mock_object_map);
+  expect_open_object_map(mock_image_ctx, mock_object_map, -EFBIG);
 
   MockJournal mock_journal;
   MockJournalPolicy mock_journal_policy;
diff --git a/src/test/librbd/exclusive_lock/test_mock_PreReleaseRequest.cc b/src/test/librbd/exclusive_lock/test_mock_PreReleaseRequest.cc
index 989e793f..38110a33 100644
--- a/src/test/librbd/exclusive_lock/test_mock_PreReleaseRequest.cc
+++ b/src/test/librbd/exclusive_lock/test_mock_PreReleaseRequest.cc
@@ -138,13 +138,13 @@ TEST_F(TestMockExclusiveLockPreReleaseRequest, Success) {
 
   expect_flush_notifies(mock_image_ctx);
 
-  MockJournal *mock_journal = new MockJournal();
-  mock_image_ctx.journal = mock_journal;
-  expect_close_journal(mock_image_ctx, *mock_journal, -EINVAL);
+  MockJournal mock_journal;
+  mock_image_ctx.journal = &mock_journal;
+  expect_close_journal(mock_image_ctx, mock_journal, -EINVAL);
 
-  MockObjectMap *mock_object_map = new MockObjectMap();
-  mock_image_ctx.object_map = mock_object_map;
-  expect_close_object_map(mock_image_ctx, *mock_object_map);
+  MockObjectMap mock_object_map;
+  mock_image_ctx.object_map = &mock_object_map;
+  expect_close_object_map(mock_image_ctx, mock_object_map);
 
   expect_handle_prepare_lock_complete(mock_image_ctx);
 
@@ -173,9 +173,9 @@ TEST_F(TestMockExclusiveLockPreReleaseRequest, SuccessJournalDisabled) {
 
   expect_flush_notifies(mock_image_ctx);
 
-  MockObjectMap *mock_object_map = new MockObjectMap();
-  mock_image_ctx.object_map = mock_object_map;
-  expect_close_object_map(mock_image_ctx, *mock_object_map);
+  MockObjectMap mock_object_map;
+  mock_image_ctx.object_map = &mock_object_map;
+  expect_close_object_map(mock_image_ctx, mock_object_map);
 
   expect_handle_prepare_lock_complete(mock_image_ctx);
 
@@ -228,13 +228,13 @@ TEST_F(TestMockExclusiveLockPreReleaseRequest, Blacklisted) {
 
   expect_flush_notifies(mock_image_ctx);
 
-  MockJournal *mock_journal = new MockJournal();
-  mock_image_ctx.journal = mock_journal;
-  expect_close_journal(mock_image_ctx, *mock_journal, -EBLACKLISTED);
+  MockJournal mock_journal;
+  mock_image_ctx.journal = &mock_journal;
+  expect_close_journal(mock_image_ctx, mock_journal, -EBLACKLISTED);
 
-  MockObjectMap *mock_object_map = new MockObjectMap();
-  mock_image_ctx.object_map = mock_object_map;
-  expect_close_object_map(mock_image_ctx, *mock_object_map);
+  MockObjectMap mock_object_map;
+  mock_image_ctx.object_map = &mock_object_map;
+  expect_close_object_map(mock_image_ctx, mock_object_map);
 
   expect_handle_prepare_lock_complete(mock_image_ctx);
 
diff --git a/src/test/librbd/image/test_mock_PreRemoveRequest.cc b/src/test/librbd/image/test_mock_PreRemoveRequest.cc
index 65a20db9..a438be8f 100644
--- a/src/test/librbd/image/test_mock_PreRemoveRequest.cc
+++ b/src/test/librbd/image/test_mock_PreRemoveRequest.cc
@@ -285,17 +285,17 @@ TEST_F(TestMockImagePreRemoveRequest, ExclusiveLockTryAcquireNotLockOwner) {
 TEST_F(TestMockImagePreRemoveRequest, Force) {
   REQUIRE_FEATURE(RBD_FEATURE_EXCLUSIVE_LOCK);
 
-  MockExclusiveLock *mock_exclusive_lock = new MockExclusiveLock();
-  m_mock_imctx->exclusive_lock = mock_exclusive_lock;
+  MockExclusiveLock mock_exclusive_lock;
+  m_mock_imctx->exclusive_lock = &mock_exclusive_lock;
 
   expect_op_work_queue(*m_mock_imctx);
   expect_test_features(*m_mock_imctx);
 
   InSequence seq;
   expect_set_journal_policy(*m_mock_imctx);
-  expect_try_acquire_exclusive_lock(*m_mock_imctx, *mock_exclusive_lock,
+  expect_try_acquire_exclusive_lock(*m_mock_imctx, mock_exclusive_lock,
                                     -EINVAL);
-  expect_shut_down_exclusive_lock(*m_mock_imctx, *mock_exclusive_lock, 0);
+  expect_shut_down_exclusive_lock(*m_mock_imctx, mock_exclusive_lock, 0);
 
   MockListWatchersRequest mock_list_watchers_request;
   expect_list_image_watchers(*m_mock_imctx, mock_list_watchers_request, 0);
@@ -312,16 +312,16 @@ TEST_F(TestMockImagePreRemoveRequest, Force) {
 TEST_F(TestMockImagePreRemoveRequest, ExclusiveLockShutDownFailed) {
   REQUIRE_FEATURE(RBD_FEATURE_EXCLUSIVE_LOCK);
 
-  MockExclusiveLock *mock_exclusive_lock = new MockExclusiveLock();
-  m_mock_imctx->exclusive_lock = mock_exclusive_lock;
+  MockExclusiveLock mock_exclusive_lock;
+  m_mock_imctx->exclusive_lock = &mock_exclusive_lock;
 
   expect_op_work_queue(*m_mock_imctx);
   expect_test_features(*m_mock_imctx);
 
   InSequence seq;
   expect_set_journal_policy(*m_mock_imctx);
-  expect_try_acquire_exclusive_lock(*m_mock_imctx, *mock_exclusive_lock, -EINVAL);
-  expect_shut_down_exclusive_lock(*m_mock_imctx, *mock_exclusive_lock, -EINVAL);
+  expect_try_acquire_exclusive_lock(*m_mock_imctx, mock_exclusive_lock, -EINVAL);
+  expect_shut_down_exclusive_lock(*m_mock_imctx, mock_exclusive_lock, -EINVAL);
 
   C_SaferCond ctx;
   auto req = MockPreRemoveRequest::create(m_mock_imctx, true, &ctx);
diff --git a/src/test/librbd/image/test_mock_RefreshRequest.cc b/src/test/librbd/image/test_mock_RefreshRequest.cc
index a920948f..e7c2df97 100644
--- a/src/test/librbd/image/test_mock_RefreshRequest.cc
+++ b/src/test/librbd/image/test_mock_RefreshRequest.cc
@@ -851,8 +851,8 @@ TEST_F(TestMockImageRefreshRequest, DisableExclusiveLock) {
   MockRefreshImageCtx mock_image_ctx(*ictx);
   MockRefreshParentRequest mock_refresh_parent_request;
 
-  MockExclusiveLock *mock_exclusive_lock = new MockExclusiveLock();
-  mock_image_ctx.exclusive_lock = mock_exclusive_lock;
+  MockExclusiveLock mock_exclusive_lock;
+  mock_image_ctx.exclusive_lock = &mock_exclusive_lock;
 
   MockObjectMap mock_object_map;
   if (ictx->test_features(RBD_FEATURE_OBJECT_MAP)) {
@@ -893,7 +893,7 @@ TEST_F(TestMockImageRefreshRequest, DisableExclusiveLock) {
   expect_apply_metadata(mock_image_ctx, 0);
   expect_get_group(mock_image_ctx, 0);
   expect_refresh_parent_is_required(mock_refresh_parent_request, false);
-  expect_shut_down_exclusive_lock(mock_image_ctx, *mock_exclusive_lock, 0);
+  expect_shut_down_exclusive_lock(mock_image_ctx, mock_exclusive_lock, 0);
 
   C_SaferCond ctx;
   MockRefreshRequest *req = new MockRefreshRequest(mock_image_ctx, false, false, &ctx);
@@ -1098,8 +1098,8 @@ TEST_F(TestMockImageRefreshRequest, DisableJournal) {
     mock_image_ctx.object_map = &mock_object_map;
   }
 
-  MockJournal *mock_journal = new MockJournal();
-  mock_image_ctx.journal = mock_journal;
+  MockJournal mock_journal;
+  mock_image_ctx.journal = &mock_journal;
 
   if (ictx->test_features(RBD_FEATURE_JOURNALING)) {
     ASSERT_EQ(0, ictx->operations->update_features(RBD_FEATURE_JOURNALING,
@@ -1123,7 +1123,7 @@ TEST_F(TestMockImageRefreshRequest, DisableJournal) {
   if (!mock_image_ctx.clone_copy_on_read) {
     expect_set_require_lock(mock_image_ctx, librbd::io::DIRECTION_READ, false);
   }
-  expect_close_journal(mock_image_ctx, *mock_journal, 0);
+  expect_close_journal(mock_image_ctx, mock_journal, 0);
   expect_unblock_writes(mock_image_ctx);
 
   C_SaferCond ctx;
@@ -1226,8 +1226,8 @@ TEST_F(TestMockImageRefreshRequest, DisableObjectMap) {
   MockExclusiveLock mock_exclusive_lock;
   mock_image_ctx.exclusive_lock = &mock_exclusive_lock;
 
-  MockObjectMap *mock_object_map = new MockObjectMap();
-  mock_image_ctx.object_map = mock_object_map;
+  MockObjectMap mock_object_map;
+  mock_image_ctx.object_map = &mock_object_map;
 
   MockJournal mock_journal;
   if (ictx->test_features(RBD_FEATURE_JOURNALING)) {
@@ -1252,7 +1252,7 @@ TEST_F(TestMockImageRefreshRequest, DisableObjectMap) {
   expect_apply_metadata(mock_image_ctx, 0);
   expect_get_group(mock_image_ctx, 0);
   expect_refresh_parent_is_required(mock_refresh_parent_request, false);
-  expect_close_object_map(mock_image_ctx, *mock_object_map, 0);
+  expect_close_object_map(mock_image_ctx, mock_object_map, 0);
 
   C_SaferCond ctx;
   MockRefreshRequest *req = new MockRefreshRequest(mock_image_ctx, false, false, &ctx);
@@ -1280,7 +1280,7 @@ TEST_F(TestMockImageRefreshRequest, OpenObjectMapError) {
   MockExclusiveLock mock_exclusive_lock;
   mock_image_ctx.exclusive_lock = &mock_exclusive_lock;
 
-  MockObjectMap *mock_object_map = new MockObjectMap();
+  MockObjectMap mock_object_map;
 
   expect_op_work_queue(mock_image_ctx);
   expect_test_features(mock_image_ctx);
@@ -1294,7 +1294,7 @@ TEST_F(TestMockImageRefreshRequest, OpenObjectMapError) {
   expect_apply_metadata(mock_image_ctx, 0);
   expect_get_group(mock_image_ctx, 0);
   expect_refresh_parent_is_required(mock_refresh_parent_request, false);
-  expect_open_object_map(mock_image_ctx, mock_object_map, -EBLACKLISTED);
+  expect_open_object_map(mock_image_ctx, &mock_object_map, -EBLACKLISTED);
 
   C_SaferCond ctx;
   MockRefreshRequest *req = new MockRefreshRequest(mock_image_ctx, false, false,
@@ -1324,7 +1324,7 @@ TEST_F(TestMockImageRefreshRequest, OpenObjectMapTooLarge) {
   MockExclusiveLock mock_exclusive_lock;
   mock_image_ctx.exclusive_lock = &mock_exclusive_lock;
 
-  MockObjectMap *mock_object_map = new MockObjectMap();
+  MockObjectMap mock_object_map;
 
   expect_op_work_queue(mock_image_ctx);
   expect_test_features(mock_image_ctx);
@@ -1338,7 +1338,7 @@ TEST_F(TestMockImageRefreshRequest, OpenObjectMapTooLarge) {
   expect_apply_metadata(mock_image_ctx, 0);
   expect_get_group(mock_image_ctx, 0);
   expect_refresh_parent_is_required(mock_refresh_parent_request, false);
-  expect_open_object_map(mock_image_ctx, mock_object_map, -EFBIG);
+  expect_open_object_map(mock_image_ctx, &mock_object_map, -EFBIG);
 
   C_SaferCond ctx;
   MockRefreshRequest *req = new MockRefreshRequest(mock_image_ctx, false, false,
diff --git a/src/test/librbd/io/test_mock_ImageRequestWQ.cc b/src/test/librbd/io/test_mock_ImageRequestWQ.cc
index 50daa83c..db0e7c9f 100644
--- a/src/test/librbd/io/test_mock_ImageRequestWQ.cc
+++ b/src/test/librbd/io/test_mock_ImageRequestWQ.cc
@@ -58,6 +58,12 @@ struct ImageDispatchSpec<librbd::MockTestImageCtx> {
     return s_instance;
   }
 
+#ifdef WITH_GLOBAL_CACHE
+  AioCompletion* get_completion() {
+    return aio_comp;
+  }
+#endif
+
   MOCK_CONST_METHOD0(is_write_op, bool());
   MOCK_CONST_METHOD0(start_op, void());
   MOCK_CONST_METHOD0(send, void());
diff --git a/src/test/librbd/journal/test_Replay.cc b/src/test/librbd/journal/test_Replay.cc
index 88b01c60..f498ffdf 100644
--- a/src/test/librbd/journal/test_Replay.cc
+++ b/src/test/librbd/journal/test_Replay.cc
@@ -65,7 +65,8 @@ public:
     C_SaferCond close_cond;
     ictx->journal->close(&close_cond);
     ASSERT_EQ(0, close_cond.wait());
-    delete ictx->journal;
+    
+    ictx->journal->put();
     ictx->journal = nullptr;
 
     C_SaferCond cond;
diff --git a/src/test/librbd/journal/test_mock_Replay.cc b/src/test/librbd/journal/test_mock_Replay.cc
index 62014bab..2cb29e50 100644
--- a/src/test/librbd/journal/test_mock_Replay.cc
+++ b/src/test/librbd/journal/test_mock_Replay.cc
@@ -847,6 +847,7 @@ TEST_F(TestMockJournalReplay, MissingOpFinishEvent) {
 					  "snap")},
                &on_snap_remove_ready,
 	       &on_snap_remove_safe);
+  ictx->op_work_queue->drain();
   ASSERT_EQ(0, on_snap_remove_ready.wait());
 
   C_SaferCond on_snap_create_ready;
@@ -857,7 +858,7 @@ TEST_F(TestMockJournalReplay, MissingOpFinishEvent) {
 					  "snap")},
                &on_snap_create_ready,
 	       &on_snap_create_safe);
-
+  ictx->op_work_queue->drain();
   C_SaferCond on_shut_down;
   mock_journal_replay.shut_down(false, &on_shut_down);
 
@@ -903,6 +904,7 @@ TEST_F(TestMockJournalReplay, MissingOpFinishEventCancelOps) {
 					  "snap")},
                &on_snap_remove_ready,
 	       &on_snap_remove_safe);
+  ictx->op_work_queue->drain();
   ASSERT_EQ(0, on_snap_remove_ready.wait());
 
   C_SaferCond on_snap_create_ready;
@@ -913,6 +915,7 @@ TEST_F(TestMockJournalReplay, MissingOpFinishEventCancelOps) {
 					  "snap")},
                &on_snap_create_ready,
 	       &on_snap_create_safe);
+  ictx->op_work_queue->drain();
 
   C_SaferCond on_resume;
   when_replay_op_ready(mock_journal_replay, 123, &on_resume);
diff --git a/src/test/librbd/mock/MockExclusiveLock.h b/src/test/librbd/mock/MockExclusiveLock.h
index efb4fa4e..2bf552f3 100644
--- a/src/test/librbd/mock/MockExclusiveLock.h
+++ b/src/test/librbd/mock/MockExclusiveLock.h
@@ -4,6 +4,7 @@
 #ifndef CEPH_TEST_LIBRBD_MOCK_EXCLUSIVE_LOCK_H
 #define CEPH_TEST_LIBRBD_MOCK_EXCLUSIVE_LOCK_H
 
+#include "common/RefCountedObj.h"
 #include "include/int_types.h"
 #include "include/rados/librados.hpp"
 #include "librbd/exclusive_lock/Policy.h"
@@ -34,6 +35,9 @@ struct MockExclusiveLock {
   MOCK_METHOD0(get_unlocked_op_error, int());
 
   MOCK_METHOD1(start_op, Context*(int*));
+
+  void get() {}
+  void put() {}
 };
 
 } // namespace librbd
diff --git a/src/test/librbd/mock/MockJournal.h b/src/test/librbd/mock/MockJournal.h
index 31806217..15baf790 100644
--- a/src/test/librbd/mock/MockJournal.h
+++ b/src/test/librbd/mock/MockJournal.h
@@ -4,6 +4,7 @@
 #ifndef CEPH_TEST_LIBRBD_MOCK_JOURNAL_H
 #define CEPH_TEST_LIBRBD_MOCK_JOURNAL_H
 
+#include "common/RefCountedObj.h"
 #include "gmock/gmock.h"
 #include "include/rados/librados_fwd.hpp"
 #include "librbd/Journal.h"
@@ -41,6 +42,9 @@ struct MockJournal {
     s_instance = this;
   }
 
+  void get() {}
+  void put() {}
+
   MOCK_CONST_METHOD0(is_journal_ready, bool());
   MOCK_CONST_METHOD0(is_journal_replaying, bool());
   MOCK_CONST_METHOD0(is_journal_appending, bool());
diff --git a/src/test/librbd/mock/MockObjectMap.h b/src/test/librbd/mock/MockObjectMap.h
index 2692a30f..d7240840 100644
--- a/src/test/librbd/mock/MockObjectMap.h
+++ b/src/test/librbd/mock/MockObjectMap.h
@@ -26,6 +26,9 @@ struct MockObjectMap {
   MOCK_METHOD3(aio_resize, void(uint64_t new_size, uint8_t default_object_state,
                                 Context *on_finish));
 
+  void get() {}
+  void put() {}
+
   template <typename T, void(T::*MF)(int) = &T::complete>
   bool aio_update(uint64_t snap_id, uint64_t start_object_no, uint8_t new_state,
                   const boost::optional<uint8_t> &current_state,
diff --git a/src/test/librbd/object_map/test_mock_SnapshotRemoveRequest.cc b/src/test/librbd/object_map/test_mock_SnapshotRemoveRequest.cc
index b9dd8168..aa3d7d25 100644
--- a/src/test/librbd/object_map/test_mock_SnapshotRemoveRequest.cc
+++ b/src/test/librbd/object_map/test_mock_SnapshotRemoveRequest.cc
@@ -294,11 +294,12 @@ TEST_F(TestMockObjectMapSnapshotRemoveRequest, ScrubCleanObjects) {
   
   C_SaferCond cond_ctx1;
   {
-    librbd::ObjectMap om(*ictx, ictx->snap_id);
+    librbd::ObjectMap<> *om = new librbd::ObjectMap<>(*ictx, ictx->snap_id);
     RWLock::RLocker owner_locker(ictx->owner_lock);
     RWLock::WLocker snap_locker(ictx->snap_lock);
-    om.set_object_map(object_map);
-    om.aio_save(&cond_ctx1);
+    om->set_object_map(object_map);
+    om->aio_save(&cond_ctx1);
+    om->put();
   }
   ASSERT_EQ(0, cond_ctx1.wait());
   ASSERT_EQ(0, snap_create(*ictx, "snap1"));
diff --git a/src/test/librbd/operation/test_mock_DisableFeaturesRequest.cc b/src/test/librbd/operation/test_mock_DisableFeaturesRequest.cc
index e7843586..faabf2da 100644
--- a/src/test/librbd/operation/test_mock_DisableFeaturesRequest.cc
+++ b/src/test/librbd/operation/test_mock_DisableFeaturesRequest.cc
@@ -292,13 +292,9 @@ TEST_F(TestMockOperationDisableFeaturesRequest, All) {
 
   MockOperationImageCtx mock_image_ctx(*ictx);
   MockExclusiveLock mock_exclusive_lock;
-  MockJournal mock_journal_stack;
-  MockJournal *mock_journal = &mock_journal_stack;
-  if (features_to_disable & RBD_FEATURE_JOURNALING) {
-    mock_journal = new MockJournal();
-  }
+  MockJournal mock_journal;
   MockObjectMap mock_object_map;
-  initialize_features(ictx, mock_image_ctx, mock_exclusive_lock, *mock_journal,
+  initialize_features(ictx, mock_image_ctx, mock_exclusive_lock, mock_journal,
 		      mock_object_map);
 
   expect_verify_lock_ownership(mock_image_ctx);
@@ -444,9 +440,9 @@ TEST_F(TestMockOperationDisableFeaturesRequest, Mirroring) {
 
   MockOperationImageCtx mock_image_ctx(*ictx);
   MockExclusiveLock mock_exclusive_lock;
-  MockJournal *mock_journal = new MockJournal();
+  MockJournal mock_journal;
   MockObjectMap mock_object_map;
-  initialize_features(ictx, mock_image_ctx, mock_exclusive_lock, *mock_journal,
+  initialize_features(ictx, mock_image_ctx, mock_exclusive_lock, mock_journal,
 		      mock_object_map);
 
   expect_verify_lock_ownership(mock_image_ctx);
@@ -487,9 +483,9 @@ TEST_F(TestMockOperationDisableFeaturesRequest, MirroringError) {
 
   MockOperationImageCtx mock_image_ctx(*ictx);
   MockExclusiveLock mock_exclusive_lock;
-  MockJournal *mock_journal = new MockJournal();
+  MockJournal mock_journal;
   MockObjectMap mock_object_map;
-  initialize_features(ictx, mock_image_ctx, mock_exclusive_lock, *mock_journal,
+  initialize_features(ictx, mock_image_ctx, mock_exclusive_lock, mock_journal,
 		      mock_object_map);
 
   expect_verify_lock_ownership(mock_image_ctx);
diff --git a/src/test/librbd/operation/test_mock_SnapshotCreateRequest.cc b/src/test/librbd/operation/test_mock_SnapshotCreateRequest.cc
index 64d995d4..e8df6067 100644
--- a/src/test/librbd/operation/test_mock_SnapshotCreateRequest.cc
+++ b/src/test/librbd/operation/test_mock_SnapshotCreateRequest.cc
@@ -12,6 +12,11 @@
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 
+#ifdef WITH_GLOBAL_CACHE
+#include "test/ClientAdaptorTest/ClientAdaptorTest.h"
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMgr.h"
+#endif
 // template definitions
 #include "librbd/operation/SnapshotCreateRequest.cc"
 
@@ -77,6 +82,25 @@ public:
     }
   }
 
+#ifdef WITH_GLOBAL_CACHE
+  void expect_relese_snap(MockImageCtx &mock_image_ctx, int r) {
+      auto &expect = EXPECT_CALL(get_mock_io_ctx(mock_image_ctx.md_ctx),
+                               exec(mock_image_ctx.header_oid, _, StrEq("rbd"),
+                               StrEq(mock_image_ctx.old_format ? "snap_remove" :
+                                                                 "snapshot_remove"),
+                               _, _, _));
+      if (r < 0) {
+        expect.WillOnce(Return(r));
+      } else {
+        expect.WillOnce(DoDefault());
+      }
+  }
+  void expect_add_snap_to_gc(TestMockClientAdapterCcm &ccm, int r) {
+      auto &expect = EXPECT_CALL(ccm, add_snap_to_gc(_, _, _, _));
+      expect.WillOnce(Return(r));
+  }
+#endif
+
   void expect_object_map_snap_create(MockImageCtx &mock_image_ctx) {
     if (mock_image_ctx.object_map != nullptr) {
       EXPECT_CALL(*mock_image_ctx.object_map, snapshot_add(_, _))
@@ -100,7 +124,7 @@ public:
 };
 
 TEST_F(TestMockOperationSnapshotCreateRequest, Success) {
-  REQUIRE_FORMAT_V2();
+  // REQUIRE_FORMAT_V2();
 
   librbd::ImageCtx *ictx;
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
@@ -120,6 +144,15 @@ TEST_F(TestMockOperationSnapshotCreateRequest, Success) {
   expect_verify_lock_ownership(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+#ifdef WITH_GLOBAL_CACHE
+  TestMockClientAdapterCcm ccm;
+  PluginRegistry *reg = mock_image_ctx.cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ClientAdaptorMgr* old_mgr = plugin->mgr_ref;
+  plugin->mgr_ref = &ccm;
+  expect_add_snap_to_gc(ccm, 0);
+#endif
+
   ::testing::InSequence seq;
   expect_block_writes(mock_image_ctx);
   expect_allocate_snap_id(mock_image_ctx, 0);
@@ -139,7 +172,68 @@ TEST_F(TestMockOperationSnapshotCreateRequest, Success) {
     req->send();
   }
   ASSERT_EQ(0, cond_ctx.wait());
+#ifdef WITH_GLOBAL_CACHE
+  plugin->mgr_ref = old_mgr;
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+#endif
+}
+
+#ifdef WITH_GLOBAL_CACHE
+TEST_F(TestMockOperationSnapshotCreateRequest, Fail) {
+  librbd::ImageCtx *ictx;
+  ASSERT_EQ(0, open_image(m_image_name, &ictx));
+
+  MockImageCtx mock_image_ctx(*ictx);
+
+  MockExclusiveLock mock_exclusive_lock;
+  if (ictx->test_features(RBD_FEATURE_EXCLUSIVE_LOCK)) {
+    mock_image_ctx.exclusive_lock = &mock_exclusive_lock;
+  }
+
+  MockObjectMap mock_object_map;
+  if (ictx->test_features(RBD_FEATURE_OBJECT_MAP)) {
+    mock_image_ctx.object_map = &mock_object_map;
+  }
+
+  expect_verify_lock_ownership(mock_image_ctx);
+  expect_op_work_queue(mock_image_ctx);
+
+  ::testing::InSequence seq;
+  expect_block_writes(mock_image_ctx);
+  expect_allocate_snap_id(mock_image_ctx, 0);
+  expect_snap_create(mock_image_ctx, 0);
+
+  TestMockClientAdapterCcm ccm;
+  PluginRegistry *reg = mock_image_ctx.cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ClientAdaptorMgr* old_mgr = plugin->mgr_ref;
+  plugin->mgr_ref = &ccm;
+  expect_add_snap_to_gc(ccm, -1);
+
+  expect_relese_snap(mock_image_ctx, 0);
+  expect_release_snap_id(mock_image_ctx, 0);
+  if (!mock_image_ctx.old_format) {
+    expect_object_map_snap_create(mock_image_ctx);
+   expect_update_snap_context(mock_image_ctx);
+  }
+  expect_unblock_writes(mock_image_ctx);
+
+  C_SaferCond cond_ctx;
+  MockSnapshotCreateRequest *req = new MockSnapshotCreateRequest(
+    mock_image_ctx, &cond_ctx, cls::rbd::UserSnapshotNamespace(),
+      "snap1", 0, false);
+  {
+    RWLock::RLocker owner_locker(mock_image_ctx.owner_lock);
+    req->send();
+  }
+  ASSERT_EQ(-1, cond_ctx.wait());
+
+  plugin->mgr_ref = old_mgr;
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
 }
+#endif
 
 TEST_F(TestMockOperationSnapshotCreateRequest, AllocateSnapIdError) {
   librbd::ImageCtx *ictx;
@@ -193,6 +287,16 @@ TEST_F(TestMockOperationSnapshotCreateRequest, CreateSnapStale) {
   expect_block_writes(mock_image_ctx);
   expect_allocate_snap_id(mock_image_ctx, -ESTALE);
   expect_snap_create(mock_image_ctx, -ESTALE);
+
+#ifdef WITH_GLOBAL_CACHE
+  TestMockClientAdapterCcm ccm;
+  PluginRegistry *reg = mock_image_ctx.cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ClientAdaptorMgr* old_mgr = plugin->mgr_ref;
+  plugin->mgr_ref = &ccm;
+  expect_add_snap_to_gc(ccm, 0);
+#endif
+
   if (!mock_image_ctx.old_format) {
     expect_object_map_snap_create(mock_image_ctx);
     expect_update_snap_context(mock_image_ctx);
@@ -208,6 +312,11 @@ TEST_F(TestMockOperationSnapshotCreateRequest, CreateSnapStale) {
     req->send();
   }
   ASSERT_EQ(0, cond_ctx.wait());
+#ifdef WITH_GLOBAL_CACHE
+  plugin->mgr_ref = old_mgr;
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+#endif
 }
 
 TEST_F(TestMockOperationSnapshotCreateRequest, CreateSnapError) {
diff --git a/src/test/librbd/operation/test_mock_SnapshotRemoveRequest.cc b/src/test/librbd/operation/test_mock_SnapshotRemoveRequest.cc
index 53c0ca1b..25702ba1 100644
--- a/src/test/librbd/operation/test_mock_SnapshotRemoveRequest.cc
+++ b/src/test/librbd/operation/test_mock_SnapshotRemoveRequest.cc
@@ -13,6 +13,11 @@
 #include "librbd/operation/SnapshotRemoveRequest.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
+#ifdef WITH_GLOBAL_CACHE
+#include "test/ClientAdaptorTest/ClientAdaptorTest.h"
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMgr.h"
+#endif
 
 // template definitions
 #include "librbd/operation/SnapshotRemoveRequest.cc"
@@ -194,11 +199,30 @@ public:
                                   .WillOnce(DoDefault());
   }
 
+#ifdef WITH_GLOBAL_CACHE
+  void expect_add_snap_to_gc(TestMockClientAdapterCcm &ccm, int r) {
+      auto &expect = EXPECT_CALL(ccm, add_snap_to_gc(_, _, _, _));
+      expect.WillOnce(Return(r));
+  }
+  void expect_remove_snap_from_gc(TestMockClientAdapterCcm &ccm, int r) {
+      auto &expect = EXPECT_CALL(ccm, remove_snap_from_gc(_, _, _, _));
+      expect.WillOnce(Return(r));
+  }
+#endif
 };
 
 TEST_F(TestMockOperationSnapshotRemoveRequest, Success) {
   librbd::ImageCtx *ictx;
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
+#ifdef WITH_GLOBAL_CACHE
+  TestMockClientAdapterCcm ccm;
+  PluginRegistry *reg = ictx->cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ClientAdaptorMgr* old_mgr = plugin->mgr_ref;
+  plugin->mgr_ref = &ccm;
+  expect_add_snap_to_gc(ccm, 0);
+  expect_remove_snap_from_gc(ccm, 0);
+#endif
   ASSERT_EQ(0, snap_create(*ictx, "snap1"));
   ASSERT_EQ(0, ictx->state->refresh_if_required());
 
@@ -239,6 +263,11 @@ TEST_F(TestMockOperationSnapshotRemoveRequest, Success) {
     req->send();
   }
   ASSERT_EQ(0, cond_ctx.wait());
+#ifdef WITH_GLOBAL_CACHE
+  plugin->mgr_ref = old_mgr;
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+#endif
 }
 
 TEST_F(TestMockOperationSnapshotRemoveRequest, SuccessCloneParent) {
@@ -672,6 +701,15 @@ TEST_F(TestMockOperationSnapshotRemoveRequest, RemoveChildError) {
 TEST_F(TestMockOperationSnapshotRemoveRequest, RemoveSnapError) {
   librbd::ImageCtx *ictx;
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
+#ifdef WITH_GLOBAL_CACHE
+  TestMockClientAdapterCcm ccm;
+  PluginRegistry *reg = ictx->cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+  ClientAdaptorMgr* old_mgr = plugin->mgr_ref;
+  plugin->mgr_ref = &ccm;
+  expect_add_snap_to_gc(ccm, 0);
+  expect_remove_snap_from_gc(ccm, -ENOENT);
+#endif
   ASSERT_EQ(0, snap_create(*ictx, "snap1"));
   ASSERT_EQ(0, ictx->state->refresh_if_required());
 
@@ -711,6 +749,11 @@ TEST_F(TestMockOperationSnapshotRemoveRequest, RemoveSnapError) {
     req->send();
   }
   ASSERT_EQ(-ENOENT, cond_ctx.wait());
+#ifdef WITH_GLOBAL_CACHE
+  plugin->mgr_ref = old_mgr;
+  std::lock_guard l(reg->lock);
+  reg->remove("global_cache", "client_adaptor_plugin");
+#endif
 }
 
 TEST_F(TestMockOperationSnapshotRemoveRequest, MissingSnap) {
diff --git a/src/test/librbd/operation/test_mock_SnapshotRollbackRequest.cc b/src/test/librbd/operation/test_mock_SnapshotRollbackRequest.cc
index 1727180e..2143392c 100644
--- a/src/test/librbd/operation/test_mock_SnapshotRollbackRequest.cc
+++ b/src/test/librbd/operation/test_mock_SnapshotRollbackRequest.cc
@@ -11,6 +11,8 @@
 #include "librbd/ImageState.h"
 #include "librbd/internal.h"
 #include "librbd/operation/SnapshotRollbackRequest.h"
+#include "librbd/operation/SnapshotCreateRequest.h"
+#include "librbd/operation/SnapshotRemoveRequest.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 
@@ -52,6 +54,60 @@ struct ResizeRequest<MockOperationImageCtx> {
 
 ResizeRequest<MockOperationImageCtx> *ResizeRequest<MockOperationImageCtx>::s_instance = nullptr;
 
+template <>
+struct SnapshotCreateRequest<MockOperationImageCtx> {
+  static SnapshotCreateRequest *sc_instance;
+  Context *on_finish = nullptr;
+
+  static SnapshotCreateRequest* create(MockOperationImageCtx &image_ctx,
+                                                Context *on_finish,
+                                                const cls::rbd::SnapshotNamespace &snap_namespace,
+                                                const std::string &snap_name,
+                                                uint64_t journal_op_tid,
+                                                bool skip_object_map) {
+    sc_instance->on_finish = on_finish;
+    return sc_instance;
+  }
+
+  SnapshotCreateRequest(MockOperationImageCtx &image_ctx,
+                                                Context *on_finish,
+                                                const cls::rbd::SnapshotNamespace &snap_namespace,
+                                                const std::string &snap_name,
+                                                uint64_t journal_op_tid,
+                                                bool skip_object_map) {
+    sc_instance = this;
+  }
+
+  void skip_send_to_gc() {}
+
+  MOCK_METHOD0(send, void());
+};
+
+SnapshotCreateRequest<MockOperationImageCtx> *SnapshotCreateRequest<MockOperationImageCtx>::sc_instance = nullptr;
+
+template <>
+struct SnapshotRemoveRequest<MockOperationImageCtx> {
+  static SnapshotRemoveRequest *sr_instance;
+  Context *on_finish = nullptr;
+
+  static SnapshotRemoveRequest* create(MockOperationImageCtx &image_ctx, Context *on_finish,
+                                        const cls::rbd::SnapshotNamespace &snap_namespace,
+                                        const std::string &snap_name, uint64_t snap_id) {
+    sr_instance->on_finish = on_finish;
+    return sr_instance;
+  }
+
+  SnapshotRemoveRequest(MockOperationImageCtx &image_ctx, Context *on_finish,
+                                        const cls::rbd::SnapshotNamespace &snap_namespace,
+                                        const std::string &snap_name, uint64_t snap_id) {
+    sr_instance = this;
+  }
+
+  MOCK_METHOD0(send, void());
+};
+
+SnapshotRemoveRequest<MockOperationImageCtx> *SnapshotRemoveRequest<MockOperationImageCtx>::sr_instance = nullptr;
+
 } // namespace operation
 
 template <>
@@ -83,6 +139,8 @@ class TestMockOperationSnapshotRollbackRequest : public TestMockFixture {
 public:
   typedef SnapshotRollbackRequest<MockOperationImageCtx> MockSnapshotRollbackRequest;
   typedef ResizeRequest<MockOperationImageCtx> MockResizeRequest;
+  typedef SnapshotCreateRequest<MockOperationImageCtx> MockSnapshotCreateRequest;
+  typedef SnapshotRemoveRequest<MockOperationImageCtx> MockSnapshotRemoveRequest;
 
   void expect_block_writes(MockOperationImageCtx &mock_image_ctx, int r) {
     EXPECT_CALL(*mock_image_ctx.io_work_queue, block_writes(_))
@@ -214,10 +272,10 @@ TEST_F(TestMockOperationSnapshotRollbackRequest, Success) {
   MockOperationImageCtx mock_image_ctx(*ictx);
   MockExclusiveLock mock_exclusive_lock;
   MockJournal mock_journal;
-  MockObjectMap *mock_object_map = new MockObjectMap();
-  MockObjectMap *mock_snap_object_map = new MockObjectMap();
+  MockObjectMap mock_object_map;
+  MockObjectMap mock_snap_object_map;
   initialize_features(ictx, mock_image_ctx, mock_exclusive_lock, mock_journal,
-                      *mock_object_map);
+                      mock_object_map);
   expect_op_work_queue(mock_image_ctx);
 
   InSequence seq;
@@ -226,10 +284,10 @@ TEST_F(TestMockOperationSnapshotRollbackRequest, Success) {
   expect_block_writes(mock_image_ctx, 0);
   expect_resize(mock_image_ctx, mock_resize_request, 0);
   expect_get_flags(mock_image_ctx, 123, 0);
-  expect_get_snap_object_map(mock_image_ctx, mock_snap_object_map, 123);
-  expect_rollback_object_map(mock_image_ctx, *mock_object_map);
+  expect_get_snap_object_map(mock_image_ctx, &mock_snap_object_map, 123);
+  expect_rollback_object_map(mock_image_ctx, mock_object_map);
   expect_rollback(mock_image_ctx, 0);
-  expect_refresh_object_map(mock_image_ctx, *mock_object_map);
+  expect_refresh_object_map(mock_image_ctx, mock_object_map);
   expect_invalidate_cache(mock_image_ctx, 0);
   expect_commit_op_event(mock_image_ctx, 0);
   expect_unblock_writes(mock_image_ctx);
@@ -263,10 +321,10 @@ TEST_F(TestMockOperationSnapshotRollbackRequest, SkipResize) {
   MockOperationImageCtx mock_image_ctx(*ictx);
   MockExclusiveLock mock_exclusive_lock;
   MockJournal mock_journal;
-  MockObjectMap *mock_object_map = new MockObjectMap();
-  MockObjectMap *mock_snap_object_map = new MockObjectMap();
+  MockObjectMap mock_object_map;
+  MockObjectMap mock_snap_object_map;
   initialize_features(ictx, mock_image_ctx, mock_exclusive_lock, mock_journal,
-                      *mock_object_map);
+                      mock_object_map);
   expect_op_work_queue(mock_image_ctx);
 
   InSequence seq;
@@ -274,10 +332,10 @@ TEST_F(TestMockOperationSnapshotRollbackRequest, SkipResize) {
   expect_block_writes(mock_image_ctx, 0);
   expect_get_image_size(mock_image_ctx, 345);
   expect_get_flags(mock_image_ctx, 123, 0);
-  expect_get_snap_object_map(mock_image_ctx, mock_snap_object_map, 123);
-  expect_rollback_object_map(mock_image_ctx, *mock_object_map);
+  expect_get_snap_object_map(mock_image_ctx, &mock_snap_object_map, 123);
+  expect_rollback_object_map(mock_image_ctx, mock_object_map);
   expect_rollback(mock_image_ctx, 0);
-  expect_refresh_object_map(mock_image_ctx, *mock_object_map);
+  expect_refresh_object_map(mock_image_ctx, mock_object_map);
   expect_invalidate_cache(mock_image_ctx, 0);
   expect_commit_op_event(mock_image_ctx, 0);
   expect_unblock_writes(mock_image_ctx);
@@ -314,7 +372,7 @@ TEST_F(TestMockOperationSnapshotRollbackRequest, RollbackObjectsError) {
   MockExclusiveLock mock_exclusive_lock;
   MockJournal mock_journal;
   MockObjectMap mock_object_map;
-  MockObjectMap *mock_snap_object_map = new MockObjectMap();
+  MockObjectMap mock_snap_object_map;
   initialize_features(ictx, mock_image_ctx, mock_exclusive_lock, mock_journal,
                       mock_object_map);
   expect_op_work_queue(mock_image_ctx);
@@ -325,7 +383,7 @@ TEST_F(TestMockOperationSnapshotRollbackRequest, RollbackObjectsError) {
   expect_block_writes(mock_image_ctx, 0);
   expect_resize(mock_image_ctx, mock_resize_request, 0);
   expect_get_flags(mock_image_ctx, 123, 0);
-  expect_get_snap_object_map(mock_image_ctx, mock_snap_object_map, 123);
+  expect_get_snap_object_map(mock_image_ctx, &mock_snap_object_map, 123);
   expect_rollback_object_map(mock_image_ctx, mock_object_map);
   expect_rollback(mock_image_ctx, -EINVAL);
   expect_commit_op_event(mock_image_ctx, -EINVAL);
@@ -341,10 +399,10 @@ TEST_F(TestMockOperationSnapshotRollbackRequest, InvalidateCacheError) {
   MockOperationImageCtx mock_image_ctx(*ictx);
   MockExclusiveLock mock_exclusive_lock;
   MockJournal mock_journal;
-  MockObjectMap *mock_object_map = new MockObjectMap();
-  MockObjectMap *mock_snap_object_map = new MockObjectMap();
+  MockObjectMap mock_object_map;
+  MockObjectMap mock_snap_object_map;
   initialize_features(ictx, mock_image_ctx, mock_exclusive_lock, mock_journal,
-                      *mock_object_map);
+                      mock_object_map);
   expect_op_work_queue(mock_image_ctx);
 
   InSequence seq;
@@ -353,10 +411,10 @@ TEST_F(TestMockOperationSnapshotRollbackRequest, InvalidateCacheError) {
   expect_block_writes(mock_image_ctx, 0);
   expect_resize(mock_image_ctx, mock_resize_request, 0);
   expect_get_flags(mock_image_ctx, 123, 0);
-  expect_get_snap_object_map(mock_image_ctx, mock_snap_object_map, 123);
-  expect_rollback_object_map(mock_image_ctx, *mock_object_map);
+  expect_get_snap_object_map(mock_image_ctx, &mock_snap_object_map, 123);
+  expect_rollback_object_map(mock_image_ctx, mock_object_map);
   expect_rollback(mock_image_ctx, 0);
-  expect_refresh_object_map(mock_image_ctx, *mock_object_map);
+  expect_refresh_object_map(mock_image_ctx, mock_object_map);
   expect_invalidate_cache(mock_image_ctx, -EINVAL);
   expect_commit_op_event(mock_image_ctx, -EINVAL);
   expect_unblock_writes(mock_image_ctx);
diff --git a/src/test/librbd/test_ObjectMap.cc b/src/test/librbd/test_ObjectMap.cc
index d939ffb9..27d78c57 100644
--- a/src/test/librbd/test_ObjectMap.cc
+++ b/src/test/librbd/test_ObjectMap.cc
@@ -25,9 +25,12 @@ public:
 
   int when_open_object_map(librbd::ImageCtx *ictx) {
     C_SaferCond ctx;
-    librbd::ObjectMap<> object_map(*ictx, ictx->snap_id);
-    object_map.open(&ctx);
-    return ctx.wait();
+    librbd::ObjectMap<> *object_map = new librbd::ObjectMap<>(*ictx, ictx->snap_id);
+    object_map->open(&ctx);
+    int r = ctx.wait();
+    object_map->put();
+
+    return r;
   }
 };
 
diff --git a/src/test/librbd/test_internal.cc b/src/test/librbd/test_internal.cc
index 0caf9fff..3bdc9674 100644
--- a/src/test/librbd/test_internal.cc
+++ b/src/test/librbd/test_internal.cc
@@ -655,13 +655,15 @@ TEST_F(TestInternal, SnapshotCopyup)
         state = OBJECT_EXISTS_CLEAN;
       }
 
-      librbd::ObjectMap<> object_map(*ictx2, ictx2->snap_id);
+      librbd::ObjectMap<> *object_map = new librbd::ObjectMap<>(*ictx2, ictx2->snap_id);
       C_SaferCond ctx;
-      object_map.open(&ctx);
+      object_map->open(&ctx);
       ASSERT_EQ(0, ctx.wait());
 
       RWLock::WLocker object_map_locker(ictx2->object_map_lock);
-      ASSERT_EQ(state, object_map[0]);
+
+      ASSERT_EQ(state, (*object_map)[0]);
+      object_map->put();
     }
   }
 }
@@ -743,13 +745,14 @@ TEST_F(TestInternal, SnapshotCopyupZeros)
         state = OBJECT_NONEXISTENT;
       }
 
-      librbd::ObjectMap<> object_map(*ictx2, ictx2->snap_id);
+      librbd::ObjectMap<> *object_map = new librbd::ObjectMap<>(*ictx2, ictx2->snap_id);
       C_SaferCond ctx;
-      object_map.open(&ctx);
+      object_map->open(&ctx);
       ASSERT_EQ(0, ctx.wait());
 
       RWLock::WLocker object_map_locker(ictx2->object_map_lock);
-      ASSERT_EQ(state, object_map[0]);
+      ASSERT_EQ(state, (*object_map)[0]);
+      object_map->put();
     }
   }
 }
@@ -830,13 +833,14 @@ TEST_F(TestInternal, SnapshotCopyupZerosMigration)
         state = OBJECT_NONEXISTENT;
       }
 
-      librbd::ObjectMap<> object_map(*ictx2, ictx2->snap_id);
+      librbd::ObjectMap<> *object_map = new librbd::ObjectMap<>(*ictx2, ictx2->snap_id);
       C_SaferCond ctx;
-      object_map.open(&ctx);
+      object_map->open(&ctx);
       ASSERT_EQ(0, ctx.wait());
 
       RWLock::WLocker object_map_locker(ictx2->object_map_lock);
-      ASSERT_EQ(state, object_map[0]);
+      ASSERT_EQ(state, (*object_map)[0]);
+      object_map->put();
     }
   }
 }
diff --git a/src/test/librbd/test_mock_DeepCopyRequest.cc b/src/test/librbd/test_mock_DeepCopyRequest.cc
index 00c457bf..902f6be1 100644
--- a/src/test/librbd/test_mock_DeepCopyRequest.cc
+++ b/src/test/librbd/test_mock_DeepCopyRequest.cc
@@ -17,6 +17,7 @@
 
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
+#include <boost/scope_exit.hpp>
 
 namespace librbd {
 
@@ -243,18 +244,20 @@ TEST_F(TestMockDeepCopyRequest, SimpleCopy) {
   librbd::MockExclusiveLock mock_exclusive_lock;
   mock_dst_image_ctx.exclusive_lock = &mock_exclusive_lock;
 
-  librbd::MockObjectMap *mock_object_map =
-    is_feature_enabled(RBD_FEATURE_OBJECT_MAP) ?
-    new librbd::MockObjectMap() : nullptr;
-  mock_dst_image_ctx.object_map = mock_object_map;
+  librbd::MockObjectMap mock_object_map;
+
+  mock_dst_image_ctx.object_map = nullptr;
+  if (is_feature_enabled(RBD_FEATURE_OBJECT_MAP)) {
+    mock_dst_image_ctx.object_map = &mock_object_map;
+  }
 
   expect_test_features(mock_dst_image_ctx);
 
   InSequence seq;
   expect_copy_snapshots(mock_snapshot_copy_request, 0);
   expect_copy_image(mock_image_copy_request, 0);
-  if (mock_object_map != nullptr) {
-    expect_refresh_object_map(mock_dst_image_ctx, mock_object_map, 0);
+  if (mock_dst_image_ctx.object_map != nullptr) {
+    expect_refresh_object_map(mock_dst_image_ctx, &mock_object_map, 0);
   }
   expect_copy_metadata(mock_metadata_copy_request, 0);
 
@@ -349,18 +352,20 @@ TEST_F(TestMockDeepCopyRequest, ErrorOnCopyMetadata) {
   librbd::MockExclusiveLock mock_exclusive_lock;
   mock_dst_image_ctx.exclusive_lock = &mock_exclusive_lock;
 
-  librbd::MockObjectMap *mock_object_map =
-    is_feature_enabled(RBD_FEATURE_OBJECT_MAP) ?
-    new librbd::MockObjectMap() : nullptr;
-  mock_dst_image_ctx.object_map = mock_object_map;
+  librbd::MockObjectMap mock_object_map;
+
+  mock_dst_image_ctx.object_map = nullptr;
+  if (is_feature_enabled(RBD_FEATURE_OBJECT_MAP)) {
+    mock_dst_image_ctx.object_map = &mock_object_map;
+  }
 
   expect_test_features(mock_dst_image_ctx);
 
   InSequence seq;
   expect_copy_snapshots(mock_snapshot_copy_request, 0);
   expect_copy_image(mock_image_copy_request, 0);
-  if (mock_object_map != nullptr) {
-    expect_refresh_object_map(mock_dst_image_ctx, mock_object_map, 0);
+  if (mock_dst_image_ctx.object_map != nullptr) {
+    expect_refresh_object_map(mock_dst_image_ctx, &mock_object_map, 0);
   }
   expect_copy_metadata(mock_metadata_copy_request, -EINVAL);
 
@@ -389,19 +394,19 @@ TEST_F(TestMockDeepCopyRequest, Snap) {
   librbd::MockExclusiveLock mock_exclusive_lock;
   mock_dst_image_ctx.exclusive_lock = &mock_exclusive_lock;
 
-  librbd::MockObjectMap *mock_object_map =
-    is_feature_enabled(RBD_FEATURE_OBJECT_MAP) ?
-    new librbd::MockObjectMap() : nullptr;
-  mock_dst_image_ctx.object_map = mock_object_map;
+  librbd::MockObjectMap mock_object_map;
+  if (is_feature_enabled(RBD_FEATURE_OBJECT_MAP)) {
+    mock_dst_image_ctx.object_map = &mock_object_map;
+  }
 
   expect_test_features(mock_dst_image_ctx);
 
   InSequence seq;
   expect_copy_snapshots(mock_snapshot_copy_request, 0);
   expect_copy_image(mock_image_copy_request, 0);
-  if (mock_object_map != nullptr) {
-    expect_copy_object_map(mock_exclusive_lock, mock_object_map, 0);
-    expect_refresh_object_map(mock_dst_image_ctx, mock_object_map, 0);
+  if (mock_dst_image_ctx.object_map != nullptr) {
+    expect_copy_object_map(mock_exclusive_lock, &mock_object_map, 0);
+    expect_refresh_object_map(mock_dst_image_ctx, &mock_object_map, 0);
   }
   expect_copy_metadata(mock_metadata_copy_request, 0);
 
diff --git a/src/test/librbd/test_mock_ExclusiveLock.cc b/src/test/librbd/test_mock_ExclusiveLock.cc
index dbdb12e7..3dfcef79 100644
--- a/src/test/librbd/test_mock_ExclusiveLock.cc
+++ b/src/test/librbd/test_mock_ExclusiveLock.cc
@@ -13,6 +13,7 @@
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include <list>
+#include <boost/scope_exit.hpp>
 
 namespace librbd {
 
@@ -165,57 +166,57 @@ public:
   typedef exclusive_lock::PostAcquireRequest<MockExclusiveLockImageCtx> MockPostAcquireRequest;
   typedef exclusive_lock::PreReleaseRequest<MockExclusiveLockImageCtx> MockPreReleaseRequest;
 
-  void expect_set_state_initializing(MockManagedLock &managed_lock) {
-    EXPECT_CALL(managed_lock, set_state_initializing());
+  void expect_set_state_initializing(MockManagedLock *managed_lock) {
+    EXPECT_CALL(*managed_lock, set_state_initializing());
   }
 
-  void expect_set_state_unlocked(MockManagedLock &managed_lock) {
-    EXPECT_CALL(managed_lock, set_state_unlocked());
+  void expect_set_state_unlocked(MockManagedLock *managed_lock) {
+    EXPECT_CALL(*managed_lock, set_state_unlocked());
   }
 
-  void expect_set_state_waiting_for_lock(MockManagedLock &managed_lock) {
-    EXPECT_CALL(managed_lock, set_state_waiting_for_lock());
+  void expect_set_state_waiting_for_lock(MockManagedLock *managed_lock) {
+    EXPECT_CALL(*managed_lock, set_state_waiting_for_lock());
   }
 
-  void expect_set_state_post_acquiring(MockManagedLock &managed_lock) {
-    EXPECT_CALL(managed_lock, set_state_post_acquiring());
+  void expect_set_state_post_acquiring(MockManagedLock *managed_lock) {
+    EXPECT_CALL(*managed_lock, set_state_post_acquiring());
   }
 
-  void expect_is_state_acquiring(MockManagedLock &managed_lock, bool ret_val) {
-    EXPECT_CALL(managed_lock, is_state_acquiring())
+  void expect_is_state_acquiring(MockManagedLock *managed_lock, bool ret_val) {
+    EXPECT_CALL(*managed_lock, is_state_acquiring())
       .WillOnce(Return(ret_val));
   }
 
-  void expect_is_state_waiting_for_lock(MockManagedLock &managed_lock,
+  void expect_is_state_waiting_for_lock(MockManagedLock *managed_lock,
                                         bool ret_val) {
-    EXPECT_CALL(managed_lock, is_state_waiting_for_lock())
+    EXPECT_CALL(*managed_lock, is_state_waiting_for_lock())
       .WillOnce(Return(ret_val));
   }
 
-  void expect_is_state_pre_releasing(MockManagedLock &managed_lock,
+  void expect_is_state_pre_releasing(MockManagedLock *managed_lock,
                                      bool ret_val) {
-    EXPECT_CALL(managed_lock, is_state_pre_releasing())
+    EXPECT_CALL(*managed_lock, is_state_pre_releasing())
       .WillOnce(Return(ret_val));
   }
 
-  void expect_is_state_releasing(MockManagedLock &managed_lock, bool ret_val) {
-    EXPECT_CALL(managed_lock, is_state_releasing())
+  void expect_is_state_releasing(MockManagedLock *managed_lock, bool ret_val) {
+    EXPECT_CALL(*managed_lock, is_state_releasing())
       .WillOnce(Return(ret_val));
   }
 
-  void expect_is_state_locked(MockManagedLock &managed_lock, bool ret_val) {
-    EXPECT_CALL(managed_lock, is_state_locked())
+  void expect_is_state_locked(MockManagedLock *managed_lock, bool ret_val) {
+    EXPECT_CALL(*managed_lock, is_state_locked())
       .WillOnce(Return(ret_val));
   }
 
-  void expect_is_state_shutdown(MockManagedLock &managed_lock, bool ret_val) {
-    EXPECT_CALL(managed_lock, is_state_shutdown())
+  void expect_is_state_shutdown(MockManagedLock *managed_lock, bool ret_val) {
+    EXPECT_CALL(*managed_lock, is_state_shutdown())
       .WillOnce(Return(ret_val));
   }
 
-  void expect_is_action_acquire_lock(MockManagedLock &managed_lock,
+  void expect_is_action_acquire_lock(MockManagedLock *managed_lock,
                                      bool ret_val) {
-    EXPECT_CALL(managed_lock, is_action_acquire_lock())
+    EXPECT_CALL(*managed_lock, is_action_acquire_lock())
       .WillOnce(Return(ret_val));
   }
 
@@ -251,7 +252,7 @@ public:
       .WillOnce(CompleteRequest(&pre_acquire_request, r));
   }
 
-  void expect_post_acquire_request(MockExclusiveLock &mock_exclusive_lock,
+  void expect_post_acquire_request(MockExclusiveLock *mock_exclusive_lock,
                                    MockPostAcquireRequest &post_acquire_request,
                                    int r) {
     EXPECT_CALL(post_acquire_request, send())
@@ -267,7 +268,7 @@ public:
   }
 
   void expect_notify_request_lock(MockExclusiveLockImageCtx &mock_image_ctx,
-                                  MockExclusiveLock &mock_exclusive_lock) {
+                                  MockExclusiveLock *mock_exclusive_lock) {
     EXPECT_CALL(*mock_image_ctx.image_watcher, notify_request_lock());
   }
 
@@ -286,8 +287,8 @@ public:
                   .WillOnce(CompleteContext(0, mock_image_ctx.image_ctx->op_work_queue));
   }
 
-  void expect_shut_down(MockManagedLock &managed_lock) {
-    EXPECT_CALL(managed_lock, shut_down(_))
+  void expect_shut_down(MockManagedLock *managed_lock) {
+    EXPECT_CALL(*managed_lock, shut_down(_))
       .WillOnce(CompleteContext(0, static_cast<ContextWQ*>(nullptr)));
   }
 
@@ -302,61 +303,61 @@ public:
   }
 
   int when_init(MockExclusiveLockImageCtx &mock_image_ctx,
-                MockExclusiveLock &exclusive_lock) {
+                MockExclusiveLock *exclusive_lock) {
     C_SaferCond ctx;
     {
       RWLock::WLocker owner_locker(mock_image_ctx.owner_lock);
-      exclusive_lock.init(mock_image_ctx.features, &ctx);
+      exclusive_lock->init(mock_image_ctx.features, &ctx);
     }
     return ctx.wait();
   }
 
-  int when_pre_acquire_lock_handler(MockManagedLock &managed_lock) {
+  int when_pre_acquire_lock_handler(MockManagedLock *managed_lock) {
     C_SaferCond ctx;
-    managed_lock.pre_acquire_lock_handler(&ctx);
+    managed_lock->pre_acquire_lock_handler(&ctx);
     return ctx.wait();
   }
 
-  int when_post_acquire_lock_handler(MockManagedLock &managed_lock, int r) {
+  int when_post_acquire_lock_handler(MockManagedLock *managed_lock, int r) {
     C_SaferCond ctx;
-    managed_lock.post_acquire_lock_handler(r, &ctx);
+    managed_lock->post_acquire_lock_handler(r, &ctx);
     return ctx.wait();
   }
 
-  int when_pre_release_lock_handler(MockManagedLock &managed_lock,
+  int when_pre_release_lock_handler(MockManagedLock *managed_lock,
                                     bool shutting_down) {
     C_SaferCond ctx;
-    managed_lock.pre_release_lock_handler(shutting_down, &ctx);
+    managed_lock->pre_release_lock_handler(shutting_down, &ctx);
     return ctx.wait();
   }
 
-  int when_post_release_lock_handler(MockManagedLock &managed_lock,
+  int when_post_release_lock_handler(MockManagedLock *managed_lock,
                                      bool shutting_down, int r) {
     C_SaferCond ctx;
-    managed_lock.post_release_lock_handler(shutting_down, r, &ctx);
+    managed_lock->post_release_lock_handler(shutting_down, r, &ctx);
     return ctx.wait();
   }
 
-  int when_post_reacquire_lock_handler(MockManagedLock &managed_lock, int r) {
+  int when_post_reacquire_lock_handler(MockManagedLock *managed_lock, int r) {
     C_SaferCond ctx;
-    managed_lock.post_reacquire_lock_handler(r, &ctx);
+    managed_lock->post_reacquire_lock_handler(r, &ctx);
     return ctx.wait();
   }
 
   int when_shut_down(MockExclusiveLockImageCtx &mock_image_ctx,
-                     MockExclusiveLock &exclusive_lock) {
+                     MockExclusiveLock *exclusive_lock) {
     C_SaferCond ctx;
     {
       RWLock::WLocker owner_locker(mock_image_ctx.owner_lock);
-      exclusive_lock.shut_down(&ctx);
+      exclusive_lock->shut_down(&ctx);
     }
     return ctx.wait();
   }
 
   bool is_lock_owner(MockExclusiveLockImageCtx &mock_image_ctx,
-                     MockExclusiveLock &exclusive_lock) {
+                     MockExclusiveLock *exclusive_lock) {
     RWLock::RLocker owner_locker(mock_image_ctx.owner_lock);
-    return exclusive_lock.is_lock_owner();
+    return exclusive_lock->is_lock_owner();
   }
 };
 
@@ -367,9 +368,13 @@ TEST_F(TestMockExclusiveLock, StateTransitions) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockExclusiveLockImageCtx mock_image_ctx(*ictx);
-  MockExclusiveLock exclusive_lock(mock_image_ctx);
+  MockExclusiveLock *exclusive_lock = new MockExclusiveLock(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&exclusive_lock) {
+    exclusive_lock->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
   expect_set_state_initializing(exclusive_lock);
   expect_block_writes(mock_image_ctx);
@@ -431,10 +436,13 @@ TEST_F(TestMockExclusiveLock, TryLockAlreadyLocked) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockExclusiveLockImageCtx mock_image_ctx(*ictx);
-  MockExclusiveLock exclusive_lock(mock_image_ctx);
+  MockExclusiveLock *exclusive_lock = new MockExclusiveLock(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
-  InSequence seq;
+  BOOST_SCOPE_EXIT(&exclusive_lock) {
+    exclusive_lock->put();
+  } BOOST_SCOPE_EXIT_END
+
   expect_set_state_initializing(exclusive_lock);
   expect_block_writes(mock_image_ctx);
   expect_set_state_unlocked(exclusive_lock);
@@ -458,9 +466,13 @@ TEST_F(TestMockExclusiveLock, TryLockError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockExclusiveLockImageCtx mock_image_ctx(*ictx);
-  MockExclusiveLock exclusive_lock(mock_image_ctx);
+  MockExclusiveLock *exclusive_lock = new MockExclusiveLock(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&exclusive_lock) {
+    exclusive_lock->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
   expect_set_state_initializing(exclusive_lock);
   expect_block_writes(mock_image_ctx);
@@ -485,9 +497,13 @@ TEST_F(TestMockExclusiveLock, AcquireLockAlreadyLocked) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockExclusiveLockImageCtx mock_image_ctx(*ictx);
-  MockExclusiveLock exclusive_lock(mock_image_ctx);
+  MockExclusiveLock *exclusive_lock = new MockExclusiveLock(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&exclusive_lock) {
+    exclusive_lock->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
   expect_set_state_initializing(exclusive_lock);
   expect_block_writes(mock_image_ctx);
@@ -515,9 +531,13 @@ TEST_F(TestMockExclusiveLock, AcquireLockBusy) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockExclusiveLockImageCtx mock_image_ctx(*ictx);
-  MockExclusiveLock exclusive_lock(mock_image_ctx);
+  MockExclusiveLock *exclusive_lock = new MockExclusiveLock(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&exclusive_lock) {
+    exclusive_lock->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
   expect_set_state_initializing(exclusive_lock);
   expect_block_writes(mock_image_ctx);
@@ -545,9 +565,13 @@ TEST_F(TestMockExclusiveLock, AcquireLockError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockExclusiveLockImageCtx mock_image_ctx(*ictx);
-  MockExclusiveLock exclusive_lock(mock_image_ctx);
+  MockExclusiveLock *exclusive_lock = new MockExclusiveLock(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&exclusive_lock) {
+    exclusive_lock->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
   expect_set_state_initializing(exclusive_lock);
   expect_block_writes(mock_image_ctx);
@@ -573,9 +597,13 @@ TEST_F(TestMockExclusiveLock, PostAcquireLockError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockExclusiveLockImageCtx mock_image_ctx(*ictx);
-  MockExclusiveLock exclusive_lock(mock_image_ctx);
+  MockExclusiveLock *exclusive_lock = new MockExclusiveLock(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&exclusive_lock) {
+    exclusive_lock->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
   expect_set_state_initializing(exclusive_lock);
   expect_block_writes(mock_image_ctx);
@@ -601,9 +629,13 @@ TEST_F(TestMockExclusiveLock, PreReleaseLockError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockExclusiveLockImageCtx mock_image_ctx(*ictx);
-  MockExclusiveLock exclusive_lock(mock_image_ctx);
+  MockExclusiveLock *exclusive_lock = new MockExclusiveLock(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&exclusive_lock) {
+    exclusive_lock->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
   expect_set_state_initializing(exclusive_lock);
   expect_block_writes(mock_image_ctx);
@@ -627,9 +659,13 @@ TEST_F(TestMockExclusiveLock, ReacquireLock) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockExclusiveLockImageCtx mock_image_ctx(*ictx);
-  MockExclusiveLock exclusive_lock(mock_image_ctx);
+  MockExclusiveLock *exclusive_lock = new MockExclusiveLock(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&exclusive_lock) {
+    exclusive_lock->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
   expect_set_state_initializing(exclusive_lock);
   expect_block_writes(mock_image_ctx);
@@ -673,11 +709,14 @@ TEST_F(TestMockExclusiveLock, BlockRequests) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockExclusiveLockImageCtx mock_image_ctx(*ictx);
-  MockExclusiveLock exclusive_lock(mock_image_ctx);
+  MockExclusiveLock *exclusive_lock = new MockExclusiveLock(mock_image_ctx);
   exclusive_lock::MockPolicy mock_exclusive_lock_policy;
 
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&exclusive_lock) {
+    exclusive_lock->put();
+  } BOOST_SCOPE_EXIT_END
   InSequence seq;
   expect_set_state_initializing(exclusive_lock);
   expect_block_writes(mock_image_ctx);
@@ -687,17 +726,17 @@ TEST_F(TestMockExclusiveLock, BlockRequests) {
   int ret_val;
   expect_is_state_shutdown(exclusive_lock, false);
   expect_is_state_locked(exclusive_lock, true);
-  ASSERT_TRUE(exclusive_lock.accept_request(
+  ASSERT_TRUE(exclusive_lock->accept_request(
                 exclusive_lock::OPERATION_REQUEST_TYPE_GENERAL, &ret_val));
   ASSERT_EQ(0, ret_val);
 
-  exclusive_lock.block_requests(-EROFS);
+  exclusive_lock->block_requests(-EROFS);
   expect_is_state_shutdown(exclusive_lock, false);
   expect_is_state_locked(exclusive_lock, true);
   expect_accept_blocked_request(mock_image_ctx, mock_exclusive_lock_policy,
                                 exclusive_lock::OPERATION_REQUEST_TYPE_GENERAL,
                                 false);
-  ASSERT_FALSE(exclusive_lock.accept_request(
+  ASSERT_FALSE(exclusive_lock->accept_request(
                  exclusive_lock::OPERATION_REQUEST_TYPE_GENERAL, &ret_val));
   ASSERT_EQ(-EROFS, ret_val);
 
@@ -706,15 +745,15 @@ TEST_F(TestMockExclusiveLock, BlockRequests) {
   expect_accept_blocked_request(
     mock_image_ctx, mock_exclusive_lock_policy,
     exclusive_lock::OPERATION_REQUEST_TYPE_TRASH_SNAP_REMOVE, true);
-  ASSERT_TRUE(exclusive_lock.accept_request(
+  ASSERT_TRUE(exclusive_lock->accept_request(
                 exclusive_lock::OPERATION_REQUEST_TYPE_TRASH_SNAP_REMOVE,
                 &ret_val));
   ASSERT_EQ(0, ret_val);
 
-  exclusive_lock.unblock_requests();
+  exclusive_lock->unblock_requests();
   expect_is_state_shutdown(exclusive_lock, false);
   expect_is_state_locked(exclusive_lock, true);
-  ASSERT_TRUE(exclusive_lock.accept_request(
+  ASSERT_TRUE(exclusive_lock->accept_request(
                 exclusive_lock::OPERATION_REQUEST_TYPE_GENERAL, &ret_val));
   ASSERT_EQ(0, ret_val);
 }
diff --git a/src/test/librbd/test_mock_Journal.cc b/src/test/librbd/test_mock_Journal.cc
index 40aed36f..98ca7ac6 100644
--- a/src/test/librbd/test_mock_Journal.cc
+++ b/src/test/librbd/test_mock_Journal.cc
@@ -443,32 +443,32 @@ public:
                   .WillOnce(CompleteContext(0, static_cast<ContextWQ*>(NULL)));
   }
 
-  int when_open(MockJournal &mock_journal) {
+  int when_open(MockJournal *mock_journal) {
     C_SaferCond ctx;
-    mock_journal.open(&ctx);
+    mock_journal->open(&ctx);
     return ctx.wait();
   }
 
-  int when_close(MockJournal &mock_journal) {
+  int when_close(MockJournal *mock_journal) {
     C_SaferCond ctx;
-    mock_journal.close(&ctx);
+    mock_journal->close(&ctx);
     return ctx.wait();
   }
 
   uint64_t when_append_write_event(MockJournalImageCtx &mock_image_ctx,
-                                   MockJournal &mock_journal, uint64_t length) {
+                                   MockJournal *mock_journal, uint64_t length) {
     bufferlist bl;
     bl.append_zero(length);
 
     RWLock::RLocker owner_locker(mock_image_ctx.owner_lock);
-    return mock_journal.append_write_event(0, length, bl, false);
+    return mock_journal->append_write_event(0, length, bl, false);
   }
 
   uint64_t when_append_io_event(MockJournalImageCtx &mock_image_ctx,
-                                MockJournal &mock_journal,
+                                MockJournal *mock_journal,
                                 int filter_ret_val) {
     RWLock::RLocker owner_locker(mock_image_ctx.owner_lock);
-    return mock_journal.append_io_event(
+    return mock_journal->append_io_event(
       journal::EventEntry{journal::AioFlushEvent{}}, 0, 0, false,
                           filter_ret_val);
   }
@@ -504,7 +504,7 @@ public:
   }
 
   void open_journal(MockJournalImageCtx &mock_image_ctx,
-                    MockJournal &mock_journal,
+                    MockJournal *mock_journal,
                     MockObjectDispatch& mock_object_dispatch,
                     ::journal::MockJournaler &mock_journaler,
                     MockJournalOpenRequest &mock_open_request,
@@ -532,7 +532,7 @@ public:
   }
 
   void close_journal(MockJournalImageCtx& mock_image_ctx,
-                     MockJournal &mock_journal,
+                     MockJournal *mock_journal,
                      ::journal::MockJournaler &mock_journaler) {
     expect_stop_append(mock_journaler, 0);
     expect_shut_down_object_dispatch(mock_image_ctx);
@@ -558,9 +558,13 @@ TEST_F(TestMockJournal, StateTransitions) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&mock_journal) {
+    mock_journal->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
 
   MockObjectDispatch mock_object_dispatch;
@@ -612,9 +616,13 @@ TEST_F(TestMockJournal, InitError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&mock_journal) {
+    mock_journal->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
 
   MockObjectDispatch mock_object_dispatch;
@@ -636,9 +644,13 @@ TEST_F(TestMockJournal, ReplayCompleteError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&mock_journal) {
+    mock_journal->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
 
   MockObjectDispatch mock_object_dispatch;
@@ -689,9 +701,13 @@ TEST_F(TestMockJournal, FlushReplayError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&mock_journal) {
+    mock_journal->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
 
   MockObjectDispatch mock_object_dispatch;
@@ -747,9 +763,13 @@ TEST_F(TestMockJournal, CorruptEntry) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&mock_journal) {
+    mock_journal->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
 
   MockObjectDispatch mock_object_dispatch;
@@ -802,9 +822,13 @@ TEST_F(TestMockJournal, StopError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&mock_journal) {
+    mock_journal->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
 
   MockObjectDispatch mock_object_dispatch;
@@ -841,9 +865,13 @@ TEST_F(TestMockJournal, ReplayOnDiskPreFlushError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&mock_journal) {
+    mock_journal->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
   MockObjectDispatch mock_object_dispatch;
   expect_register_object_dispatch(mock_image_ctx, mock_object_dispatch);
@@ -894,7 +922,7 @@ TEST_F(TestMockJournal, ReplayOnDiskPreFlushError) {
   expect_set_append_batch_options(mock_image_ctx, mock_journaler, false);
 
   C_SaferCond ctx;
-  mock_journal.open(&ctx);
+  mock_journal->open(&ctx);
 
   // wait for the process callback
   {
@@ -928,9 +956,13 @@ TEST_F(TestMockJournal, ReplayOnDiskPostFlushError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   expect_op_work_queue(mock_image_ctx);
 
+  BOOST_SCOPE_EXIT(&mock_journal) {
+    mock_journal->put();
+  } BOOST_SCOPE_EXIT_END
+
   InSequence seq;
 
   MockObjectDispatch mock_object_dispatch;
@@ -977,7 +1009,7 @@ TEST_F(TestMockJournal, ReplayOnDiskPostFlushError) {
   expect_set_append_batch_options(mock_image_ctx, mock_journaler, false);
 
   C_SaferCond ctx;
-  mock_journal.open(&ctx);
+  mock_journal->open(&ctx);
 
   // proceed with the flush
   {
@@ -1014,7 +1046,7 @@ TEST_F(TestMockJournal, EventAndIOCommitOrder) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1022,6 +1054,7 @@ TEST_F(TestMockJournal, EventAndIOCommitOrder) {
                mock_journaler, mock_open_request);
   BOOST_SCOPE_EXIT_ALL(&) {
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   ::journal::MockFuture mock_future;
@@ -1029,26 +1062,26 @@ TEST_F(TestMockJournal, EventAndIOCommitOrder) {
   expect_append_journaler(mock_journaler);
   expect_wait_future(mock_future, &on_journal_safe1);
   ASSERT_EQ(1U, when_append_io_event(mock_image_ctx, mock_journal, 0));
-  mock_journal.get_work_queue()->drain();
+  mock_journal->get_work_queue()->drain();
 
   Context *on_journal_safe2;
   expect_append_journaler(mock_journaler);
   expect_wait_future(mock_future, &on_journal_safe2);
   ASSERT_EQ(2U, when_append_io_event(mock_image_ctx, mock_journal, 0));
-  mock_journal.get_work_queue()->drain();
+  mock_journal->get_work_queue()->drain();
 
   // commit journal event followed by IO event (standard)
   on_journal_safe1->complete(0);
   ictx->op_work_queue->drain();
   expect_future_committed(mock_journaler);
-  mock_journal.commit_io_event(1U, 0);
+  mock_journal->commit_io_event(1U, 0);
 
   // commit IO event followed by journal event (cache overwrite)
-  mock_journal.commit_io_event(2U, 0);
+  mock_journal->commit_io_event(2U, 0);
   expect_future_committed(mock_journaler);
 
   C_SaferCond event_ctx;
-  mock_journal.wait_event(2U, &event_ctx);
+  mock_journal->wait_event(2U, &event_ctx);
   on_journal_safe2->complete(0);
   ictx->op_work_queue->drain();
   ASSERT_EQ(0, event_ctx.wait());
@@ -1063,7 +1096,7 @@ TEST_F(TestMockJournal, AppendWriteEvent) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1071,6 +1104,7 @@ TEST_F(TestMockJournal, AppendWriteEvent) {
                mock_journaler, mock_open_request);
   BOOST_SCOPE_EXIT_ALL(&) {
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   InSequence seq;
@@ -1082,17 +1116,17 @@ TEST_F(TestMockJournal, AppendWriteEvent) {
   expect_append_journaler(mock_journaler);
   expect_wait_future(mock_future, &on_journal_safe);
   ASSERT_EQ(1U, when_append_write_event(mock_image_ctx, mock_journal, 1 << 17));
-  mock_journal.get_work_queue()->drain();
+  mock_journal->get_work_queue()->drain();
 
   on_journal_safe->complete(0);
   C_SaferCond event_ctx;
-  mock_journal.wait_event(1U, &event_ctx);
+  mock_journal->wait_event(1U, &event_ctx);
   ASSERT_EQ(0, event_ctx.wait());
 
   expect_future_committed(mock_journaler);
   expect_future_committed(mock_journaler);
   expect_future_committed(mock_journaler);
-  mock_journal.commit_io_event(1U, 0);
+  mock_journal->commit_io_event(1U, 0);
   ictx->op_work_queue->drain();
 
   expect_shut_down_journaler(mock_journaler);
@@ -1105,7 +1139,7 @@ TEST_F(TestMockJournal, EventCommitError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1113,6 +1147,7 @@ TEST_F(TestMockJournal, EventCommitError) {
                mock_journaler, mock_open_request);
   BOOST_SCOPE_EXIT_ALL(&) {
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   ::journal::MockFuture mock_future;
@@ -1120,19 +1155,19 @@ TEST_F(TestMockJournal, EventCommitError) {
   expect_append_journaler(mock_journaler);
   expect_wait_future(mock_future, &on_journal_safe);
   ASSERT_EQ(1U, when_append_io_event(mock_image_ctx, mock_journal, 0));
-  mock_journal.get_work_queue()->drain();
+  mock_journal->get_work_queue()->drain();
 
   // commit the event in the journal w/o waiting writeback
   expect_future_committed(mock_journaler);
   C_SaferCond object_request_ctx;
-  mock_journal.wait_event(1U, &object_request_ctx);
+  mock_journal->wait_event(1U, &object_request_ctx);
   on_journal_safe->complete(-EINVAL);
   ASSERT_EQ(-EINVAL, object_request_ctx.wait());
 
   // cache should receive the error after attempting writeback
   expect_future_is_valid(mock_future);
   C_SaferCond flush_ctx;
-  mock_journal.flush_event(1U, &flush_ctx);
+  mock_journal->flush_event(1U, &flush_ctx);
   ASSERT_EQ(-EINVAL, flush_ctx.wait());
 
   expect_shut_down_journaler(mock_journaler);
@@ -1145,7 +1180,7 @@ TEST_F(TestMockJournal, EventCommitErrorWithPendingWriteback) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1153,6 +1188,7 @@ TEST_F(TestMockJournal, EventCommitErrorWithPendingWriteback) {
                mock_journaler, mock_open_request);
   BOOST_SCOPE_EXIT_ALL(&) {
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   ::journal::MockFuture mock_future;
@@ -1160,16 +1196,16 @@ TEST_F(TestMockJournal, EventCommitErrorWithPendingWriteback) {
   expect_append_journaler(mock_journaler);
   expect_wait_future(mock_future, &on_journal_safe);
   ASSERT_EQ(1U, when_append_io_event(mock_image_ctx, mock_journal, 0));
-  mock_journal.get_work_queue()->drain();
+  mock_journal->get_work_queue()->drain();
 
   expect_future_is_valid(mock_future);
   C_SaferCond flush_ctx;
-  mock_journal.flush_event(1U, &flush_ctx);
+  mock_journal->flush_event(1U, &flush_ctx);
 
   // commit the event in the journal w/ waiting cache writeback
   expect_future_committed(mock_journaler);
   C_SaferCond object_request_ctx;
-  mock_journal.wait_event(1U, &object_request_ctx);
+  mock_journal->wait_event(1U, &object_request_ctx);
   on_journal_safe->complete(-EINVAL);
   ASSERT_EQ(-EINVAL, object_request_ctx.wait());
 
@@ -1186,7 +1222,7 @@ TEST_F(TestMockJournal, IOCommitError) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1194,6 +1230,7 @@ TEST_F(TestMockJournal, IOCommitError) {
                mock_journaler, mock_open_request);
   BOOST_SCOPE_EXIT_ALL(&) {
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   ::journal::MockFuture mock_future;
@@ -1201,12 +1238,12 @@ TEST_F(TestMockJournal, IOCommitError) {
   expect_append_journaler(mock_journaler);
   expect_wait_future(mock_future, &on_journal_safe);
   ASSERT_EQ(1U, when_append_io_event(mock_image_ctx, mock_journal, 0));
-  mock_journal.get_work_queue()->drain();
+  mock_journal->get_work_queue()->drain();
 
   // failed IO remains uncommitted in journal
   on_journal_safe->complete(0);
   ictx->op_work_queue->drain();
-  mock_journal.commit_io_event(1U, -EINVAL);
+  mock_journal->commit_io_event(1U, -EINVAL);
 
   expect_shut_down_journaler(mock_journaler);
 }
@@ -1218,7 +1255,7 @@ TEST_F(TestMockJournal, IOCommitErrorFiltered) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1226,6 +1263,7 @@ TEST_F(TestMockJournal, IOCommitErrorFiltered) {
                mock_journaler, mock_open_request);
   BOOST_SCOPE_EXIT_ALL(&) {
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   ::journal::MockFuture mock_future;
@@ -1233,13 +1271,13 @@ TEST_F(TestMockJournal, IOCommitErrorFiltered) {
   expect_append_journaler(mock_journaler);
   expect_wait_future(mock_future, &on_journal_safe);
   ASSERT_EQ(1U, when_append_io_event(mock_image_ctx, mock_journal, -EILSEQ));
-  mock_journal.get_work_queue()->drain();
+  mock_journal->get_work_queue()->drain();
 
   // filter failed IO committed in journal
   on_journal_safe->complete(0);
   ictx->op_work_queue->drain();
   expect_future_committed(mock_journaler);
-  mock_journal.commit_io_event(1U, -EILSEQ);
+  mock_journal->commit_io_event(1U, -EILSEQ);
 
   expect_shut_down_journaler(mock_journaler);
 }
@@ -1251,7 +1289,7 @@ TEST_F(TestMockJournal, FlushCommitPosition) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1259,11 +1297,12 @@ TEST_F(TestMockJournal, FlushCommitPosition) {
                mock_journaler, mock_open_request);
   BOOST_SCOPE_EXIT_ALL(&) {
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   expect_flush_commit_position(mock_journaler);
   C_SaferCond ctx;
-  mock_journal.flush_commit_position(&ctx);
+  mock_journal->flush_commit_position(&ctx);
   ASSERT_EQ(0, ctx.wait());
 
   expect_shut_down_journaler(mock_journaler);
@@ -1276,7 +1315,7 @@ TEST_F(TestMockJournal, ExternalReplay) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1284,6 +1323,7 @@ TEST_F(TestMockJournal, ExternalReplay) {
                mock_journaler, mock_open_request);
   BOOST_SCOPE_EXIT_ALL(&) {
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   InSequence seq;
@@ -1295,10 +1335,10 @@ TEST_F(TestMockJournal, ExternalReplay) {
   C_SaferCond start_ctx;
 
   journal::Replay<MockJournalImageCtx> *journal_replay = nullptr;
-  mock_journal.start_external_replay(&journal_replay, &start_ctx);
+  mock_journal->start_external_replay(&journal_replay, &start_ctx);
   ASSERT_EQ(0, start_ctx.wait());
 
-  mock_journal.stop_external_replay();
+  mock_journal->stop_external_replay();
 }
 
 TEST_F(TestMockJournal, ExternalReplayFailure) {
@@ -1308,7 +1348,7 @@ TEST_F(TestMockJournal, ExternalReplayFailure) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1316,6 +1356,7 @@ TEST_F(TestMockJournal, ExternalReplayFailure) {
                mock_journaler, mock_open_request);
   BOOST_SCOPE_EXIT_ALL(&) {
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   InSequence seq;
@@ -1327,7 +1368,7 @@ TEST_F(TestMockJournal, ExternalReplayFailure) {
   C_SaferCond start_ctx;
 
   journal::Replay<MockJournalImageCtx> *journal_replay = nullptr;
-  mock_journal.start_external_replay(&journal_replay, &start_ctx);
+  mock_journal->start_external_replay(&journal_replay, &start_ctx);
   ASSERT_EQ(-EINVAL, start_ctx.wait());
 }
 
@@ -1338,7 +1379,7 @@ TEST_F(TestMockJournal, AppendDisabled) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   MockJournalPolicy mock_journal_policy;
 
@@ -1348,18 +1389,19 @@ TEST_F(TestMockJournal, AppendDisabled) {
                mock_journaler, mock_open_request);
   BOOST_SCOPE_EXIT_ALL(&) {
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   InSequence seq;
   RWLock::RLocker snap_locker(mock_image_ctx.snap_lock);
   EXPECT_CALL(mock_image_ctx, get_journal_policy()).WillOnce(
     Return(ictx->get_journal_policy()));
-  ASSERT_TRUE(mock_journal.is_journal_appending());
+  ASSERT_TRUE(mock_journal->is_journal_appending());
 
   EXPECT_CALL(mock_image_ctx, get_journal_policy()).WillOnce(
     Return(&mock_journal_policy));
   EXPECT_CALL(mock_journal_policy, append_disabled()).WillOnce(Return(true));
-  ASSERT_FALSE(mock_journal.is_journal_appending());
+  ASSERT_FALSE(mock_journal->is_journal_appending());
 
   expect_shut_down_journaler(mock_journaler);
 }
@@ -1371,7 +1413,12 @@ TEST_F(TestMockJournal, CloseListenerEvent) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
+
+  BOOST_SCOPE_EXIT(&mock_journal) {
+    mock_journal->put();
+  } BOOST_SCOPE_EXIT_END
+
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1390,13 +1437,13 @@ TEST_F(TestMockJournal, CloseListenerEvent) {
       ADD_FAILURE() << "unexpected promotion event";
     }
   } listener;
-  mock_journal.add_listener(&listener);
+  mock_journal->add_listener(&listener);
 
   expect_shut_down_journaler(mock_journaler);
   close_journal(mock_image_ctx, mock_journal, mock_journaler);
 
   ASSERT_EQ(0, listener.ctx.wait());
-  mock_journal.remove_listener(&listener);
+  mock_journal->remove_listener(&listener);
 }
 
 TEST_F(TestMockJournal, ResyncRequested) {
@@ -1406,7 +1453,7 @@ TEST_F(TestMockJournal, ResyncRequested) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1426,11 +1473,12 @@ TEST_F(TestMockJournal, ResyncRequested) {
       ADD_FAILURE() << "unexpected promotion event";
     }
   } listener;
-  mock_journal.add_listener(&listener);
+  mock_journal->add_listener(&listener);
 
   BOOST_SCOPE_EXIT_ALL(&) {
-    mock_journal.remove_listener(&listener);
+    mock_journal->remove_listener(&listener);
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   InSequence seq;
@@ -1460,7 +1508,7 @@ TEST_F(TestMockJournal, ForcePromoted) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1479,11 +1527,12 @@ TEST_F(TestMockJournal, ForcePromoted) {
       ctx.complete(0);
     }
   } listener;
-  mock_journal.add_listener(&listener);
+  mock_journal->add_listener(&listener);
 
   BOOST_SCOPE_EXIT_ALL(&) {
-    mock_journal.remove_listener(&listener);
+    mock_journal->remove_listener(&listener);
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   InSequence seq;
@@ -1512,7 +1561,7 @@ TEST_F(TestMockJournal, UserFlushed) {
   ASSERT_EQ(0, open_image(m_image_name, &ictx));
 
   MockJournalImageCtx mock_image_ctx(*ictx);
-  MockJournal mock_journal(mock_image_ctx);
+  MockJournal *mock_journal = new MockJournal(mock_image_ctx);
   MockObjectDispatch mock_object_dispatch;
   ::journal::MockJournaler mock_journaler;
   MockJournalOpenRequest mock_open_request;
@@ -1520,10 +1569,11 @@ TEST_F(TestMockJournal, UserFlushed) {
                mock_journaler, mock_open_request);
   BOOST_SCOPE_EXIT_ALL(&) {
     close_journal(mock_image_ctx, mock_journal, mock_journaler);
+    mock_journal->put();
   };
 
   expect_set_append_batch_options(mock_image_ctx, mock_journaler, true);
-  mock_journal.user_flushed();
+  mock_journal->user_flushed();
 
   expect_shut_down_journaler(mock_journaler);
 }
diff --git a/src/test/librbd/test_mock_ObjectMap.cc b/src/test/librbd/test_mock_ObjectMap.cc
index 41672c73..d6add9c8 100644
--- a/src/test/librbd/test_mock_ObjectMap.cc
+++ b/src/test/librbd/test_mock_ObjectMap.cc
@@ -8,6 +8,7 @@
 #include "librbd/object_map/RefreshRequest.h"
 #include "librbd/object_map/UnlockRequest.h"
 #include "librbd/object_map/UpdateRequest.h"
+#include <boost/scope_exit.hpp>
 
 namespace librbd {
 
@@ -172,9 +173,13 @@ TEST_F(TestMockObjectMap, NonDetainedUpdate) {
   MockUnlockRequest mock_unlock_request;
   expect_unlock(mock_image_ctx, mock_unlock_request, 0);
 
-  MockObjectMap mock_object_map(mock_image_ctx, CEPH_NOSNAP);
+  MockObjectMap *mock_object_map = new MockObjectMap(mock_image_ctx, CEPH_NOSNAP);
+  BOOST_SCOPE_EXIT(&mock_object_map) {
+    mock_object_map->put();
+  } BOOST_SCOPE_EXIT_END
+
   C_SaferCond open_ctx;
-  mock_object_map.open(&open_ctx);
+  mock_object_map->open(&open_ctx);
   ASSERT_EQ(0, open_ctx.wait());
 
   C_SaferCond update_ctx1;
@@ -182,8 +187,8 @@ TEST_F(TestMockObjectMap, NonDetainedUpdate) {
   {
     RWLock::RLocker snap_locker(mock_image_ctx.snap_lock);
     RWLock::WLocker object_map_locker(mock_image_ctx.object_map_lock);
-    mock_object_map.aio_update(CEPH_NOSNAP, 0, 1, {}, {}, false, &update_ctx1);
-    mock_object_map.aio_update(CEPH_NOSNAP, 1, 1, {}, {}, false, &update_ctx2);
+    mock_object_map->aio_update(CEPH_NOSNAP, 0, 1, {}, {}, false, &update_ctx1);
+    mock_object_map->aio_update(CEPH_NOSNAP, 1, 1, {}, {}, false, &update_ctx2);
   }
 
   finish_update_2->complete(0);
@@ -193,7 +198,7 @@ TEST_F(TestMockObjectMap, NonDetainedUpdate) {
   ASSERT_EQ(0, update_ctx1.wait());
 
   C_SaferCond close_ctx;
-  mock_object_map.close(&close_ctx);
+  mock_object_map->close(&close_ctx);
   ASSERT_EQ(0, close_ctx.wait());
 }
 
@@ -228,9 +233,13 @@ TEST_F(TestMockObjectMap, DetainedUpdate) {
   MockUnlockRequest mock_unlock_request;
   expect_unlock(mock_image_ctx, mock_unlock_request, 0);
 
-  MockObjectMap mock_object_map(mock_image_ctx, CEPH_NOSNAP);
+  MockObjectMap *mock_object_map = new MockObjectMap(mock_image_ctx, CEPH_NOSNAP);
+  BOOST_SCOPE_EXIT(&mock_object_map) {
+    mock_object_map->put();
+  } BOOST_SCOPE_EXIT_END
+
   C_SaferCond open_ctx;
-  mock_object_map.open(&open_ctx);
+  mock_object_map->open(&open_ctx);
   ASSERT_EQ(0, open_ctx.wait());
 
   C_SaferCond update_ctx1;
@@ -240,13 +249,13 @@ TEST_F(TestMockObjectMap, DetainedUpdate) {
   {
     RWLock::RLocker snap_locker(mock_image_ctx.snap_lock);
     RWLock::WLocker object_map_locker(mock_image_ctx.object_map_lock);
-    mock_object_map.aio_update(CEPH_NOSNAP, 1, 4, 1, {}, {}, false,
+    mock_object_map->aio_update(CEPH_NOSNAP, 1, 4, 1, {}, {}, false,
                                &update_ctx1);
-    mock_object_map.aio_update(CEPH_NOSNAP, 1, 3, 1, {}, {}, false,
+    mock_object_map->aio_update(CEPH_NOSNAP, 1, 3, 1, {}, {}, false,
                                &update_ctx2);
-    mock_object_map.aio_update(CEPH_NOSNAP, 2, 3, 1, {}, {}, false,
+    mock_object_map->aio_update(CEPH_NOSNAP, 2, 3, 1, {}, {}, false,
                                &update_ctx3);
-    mock_object_map.aio_update(CEPH_NOSNAP, 0, 2, 1, {}, {}, false,
+    mock_object_map->aio_update(CEPH_NOSNAP, 0, 2, 1, {}, {}, false,
                                &update_ctx4);
   }
 
@@ -270,7 +279,7 @@ TEST_F(TestMockObjectMap, DetainedUpdate) {
   ASSERT_EQ(0, update_ctx4.wait());
 
   C_SaferCond close_ctx;
-  mock_object_map.close(&close_ctx);
+  mock_object_map->close(&close_ctx);
   ASSERT_EQ(0, close_ctx.wait());
 }
 
diff --git a/src/test/messenger/simple_client.cc b/src/test/messenger/simple_client.cc
index ba7ed2b0..992f8abf 100644
--- a/src/test/messenger/simple_client.cc
+++ b/src/test/messenger/simple_client.cc
@@ -30,6 +30,7 @@ using namespace std;
 #include "common/address_helper.h"
 #include "message_helper.h"
 #include "simple_dispatcher.h"
+#include "auth/DummyAuth.h"
 
 #define dout_subsys ceph_subsys_simple_client
 
@@ -59,7 +60,7 @@ int main(int argc, const char **argv)
 	std::string addr = "localhost";
 	std::string port = "1234";
 
-	int n_msgs = 50;
+	int n_msgs = 1;
 	int n_dsize = 0;
 
 	struct timespec ts;
@@ -101,12 +102,20 @@ int main(int argc, const char **argv)
 	  "dest port " << port << " " <<
 	  "initial msgs (pipe depth) " << n_msgs << " " <<
 	  "data buffer size " << n_dsize << std::endl;
-
-	messenger = Messenger::create(g_ceph_context, g_conf().get_val<std::string>("ms_type"),
-				      entity_name_t::MON(-1),
+        g_ceph_context->_conf.set_val("auth_cluster_required", "none");
+        g_ceph_context->_conf.set_val("auth_service_required", "none");
+        g_ceph_context->_conf.set_val("auth_client_required", "none");
+        string ms_type =  g_conf().get_val<std::string>("ms_type");
+        cout << "Client Adaptor: ms_type: " << ms_type << std::endl;
+	messenger = Messenger::create(g_ceph_context, ms_type,
+				      entity_name_t::CLIENT(-1),
 				      "client",
 				      getpid(), 0);
 
+	DummyAuthClientServer dummy_auth(g_ceph_context);
+        dummy_auth.auth_registry.refresh_config();
+	messenger->set_auth_client(&dummy_auth);
+        messenger->set_auth_server(&dummy_auth);
 	// enable timing prints
 	messenger->set_magic(MSG_MAGIC_TRACE_CTR);
 	messenger->set_default_policy(Messenger::Policy::lossy_client(0));
@@ -115,10 +124,16 @@ int main(int argc, const char **argv)
 	dest_str += addr;
 	dest_str += ":";
 	dest_str += port;
+        cout << "Client Adaptor: address = " << dest_str << std::endl;
 	entity_addr_from_url(&dest_addr, dest_str.c_str());
+	// dest_addr.set_type(entity_addr_t::TYPE_LEGACY);
+	dest_addr.set_type(entity_addr_t::TYPE_MSGR2);
+        cout << "Client Adaptor: legacy address = " << dest_addr.get_legacy_str() << std::endl;        
 	entity_addrvec_t dest_addrs(dest_addr);
+        cout << "Client Adaptor: vec legacy address = " << dest_addrs.get_legacy_str() << std::endl;        
 
 	dispatcher = new SimpleDispatcher(messenger);
+	dispatcher->ms_set_require_authorizer(false);
 	messenger->add_dispatcher_head(dispatcher);
 
 	dispatcher->set_active(); // this side is the pinger
@@ -127,7 +142,12 @@ int main(int argc, const char **argv)
 	if (r < 0)
 		goto out;
 
-	conn = messenger->connect_to_mon(dest_addrs);
+	conn = messenger->connect_to_osd(dest_addrs);
+        std::cout << "Client Adaptor: conn = " << conn << std::endl;
+
+        while (!conn->is_connected()) {
+          nanosleep(&ts, NULL);
+        }
 
 	// do stuff
 	time_t t1, t2;
@@ -144,6 +164,12 @@ int main(int argc, const char **argv)
 	    m = new_simple_ping_with_data("simple_client", n_dsize);
 	  }
 	  conn->send_message(m);
+          std::cout << "Client Adaptor: client message conn = " << m->get_connection() << std::endl;
+          std::cout << "Client Adaptor: peer_addr = " << conn->get_peer_addr();
+          entity_addrvec_t peer_addr_vec = *(m->get_connection()->peer_addrs);
+          for (auto it : peer_addr_vec.v) {
+            std::cout << "Client Adaptor: peer_addr = " << it.get_legacy_str() << std::endl;
+          }
 	}
 
 	// do stuff
diff --git a/src/test/messenger/simple_dispatcher.cc b/src/test/messenger/simple_dispatcher.cc
index b13958d3..45ee6914 100644
--- a/src/test/messenger/simple_dispatcher.cc
+++ b/src/test/messenger/simple_dispatcher.cc
@@ -17,6 +17,8 @@
 #include "simple_dispatcher.h"
 #include "messages/MPing.h"
 #include "messages/MDataPing.h"
+#include "messages/MOSDOpReply.h"
+#include "messages/MOSDOp.h"
 
 SimpleDispatcher::SimpleDispatcher(Messenger *msgr) :
   Dispatcher(msgr->cct),
@@ -42,16 +44,37 @@ bool SimpleDispatcher::ms_dispatch(Message *m)
 
   switch (m->get_type()) {
   case CEPH_MSG_PING:
+  {
+    std::cout << "Client Adaptor: msg ping " << std::endl;
+    std::cout << "Client Adaptor: conn = " << con << "peer_addr = " << con->get_peer_addr() << std::endl;
+    //entity_addrvec_t peer_addr_vec = *(m->get_connection()->peer_addrs);
+    //for (auto it : peer_addr_vec.v) {
+    //  std::cout << "Nalu debug: peer_addr = " << it.get_legacy_str() << std::endl;
+    //}
     break;
+  }
   case MSG_DATA_PING:
   {
     MDataPing* mdp __attribute__((unused)) = static_cast<MDataPing*>(m);
+    std::cout << "Client Adaptor: msg data ping" << std::endl;
     //cout << "MDataPing " << mdp->tag << " " << mdp->counter << std::endl;
     //mdp->get_data().hexdump(cout);
     ConnectionRef con = m->get_connection();
     con->send_message(m);
   }
     break;
+  case CEPH_MSG_OSD_OP:
+  {
+    std::cout << "Client Adaptor: osd op msg" << std::endl;
+    std::cout << "Client Adaptor: conn = " << con << std::endl;
+    std::cout << "Client Adaptor: peer_addr = " << con->get_peer_addr() << std::endl;
+    MOSDOp *osd_op = static_cast<MOSDOp*>(m);
+    MOSDOpReply *reply = new MOSDOpReply(osd_op, 0, 0, 0, false);
+    std::cout << "Client Adaptor: connection " << m->get_connection() << std::endl;
+    m->get_connection()->send_message(reply);
+    m->put();
+    break;
+  }
   default:
     ceph_abort();
   }
@@ -66,7 +89,7 @@ bool SimpleDispatcher::ms_dispatch(Message *m)
   } /* trace ctr */
 
 
-  con->send_message(m);
+  // con->send_message(m);
 
   //m->put();
 
diff --git a/src/test/messenger/simple_server.cc b/src/test/messenger/simple_server.cc
index 8b85f3af..e4819a34 100644
--- a/src/test/messenger/simple_server.cc
+++ b/src/test/messenger/simple_server.cc
@@ -28,6 +28,8 @@ using namespace std;
 #include "perfglue/heap_profiler.h"
 #include "common/address_helper.h"
 #include "simple_dispatcher.h"
+#include "auth/DummyAuth.h"
+#include "msg/async/AsyncMessenger.h"
 
 #define dout_subsys ceph_subsys_simple_server
 
@@ -72,17 +74,26 @@ int main(int argc, const char **argv)
 	dest_str += ":";
 	dest_str += port;
 	entity_addr_from_url(&bind_addr, dest_str.c_str());
+        entity_addrvec_t bind_addrs(bind_addr);
 
-	messenger = Messenger::create(g_ceph_context, g_conf().get_val<std::string>("ms_type"),
-				      entity_name_t::MON(-1),
+        string ms_type = g_conf().get_val<std::string>("ms_type");
+        cout << "Client Adaptor: ms_type: " << ms_type << std::endl;
+	messenger = Messenger::create(g_ceph_context, ms_type,
+				      entity_name_t::OSD(-1),
 				      "simple_server",
 				      0 /* nonce */,
 				      0 /* flags */);
 	// enable timing prints
+	DummyAuthClientServer dummy_auth(g_ceph_context);
+        dummy_auth.auth_registry.refresh_config();
+        messenger->set_auth_client(&dummy_auth);
+	messenger->set_auth_server(&dummy_auth);
 	messenger->set_magic(MSG_MAGIC_TRACE_CTR);
 	messenger->set_default_policy(
 	  Messenger::Policy::stateless_server(0));
 
+        // bind_addr.set_type(entity_addr_t::TYPE_LEGACY);
+        bind_addr.set_type(entity_addr_t::TYPE_MSGR2);
 	r = messenger->bind(bind_addr);
 	if (r < 0)
 		goto out;
@@ -92,16 +103,19 @@ int main(int argc, const char **argv)
 	common_init_finish(g_ceph_context);
 
 	dispatcher = new SimpleDispatcher(messenger);
+	dispatcher->ms_set_require_authorizer(false);
 
 	messenger->add_dispatcher_head(dispatcher); // should reach ready()
 	messenger->start();
+        
+    std::cout << "Client Adaptor: server conn = " << static_cast<AsyncMessenger *>(messenger)->lookup_conn(bind_addrs) << std::endl;
 	messenger->wait(); // can't be called until ready()
 
 	// done
 	delete messenger;
 
 out:
-	cout << "Simple Server exit" << endl;
+	cout << "Simple Server exit" << std::endl;
 	return r;
 }
 
diff --git a/src/tools/rbd/action/Snap.cc b/src/tools/rbd/action/Snap.cc
index 70cf62da..bf7632dc 100644
--- a/src/tools/rbd/action/Snap.cc
+++ b/src/tools/rbd/action/Snap.cc
@@ -12,6 +12,10 @@
 #include <iostream>
 #include <boost/program_options.hpp>
 #include <boost/bind.hpp>
+#ifdef WITH_GLOBAL_CACHE
+#include "client_adaptor/ClientAdaptorPlugin.h"
+#include "client_adaptor/ClientAdaptorMsg.h"
+#endif
 
 namespace rbd {
 namespace action {
@@ -21,8 +25,11 @@ static const std::string ALL_NAME("all");
 
 namespace at = argument_types;
 namespace po = boost::program_options;
-
+#ifdef WITH_GLOBAL_CACHE
+int do_list_snaps(librados::IoCtx& io_ctx, librbd::Image& image, Formatter *f, bool all_snaps, librados::Rados& rados)
+#else
 int do_list_snaps(librbd::Image& image, Formatter *f, bool all_snaps, librados::Rados& rados)
+#endif
 {
   std::vector<librbd::snap_info_t> snaps;
   TextTable t;
@@ -58,8 +65,24 @@ int do_list_snaps(librbd::Image& image, Formatter *f, bool all_snaps, librados::
   rados.pool_list2(pool_list);
   std::map<int64_t, std::string> pool_map(pool_list.begin(), pool_list.end());
 
+#ifdef WITH_GLOBAL_CACHE
+  auto cct = reinterpret_cast<CephContext*>(rados.cct());
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+
+  if (!plugin || !plugin->msg_ref) {
+      std::cerr << "global_cache plugin not loaded, plugin=" << plugin << std::endl;
+      return -EINVAL;
+  }
+#endif
+
   for (std::vector<librbd::snap_info_t>::iterator s = snaps.begin();
        s != snaps.end(); ++s) {
+#ifdef WITH_GLOBAL_CACHE
+    if (!all_snaps && plugin->msg_ref->is_gc_snap(s->name) && io_ctx.check_acc()) {
+      continue;
+    }
+#endif
     struct timespec timestamp;
     bool snap_protected = false;
     image.snap_get_timestamp(s->id, &timestamp);
@@ -204,12 +227,25 @@ int do_rollback_snap(librbd::Image& image, const char *snapname,
   pc.finish();
   return 0;
 }
-
+#ifdef WITH_GLOBAL_CACHE
+int do_purge_snaps(librados::IoCtx& io_ctx, librbd::Image& image, bool no_progress)
+#else
 int do_purge_snaps(librbd::Image& image, bool no_progress)
+#endif
 {
   utils::ProgressContext pc("Removing all snapshots", no_progress);
   std::vector<librbd::snap_info_t> snaps;
   bool is_protected = false;
+#ifdef WITH_GLOBAL_CACHE
+  auto cct = reinterpret_cast<CephContext*>(io_ctx.cct());
+  PluginRegistry *reg = cct->get_plugin_registry();
+  auto plugin = static_cast<ClientAdaptorPlugin *>(reg->get_with_load("global_cache", "client_adaptor_plugin"));
+
+  if (!plugin || !plugin->msg_ref) {
+      std::cerr << "global_cache plugin not loaded, plugin=" << plugin << std::endl;
+      return -EINVAL;
+  }
+#endif
   int r = image.snap_list(snaps);
   if (r < 0) {
     pc.fail();
@@ -230,6 +266,10 @@ int do_purge_snaps(librbd::Image& image, bool no_progress)
       } else if (is_protected == true) {
         protect.push_back(it->name.c_str());
         snaps.erase(it);
+#ifdef WITH_GLOBAL_CACHE
+      } else if(plugin->msg_ref->is_gc_snap(it->name) && io_ctx.check_acc()) {
+        snaps.erase(it);
+#endif
       } else {
         ++it;
       }
@@ -339,7 +379,11 @@ int execute_list(const po::variables_map &vm,
   }
 
   bool all_snaps = vm[ALL_NAME].as<bool>();
+#ifdef WITH_GLOBAL_CACHE
+  r = do_list_snaps(io_ctx, image, formatter.get(), all_snaps, rados);
+#else
   r = do_list_snaps(image, formatter.get(), all_snaps, rados);
+#endif
   if (r < 0) {
     cerr << "rbd: failed to list snapshots: " << cpp_strerror(r)
          << std::endl;
@@ -530,8 +574,11 @@ int execute_purge(const po::variables_map &vm,
   if (r < 0) {
     return r;
   }
-
+#ifdef WITH_GLOBAL_CACHE
+  r = do_purge_snaps(io_ctx, image, vm[at::NO_PROGRESS].as<bool>());
+#else
   r = do_purge_snaps(image, vm[at::NO_PROGRESS].as<bool>());
+#endif
   if (r < 0) {
     if (r != -EBUSY) {
       std::cerr << "rbd: removing snaps failed: " << cpp_strerror(r)
diff --git a/src/vstart.sh b/src/vstart.sh
index 37aa28b7..142bdd1c 100755
--- a/src/vstart.sh
+++ b/src/vstart.sh
@@ -752,8 +752,10 @@ EOF
             local uuid=`uuidgen`
             echo "add osd$osd $uuid"
 	    OSD_SECRET=$($CEPH_BIN/ceph-authtool --gen-print-key)
+        # Ceph bug : If we add cout in ceph-authtool,it will impact the key
+	    OSD_SECRET=`echo ${OSD_SECRET} | awk '{print $NF}'`
 	    echo "{\"cephx_secret\": \"$OSD_SECRET\"}" > $CEPH_DEV_DIR/osd$osd/new.json
-            ceph_adm osd new $uuid -i $CEPH_DEV_DIR/osd$osd/new.json
+	    ceph_adm osd new $uuid -i $CEPH_DEV_DIR/osd$osd/new.json
 	    rm $CEPH_DEV_DIR/osd$osd/new.json
             $SUDO $CEPH_BIN/ceph-osd -i $osd $ARGS --mkfs --key $OSD_SECRET --osd-uuid $uuid
 
